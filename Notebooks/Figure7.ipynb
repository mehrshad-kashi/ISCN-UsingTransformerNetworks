{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQtisbGElB3Y",
        "outputId": "2ac48b1a-fa96-4fda-e58e-ccee6a173273"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount your Google Drive if needed\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JCw8JMPe9ON",
        "outputId": "4ce87fe9-6b4c-4e4d-94ad-235907a30371"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.27.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "# Note: Some libraries or dependencies used in this code may become deprecated over time.\n",
        "# If you encounter deprecated libraries, replace them with suitable alternatives and\n",
        "# update the corresponding sections of the code that rely on the deprecated classes or methods accordingly.\n",
        "\n",
        "!pip install transformers[torch]==4.31.0\n",
        "!pip install datasets\n",
        "\n",
        "import os\n",
        "import json\n",
        "import gzip\n",
        "import pandas as pd\n",
        "import collections\n",
        "import nltk\n",
        "from google.colab import files\n",
        "\n",
        "from urllib.request import urlopen\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from collections import defaultdict\n",
        "import pickle\n",
        "from IPython.display import clear_output\n",
        "import torch\n",
        "from transformers import RobertaTokenizerFast\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support,  recall_score, precision_score, f1_score, roc_auc_score, confusion_matrix, matthews_corrcoef\n",
        "from sklearn.model_selection import train_test_split,KFold, StratifiedKFold\n",
        "from transformers import RobertaForSequenceClassification, Trainer, TrainingArguments, EarlyStoppingCallback, AutoTokenizer, AutoModelForSequenceClassification\n",
        "from datasets import load_metric\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dt1cBnlJD5_B"
      },
      "outputs": [],
      "source": [
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(torch.cuda.device_count())\n",
        "    print(torch.cuda.get_device_name(0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXi_FBkFqXBc"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xrO-fGv5fAYO"
      },
      "outputs": [],
      "source": [
        "def set_seed(SEED):\n",
        "    \"\"\" Set random seed to all \"\"\"\n",
        "    random.seed(SEED)\n",
        "    np.random.seed(SEED)\n",
        "    torch.manual_seed(SEED)\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "\n",
        "\n",
        "class AmazonDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels= None):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        if self.labels:\n",
        "           item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings[\"input_ids\"])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def prepare_auxilary_datasets(dataset):\n",
        "\n",
        "    X_test =  dataset[\"sentence\"]\n",
        "    y_test =  dataset[\"label\"]   if \"label\" in dataset.columns.values else   dataset[\"helpful\"]\n",
        "    # Encoding\n",
        "    test_encodings = tokenizer(X_test.tolist(), truncation=True, padding=True, max_length=40)\n",
        "    test_dataset = AmazonDataset(test_encodings, y_test.tolist())\n",
        "    return test_dataset\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=1)\n",
        "\n",
        "    accuracy = accuracy_score(y_true=labels, y_pred=predictions)\n",
        "    recall = recall_score(y_true=labels, y_pred=predictions)\n",
        "    precision = precision_score(y_true=labels, y_pred=predictions)\n",
        "    f1 = f1_score(y_true=labels, y_pred=predictions)\n",
        "    macro_f1 = f1_score(y_true=labels, y_pred=predictions, average= 'macro')\n",
        "    mcc = matthews_corrcoef(labels, predictions)\n",
        "    auc = roc_auc_score(y_true= labels, y_score= logits[:, 1])\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true= labels, y_pred=predictions).ravel()\n",
        "    specificity = tn / (tn+fp)\n",
        "\n",
        "    return {\n",
        "        'accuracy'    : accuracy,\n",
        "        'f1'          : f1,\n",
        "        'macro_f1'    : macro_f1,\n",
        "        'precision'   : precision,\n",
        "        'recall'      : recall,\n",
        "        'specificity' : specificity,\n",
        "        'mcc'         : mcc,\n",
        "        'AUC'         : auc\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "def return_training_args():\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=\"test-amazon\",\n",
        "        evaluation_strategy = \"epoch\",  # there would be no evaluation during training when doing simple K-fold cross validation a\n",
        "        learning_rate=2e-5,\n",
        "        per_device_train_batch_size=16,\n",
        "        per_device_eval_batch_size=256,\n",
        "        num_train_epochs = 6,\n",
        "        weight_decay=0.01,\n",
        "        load_best_model_at_end=False,\n",
        "        logging_strategy = \"steps\",\n",
        "        logging_steps = 50,\n",
        "        save_strategy= \"no\",\n",
        "    )\n",
        "    return training_args\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1976b2c6c79b491ca904b91a5d8b3112",
            "2eed8debca704a519987f33ed0d7004f",
            "407e94e7a9314e90a839c839c815dc1e",
            "a4be557d93b2403ea7dba4d0f9053951",
            "b0a803e0689540059afaeff772e04498",
            "5f1b990fa36548298bef01916594fc2a",
            "4bfd014669cb4b87bcefd34d2ba7d8fd",
            "95bfc72abab04941b551e58a9c9ceb5b",
            "8baa9e62c91d49fb8445f4f75c239047",
            "5f47edd349c44340b58eeaac00d13f02",
            "7f3e590700d94ddcbdbe95e3d948d751",
            "cedf7dbcf69f4b638f09ec52c63db6e2",
            "4a0cccc528984fbf80eda3970ca3f4dd",
            "233172b9ba5047a5951529fd5d83376d",
            "217ea26d6e6248e59bc66698ce28b88e",
            "b7acdddd9d744d8d85e99121ff957c50",
            "11d7e1ec7a84467babc54e1e9effe0e0",
            "a1387f79961d4a4fb08eaa00e6323414",
            "083b3bc771aa4c3d9ca2847d32979ab4",
            "92952d2e8732453dbbcea1d39f740f7d",
            "8c2ce2a56ad54328b3fe326e9dd4b355",
            "62161c843b54409ea85e34f4a511327a",
            "0951edcd8691435a9fac2badba0582d1",
            "686de9d417384f7b99cc71e31187c9f8"
          ]
        },
        "id": "9fJCRCsZfVuL",
        "outputId": "2483f95e-1777-466b-82a2-852f5b365509"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1976b2c6c79b491ca904b91a5d8b3112",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2eed8debca704a519987f33ed0d7004f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/685 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "407e94e7a9314e90a839c839c815dc1e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "spiece.model:   0%|          | 0.00/760k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a4be557d93b2403ea7dba4d0f9053951",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.31M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 94, total number of training (for each informative and uninform class) and test samples: 800, 6400 0.1 ALBERT-L 94 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b0a803e0689540059afaeff772e04498",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/71.5M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [600/600 00:51, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.708300</td>\n",
              "      <td>0.691160</td>\n",
              "      <td>0.535000</td>\n",
              "      <td>0.584821</td>\n",
              "      <td>0.528206</td>\n",
              "      <td>0.528226</td>\n",
              "      <td>0.655000</td>\n",
              "      <td>0.415000</td>\n",
              "      <td>0.072107</td>\n",
              "      <td>0.527419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.696600</td>\n",
              "      <td>0.694256</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.449612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.709200</td>\n",
              "      <td>0.694576</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.543512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.701200</td>\n",
              "      <td>0.700593</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.567350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.699200</td>\n",
              "      <td>0.692988</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.572381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.704600</td>\n",
              "      <td>0.692982</td>\n",
              "      <td>0.501250</td>\n",
              "      <td>0.667223</td>\n",
              "      <td>0.336105</td>\n",
              "      <td>0.500626</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.002500</td>\n",
              "      <td>0.035377</td>\n",
              "      <td>0.568175</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 791, total number of training (for each informative and uninform class) and test samples: 800, 6400 0.1 ALBERT-L 791 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [600/600 00:51, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.686400</td>\n",
              "      <td>0.695010</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.456706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.701300</td>\n",
              "      <td>0.719615</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.625444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.685500</td>\n",
              "      <td>0.655364</td>\n",
              "      <td>0.630000</td>\n",
              "      <td>0.628141</td>\n",
              "      <td>0.629991</td>\n",
              "      <td>0.631313</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.635000</td>\n",
              "      <td>0.260013</td>\n",
              "      <td>0.594575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.627000</td>\n",
              "      <td>0.702074</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.490781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.703700</td>\n",
              "      <td>0.670456</td>\n",
              "      <td>0.573750</td>\n",
              "      <td>0.327416</td>\n",
              "      <td>0.507715</td>\n",
              "      <td>0.775701</td>\n",
              "      <td>0.207500</td>\n",
              "      <td>0.940000</td>\n",
              "      <td>0.216667</td>\n",
              "      <td>0.427956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.490100</td>\n",
              "      <td>0.661564</td>\n",
              "      <td>0.655000</td>\n",
              "      <td>0.626016</td>\n",
              "      <td>0.652915</td>\n",
              "      <td>0.683432</td>\n",
              "      <td>0.577500</td>\n",
              "      <td>0.732500</td>\n",
              "      <td>0.313792</td>\n",
              "      <td>0.712569</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 5, total number of training (for each informative and uninform class) and test samples: 800, 6400 0.1 ALBERT-L 5 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [600/600 00:51, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.910700</td>\n",
              "      <td>0.732262</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.663866</td>\n",
              "      <td>0.344128</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.987500</td>\n",
              "      <td>0.012500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.481088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.688400</td>\n",
              "      <td>0.658246</td>\n",
              "      <td>0.670000</td>\n",
              "      <td>0.693023</td>\n",
              "      <td>0.668133</td>\n",
              "      <td>0.647826</td>\n",
              "      <td>0.745000</td>\n",
              "      <td>0.595000</td>\n",
              "      <td>0.343891</td>\n",
              "      <td>0.690412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.705900</td>\n",
              "      <td>0.732411</td>\n",
              "      <td>0.617500</td>\n",
              "      <td>0.633094</td>\n",
              "      <td>0.616808</td>\n",
              "      <td>0.608295</td>\n",
              "      <td>0.660000</td>\n",
              "      <td>0.575000</td>\n",
              "      <td>0.235854</td>\n",
              "      <td>0.650181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.497800</td>\n",
              "      <td>0.595667</td>\n",
              "      <td>0.707500</td>\n",
              "      <td>0.731651</td>\n",
              "      <td>0.705111</td>\n",
              "      <td>0.675847</td>\n",
              "      <td>0.797500</td>\n",
              "      <td>0.617500</td>\n",
              "      <td>0.421891</td>\n",
              "      <td>0.783238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.387900</td>\n",
              "      <td>0.684259</td>\n",
              "      <td>0.703750</td>\n",
              "      <td>0.723454</td>\n",
              "      <td>0.702238</td>\n",
              "      <td>0.678337</td>\n",
              "      <td>0.775000</td>\n",
              "      <td>0.632500</td>\n",
              "      <td>0.411701</td>\n",
              "      <td>0.785169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.380400</td>\n",
              "      <td>0.918595</td>\n",
              "      <td>0.710000</td>\n",
              "      <td>0.728337</td>\n",
              "      <td>0.708673</td>\n",
              "      <td>0.685022</td>\n",
              "      <td>0.777500</td>\n",
              "      <td>0.642500</td>\n",
              "      <td>0.423880</td>\n",
              "      <td>0.754256</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 6932, total number of training (for each informative and uninform class) and test samples: 800, 6400 0.1 ALBERT-L 6932 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [600/600 00:51, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.577400</td>\n",
              "      <td>0.620667</td>\n",
              "      <td>0.697500</td>\n",
              "      <td>0.719258</td>\n",
              "      <td>0.695672</td>\n",
              "      <td>0.670996</td>\n",
              "      <td>0.775000</td>\n",
              "      <td>0.620000</td>\n",
              "      <td>0.399832</td>\n",
              "      <td>0.756037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.545200</td>\n",
              "      <td>0.565824</td>\n",
              "      <td>0.716250</td>\n",
              "      <td>0.718012</td>\n",
              "      <td>0.716239</td>\n",
              "      <td>0.713580</td>\n",
              "      <td>0.722500</td>\n",
              "      <td>0.710000</td>\n",
              "      <td>0.432534</td>\n",
              "      <td>0.783244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.477500</td>\n",
              "      <td>0.680607</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.653179</td>\n",
              "      <td>0.694431</td>\n",
              "      <td>0.773973</td>\n",
              "      <td>0.565000</td>\n",
              "      <td>0.835000</td>\n",
              "      <td>0.415429</td>\n",
              "      <td>0.784125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.215300</td>\n",
              "      <td>0.694217</td>\n",
              "      <td>0.738750</td>\n",
              "      <td>0.738423</td>\n",
              "      <td>0.738750</td>\n",
              "      <td>0.739348</td>\n",
              "      <td>0.737500</td>\n",
              "      <td>0.740000</td>\n",
              "      <td>0.477501</td>\n",
              "      <td>0.807638</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.196700</td>\n",
              "      <td>0.975164</td>\n",
              "      <td>0.746250</td>\n",
              "      <td>0.745932</td>\n",
              "      <td>0.746250</td>\n",
              "      <td>0.746867</td>\n",
              "      <td>0.745000</td>\n",
              "      <td>0.747500</td>\n",
              "      <td>0.492502</td>\n",
              "      <td>0.808538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.070500</td>\n",
              "      <td>1.090610</td>\n",
              "      <td>0.743750</td>\n",
              "      <td>0.747226</td>\n",
              "      <td>0.743702</td>\n",
              "      <td>0.737226</td>\n",
              "      <td>0.757500</td>\n",
              "      <td>0.730000</td>\n",
              "      <td>0.487684</td>\n",
              "      <td>0.807931</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 1759, total number of training (for each informative and uninform class) and test samples: 800, 6400 0.1 ALBERT-L 1759 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [600/600 00:51, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.703300</td>\n",
              "      <td>0.693648</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.567712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.709700</td>\n",
              "      <td>0.697640</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.387272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.698200</td>\n",
              "      <td>0.693807</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.372244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.673000</td>\n",
              "      <td>0.686559</td>\n",
              "      <td>0.588750</td>\n",
              "      <td>0.439523</td>\n",
              "      <td>0.557373</td>\n",
              "      <td>0.689840</td>\n",
              "      <td>0.322500</td>\n",
              "      <td>0.855000</td>\n",
              "      <td>0.209704</td>\n",
              "      <td>0.603400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.701800</td>\n",
              "      <td>0.694327</td>\n",
              "      <td>0.522500</td>\n",
              "      <td>0.256809</td>\n",
              "      <td>0.452530</td>\n",
              "      <td>0.578947</td>\n",
              "      <td>0.165000</td>\n",
              "      <td>0.880000</td>\n",
              "      <td>0.064366</td>\n",
              "      <td>0.572844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.663900</td>\n",
              "      <td>0.647385</td>\n",
              "      <td>0.635000</td>\n",
              "      <td>0.677704</td>\n",
              "      <td>0.628477</td>\n",
              "      <td>0.606719</td>\n",
              "      <td>0.767500</td>\n",
              "      <td>0.502500</td>\n",
              "      <td>0.280011</td>\n",
              "      <td>0.672362</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 323, total number of training (for each informative and uninform class) and test samples: 800, 6400 0.1 ALBERT-L 323 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [600/600 00:51, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.734800</td>\n",
              "      <td>0.710820</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.513022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.709500</td>\n",
              "      <td>0.701720</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.533844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.711600</td>\n",
              "      <td>0.702743</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.547213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.716500</td>\n",
              "      <td>0.767870</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.517859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.694500</td>\n",
              "      <td>0.701913</td>\n",
              "      <td>0.498750</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.332777</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.997500</td>\n",
              "      <td>-0.035377</td>\n",
              "      <td>0.539675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.697400</td>\n",
              "      <td>0.689988</td>\n",
              "      <td>0.515000</td>\n",
              "      <td>0.105991</td>\n",
              "      <td>0.386615</td>\n",
              "      <td>0.676471</td>\n",
              "      <td>0.057500</td>\n",
              "      <td>0.972500</td>\n",
              "      <td>0.074358</td>\n",
              "      <td>0.632162</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 1694, total number of training (for each informative and uninform class) and test samples: 800, 6400 0.1 ALBERT-L 1694 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [600/600 00:51, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.710000</td>\n",
              "      <td>0.704766</td>\n",
              "      <td>0.495000</td>\n",
              "      <td>0.650519</td>\n",
              "      <td>0.370305</td>\n",
              "      <td>0.497354</td>\n",
              "      <td>0.940000</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>-0.021932</td>\n",
              "      <td>0.453838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.706500</td>\n",
              "      <td>0.688600</td>\n",
              "      <td>0.537500</td>\n",
              "      <td>0.579545</td>\n",
              "      <td>0.532828</td>\n",
              "      <td>0.531250</td>\n",
              "      <td>0.637500</td>\n",
              "      <td>0.437500</td>\n",
              "      <td>0.076547</td>\n",
              "      <td>0.549844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.715200</td>\n",
              "      <td>0.715609</td>\n",
              "      <td>0.490000</td>\n",
              "      <td>0.656566</td>\n",
              "      <td>0.333137</td>\n",
              "      <td>0.494924</td>\n",
              "      <td>0.975000</td>\n",
              "      <td>0.005000</td>\n",
              "      <td>-0.082269</td>\n",
              "      <td>0.386912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.693800</td>\n",
              "      <td>0.687671</td>\n",
              "      <td>0.573750</td>\n",
              "      <td>0.398589</td>\n",
              "      <td>0.534241</td>\n",
              "      <td>0.676647</td>\n",
              "      <td>0.282500</td>\n",
              "      <td>0.865000</td>\n",
              "      <td>0.181465</td>\n",
              "      <td>0.569631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.694300</td>\n",
              "      <td>0.677328</td>\n",
              "      <td>0.586250</td>\n",
              "      <td>0.583648</td>\n",
              "      <td>0.586234</td>\n",
              "      <td>0.587342</td>\n",
              "      <td>0.580000</td>\n",
              "      <td>0.592500</td>\n",
              "      <td>0.172513</td>\n",
              "      <td>0.578463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.700300</td>\n",
              "      <td>0.675709</td>\n",
              "      <td>0.585000</td>\n",
              "      <td>0.551351</td>\n",
              "      <td>0.582652</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.510000</td>\n",
              "      <td>0.660000</td>\n",
              "      <td>0.171945</td>\n",
              "      <td>0.583681</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 9741, total number of training (for each informative and uninform class) and test samples: 800, 6400 0.1 ALBERT-L 9741 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [600/600 00:51, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.741900</td>\n",
              "      <td>0.696174</td>\n",
              "      <td>0.511250</td>\n",
              "      <td>0.187110</td>\n",
              "      <td>0.418846</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.112500</td>\n",
              "      <td>0.910000</td>\n",
              "      <td>0.037294</td>\n",
              "      <td>0.483013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.689300</td>\n",
              "      <td>0.763476</td>\n",
              "      <td>0.560000</td>\n",
              "      <td>0.399317</td>\n",
              "      <td>0.526089</td>\n",
              "      <td>0.629032</td>\n",
              "      <td>0.292500</td>\n",
              "      <td>0.827500</td>\n",
              "      <td>0.142037</td>\n",
              "      <td>0.612431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.721700</td>\n",
              "      <td>0.720669</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.562134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.701500</td>\n",
              "      <td>0.704075</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.549528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.717400</td>\n",
              "      <td>0.702062</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.640988</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.671400</td>\n",
              "      <td>0.660553</td>\n",
              "      <td>0.626250</td>\n",
              "      <td>0.603974</td>\n",
              "      <td>0.625064</td>\n",
              "      <td>0.642254</td>\n",
              "      <td>0.570000</td>\n",
              "      <td>0.682500</td>\n",
              "      <td>0.254113</td>\n",
              "      <td>0.675894</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 200, total number of training (for each informative and uninform class) and test samples: 800, 6400 0.1 ALBERT-L 200 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [600/600 00:51, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.715700</td>\n",
              "      <td>0.695194</td>\n",
              "      <td>0.507500</td>\n",
              "      <td>0.660345</td>\n",
              "      <td>0.382445</td>\n",
              "      <td>0.503947</td>\n",
              "      <td>0.957500</td>\n",
              "      <td>0.057500</td>\n",
              "      <td>0.034412</td>\n",
              "      <td>0.553156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.698200</td>\n",
              "      <td>0.697004</td>\n",
              "      <td>0.512500</td>\n",
              "      <td>0.667802</td>\n",
              "      <td>0.376155</td>\n",
              "      <td>0.506460</td>\n",
              "      <td>0.980000</td>\n",
              "      <td>0.045000</td>\n",
              "      <td>0.070492</td>\n",
              "      <td>0.520656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.722300</td>\n",
              "      <td>0.693768</td>\n",
              "      <td>0.498750</td>\n",
              "      <td>0.665555</td>\n",
              "      <td>0.332777</td>\n",
              "      <td>0.499374</td>\n",
              "      <td>0.997500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.035377</td>\n",
              "      <td>0.565656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.705800</td>\n",
              "      <td>0.689414</td>\n",
              "      <td>0.533750</td>\n",
              "      <td>0.419907</td>\n",
              "      <td>0.515074</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.337500</td>\n",
              "      <td>0.730000</td>\n",
              "      <td>0.073389</td>\n",
              "      <td>0.502712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.696000</td>\n",
              "      <td>0.689326</td>\n",
              "      <td>0.542500</td>\n",
              "      <td>0.287938</td>\n",
              "      <td>0.475461</td>\n",
              "      <td>0.649123</td>\n",
              "      <td>0.185000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.121581</td>\n",
              "      <td>0.534322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.680700</td>\n",
              "      <td>0.670678</td>\n",
              "      <td>0.592500</td>\n",
              "      <td>0.513433</td>\n",
              "      <td>0.581448</td>\n",
              "      <td>0.637037</td>\n",
              "      <td>0.430000</td>\n",
              "      <td>0.755000</td>\n",
              "      <td>0.195619</td>\n",
              "      <td>0.646631</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 999, total number of training (for each informative and uninform class) and test samples: 800, 6400 0.1 ALBERT-L 999 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [600/600 00:51, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.703200</td>\n",
              "      <td>0.686150</td>\n",
              "      <td>0.491250</td>\n",
              "      <td>0.641410</td>\n",
              "      <td>0.383070</td>\n",
              "      <td>0.495238</td>\n",
              "      <td>0.910000</td>\n",
              "      <td>0.072500</td>\n",
              "      <td>-0.032026</td>\n",
              "      <td>0.549594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.692000</td>\n",
              "      <td>0.678974</td>\n",
              "      <td>0.590000</td>\n",
              "      <td>0.635556</td>\n",
              "      <td>0.583492</td>\n",
              "      <td>0.572000</td>\n",
              "      <td>0.715000</td>\n",
              "      <td>0.465000</td>\n",
              "      <td>0.185903</td>\n",
              "      <td>0.582031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.692800</td>\n",
              "      <td>0.690989</td>\n",
              "      <td>0.523750</td>\n",
              "      <td>0.653321</td>\n",
              "      <td>0.446421</td>\n",
              "      <td>0.513591</td>\n",
              "      <td>0.897500</td>\n",
              "      <td>0.150000</td>\n",
              "      <td>0.071508</td>\n",
              "      <td>0.546906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.691000</td>\n",
              "      <td>0.694946</td>\n",
              "      <td>0.498750</td>\n",
              "      <td>0.004963</td>\n",
              "      <td>0.334979</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.002500</td>\n",
              "      <td>0.995000</td>\n",
              "      <td>-0.020451</td>\n",
              "      <td>0.537212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.696100</td>\n",
              "      <td>0.699826</td>\n",
              "      <td>0.502500</td>\n",
              "      <td>0.485788</td>\n",
              "      <td>0.501974</td>\n",
              "      <td>0.502674</td>\n",
              "      <td>0.470000</td>\n",
              "      <td>0.535000</td>\n",
              "      <td>0.005011</td>\n",
              "      <td>0.491669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.682300</td>\n",
              "      <td>0.688014</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.589806</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5f1b990fa36548298bef01916594fc2a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4bfd014669cb4b87bcefd34d2ba7d8fd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "95bfc72abab04941b551e58a9c9ceb5b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8baa9e62c91d49fb8445f4f75c239047",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5f47edd349c44340b58eeaac00d13f02",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 94, total number of training (for each informative and uninform class) and test samples: 800, 6400 0.1 DISRoBERTa-B 94 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7f3e590700d94ddcbdbe95e3d948d751",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/331M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilbert/distilroberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [600/600 00:19, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.589700</td>\n",
              "      <td>0.576697</td>\n",
              "      <td>0.725000</td>\n",
              "      <td>0.734300</td>\n",
              "      <td>0.724663</td>\n",
              "      <td>0.710280</td>\n",
              "      <td>0.760000</td>\n",
              "      <td>0.690000</td>\n",
              "      <td>0.451107</td>\n",
              "      <td>0.784181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.482200</td>\n",
              "      <td>0.543370</td>\n",
              "      <td>0.740000</td>\n",
              "      <td>0.727749</td>\n",
              "      <td>0.739472</td>\n",
              "      <td>0.763736</td>\n",
              "      <td>0.695000</td>\n",
              "      <td>0.785000</td>\n",
              "      <td>0.481956</td>\n",
              "      <td>0.805519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.410500</td>\n",
              "      <td>0.797669</td>\n",
              "      <td>0.727500</td>\n",
              "      <td>0.677515</td>\n",
              "      <td>0.720792</td>\n",
              "      <td>0.829710</td>\n",
              "      <td>0.572500</td>\n",
              "      <td>0.882500</td>\n",
              "      <td>0.478576</td>\n",
              "      <td>0.813500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.151400</td>\n",
              "      <td>1.038863</td>\n",
              "      <td>0.743750</td>\n",
              "      <td>0.768884</td>\n",
              "      <td>0.740683</td>\n",
              "      <td>0.700205</td>\n",
              "      <td>0.852500</td>\n",
              "      <td>0.635000</td>\n",
              "      <td>0.499457</td>\n",
              "      <td>0.822006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.147800</td>\n",
              "      <td>1.191393</td>\n",
              "      <td>0.757500</td>\n",
              "      <td>0.771765</td>\n",
              "      <td>0.756549</td>\n",
              "      <td>0.728889</td>\n",
              "      <td>0.820000</td>\n",
              "      <td>0.695000</td>\n",
              "      <td>0.519071</td>\n",
              "      <td>0.816937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.110200</td>\n",
              "      <td>1.231004</td>\n",
              "      <td>0.758750</td>\n",
              "      <td>0.773740</td>\n",
              "      <td>0.757686</td>\n",
              "      <td>0.728477</td>\n",
              "      <td>0.825000</td>\n",
              "      <td>0.692500</td>\n",
              "      <td>0.522103</td>\n",
              "      <td>0.811937</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 791, total number of training (for each informative and uninform class) and test samples: 800, 6400 0.1 DISRoBERTa-B 791 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilbert/distilroberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [600/600 00:19, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.631700</td>\n",
              "      <td>0.604310</td>\n",
              "      <td>0.658750</td>\n",
              "      <td>0.680702</td>\n",
              "      <td>0.657129</td>\n",
              "      <td>0.639560</td>\n",
              "      <td>0.727500</td>\n",
              "      <td>0.590000</td>\n",
              "      <td>0.320545</td>\n",
              "      <td>0.741050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.427900</td>\n",
              "      <td>0.635577</td>\n",
              "      <td>0.707500</td>\n",
              "      <td>0.699229</td>\n",
              "      <td>0.707279</td>\n",
              "      <td>0.719577</td>\n",
              "      <td>0.680000</td>\n",
              "      <td>0.735000</td>\n",
              "      <td>0.415629</td>\n",
              "      <td>0.768613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.344800</td>\n",
              "      <td>0.805421</td>\n",
              "      <td>0.708750</td>\n",
              "      <td>0.725559</td>\n",
              "      <td>0.707653</td>\n",
              "      <td>0.685969</td>\n",
              "      <td>0.770000</td>\n",
              "      <td>0.647500</td>\n",
              "      <td>0.420668</td>\n",
              "      <td>0.785413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.233200</td>\n",
              "      <td>1.088984</td>\n",
              "      <td>0.718750</td>\n",
              "      <td>0.705111</td>\n",
              "      <td>0.718147</td>\n",
              "      <td>0.741047</td>\n",
              "      <td>0.672500</td>\n",
              "      <td>0.765000</td>\n",
              "      <td>0.439384</td>\n",
              "      <td>0.783119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.200100</td>\n",
              "      <td>1.259952</td>\n",
              "      <td>0.712500</td>\n",
              "      <td>0.729412</td>\n",
              "      <td>0.711373</td>\n",
              "      <td>0.688889</td>\n",
              "      <td>0.775000</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>0.428360</td>\n",
              "      <td>0.786463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.077200</td>\n",
              "      <td>1.298942</td>\n",
              "      <td>0.716250</td>\n",
              "      <td>0.722833</td>\n",
              "      <td>0.716090</td>\n",
              "      <td>0.706444</td>\n",
              "      <td>0.740000</td>\n",
              "      <td>0.692500</td>\n",
              "      <td>0.432989</td>\n",
              "      <td>0.786250</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 5, total number of training (for each informative and uninform class) and test samples: 800, 6400 0.1 DISRoBERTa-B 5 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilbert/distilroberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [600/600 00:19, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.534600</td>\n",
              "      <td>0.627613</td>\n",
              "      <td>0.670000</td>\n",
              "      <td>0.712418</td>\n",
              "      <td>0.662661</td>\n",
              "      <td>0.631274</td>\n",
              "      <td>0.817500</td>\n",
              "      <td>0.522500</td>\n",
              "      <td>0.355836</td>\n",
              "      <td>0.761112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.459600</td>\n",
              "      <td>0.614607</td>\n",
              "      <td>0.702500</td>\n",
              "      <td>0.705446</td>\n",
              "      <td>0.702470</td>\n",
              "      <td>0.698529</td>\n",
              "      <td>0.712500</td>\n",
              "      <td>0.692500</td>\n",
              "      <td>0.405081</td>\n",
              "      <td>0.791194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.400200</td>\n",
              "      <td>0.775045</td>\n",
              "      <td>0.727500</td>\n",
              "      <td>0.742925</td>\n",
              "      <td>0.726515</td>\n",
              "      <td>0.703125</td>\n",
              "      <td>0.787500</td>\n",
              "      <td>0.667500</td>\n",
              "      <td>0.458312</td>\n",
              "      <td>0.793200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.216700</td>\n",
              "      <td>1.240297</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.734513</td>\n",
              "      <td>0.694843</td>\n",
              "      <td>0.658730</td>\n",
              "      <td>0.830000</td>\n",
              "      <td>0.570000</td>\n",
              "      <td>0.414247</td>\n",
              "      <td>0.795038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.088400</td>\n",
              "      <td>1.386870</td>\n",
              "      <td>0.728750</td>\n",
              "      <td>0.743802</td>\n",
              "      <td>0.727811</td>\n",
              "      <td>0.704698</td>\n",
              "      <td>0.787500</td>\n",
              "      <td>0.670000</td>\n",
              "      <td>0.460691</td>\n",
              "      <td>0.796828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.127700</td>\n",
              "      <td>1.470526</td>\n",
              "      <td>0.727500</td>\n",
              "      <td>0.744131</td>\n",
              "      <td>0.726344</td>\n",
              "      <td>0.701327</td>\n",
              "      <td>0.792500</td>\n",
              "      <td>0.662500</td>\n",
              "      <td>0.458894</td>\n",
              "      <td>0.793331</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 6932, total number of training (for each informative and uninform class) and test samples: 800, 6400 0.1 DISRoBERTa-B 6932 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilbert/distilroberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [600/600 00:19, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.622400</td>\n",
              "      <td>0.577444</td>\n",
              "      <td>0.690000</td>\n",
              "      <td>0.722595</td>\n",
              "      <td>0.685660</td>\n",
              "      <td>0.653846</td>\n",
              "      <td>0.807500</td>\n",
              "      <td>0.572500</td>\n",
              "      <td>0.390948</td>\n",
              "      <td>0.775294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.483800</td>\n",
              "      <td>0.564765</td>\n",
              "      <td>0.730000</td>\n",
              "      <td>0.736585</td>\n",
              "      <td>0.729831</td>\n",
              "      <td>0.719048</td>\n",
              "      <td>0.755000</td>\n",
              "      <td>0.705000</td>\n",
              "      <td>0.460576</td>\n",
              "      <td>0.809594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.267300</td>\n",
              "      <td>0.809585</td>\n",
              "      <td>0.725000</td>\n",
              "      <td>0.705094</td>\n",
              "      <td>0.723741</td>\n",
              "      <td>0.760116</td>\n",
              "      <td>0.657500</td>\n",
              "      <td>0.792500</td>\n",
              "      <td>0.454158</td>\n",
              "      <td>0.812631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.178300</td>\n",
              "      <td>1.102619</td>\n",
              "      <td>0.733750</td>\n",
              "      <td>0.731400</td>\n",
              "      <td>0.733730</td>\n",
              "      <td>0.737913</td>\n",
              "      <td>0.725000</td>\n",
              "      <td>0.742500</td>\n",
              "      <td>0.467572</td>\n",
              "      <td>0.818069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.147700</td>\n",
              "      <td>1.362383</td>\n",
              "      <td>0.737500</td>\n",
              "      <td>0.739454</td>\n",
              "      <td>0.737485</td>\n",
              "      <td>0.733990</td>\n",
              "      <td>0.745000</td>\n",
              "      <td>0.730000</td>\n",
              "      <td>0.475053</td>\n",
              "      <td>0.816237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.098200</td>\n",
              "      <td>1.393902</td>\n",
              "      <td>0.735000</td>\n",
              "      <td>0.736318</td>\n",
              "      <td>0.734993</td>\n",
              "      <td>0.732673</td>\n",
              "      <td>0.740000</td>\n",
              "      <td>0.730000</td>\n",
              "      <td>0.470024</td>\n",
              "      <td>0.816281</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 1759, total number of training (for each informative and uninform class) and test samples: 800, 6400 0.1 DISRoBERTa-B 1759 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilbert/distilroberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [600/600 00:19, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.593100</td>\n",
              "      <td>0.608290</td>\n",
              "      <td>0.711250</td>\n",
              "      <td>0.708701</td>\n",
              "      <td>0.711228</td>\n",
              "      <td>0.715013</td>\n",
              "      <td>0.702500</td>\n",
              "      <td>0.720000</td>\n",
              "      <td>0.422565</td>\n",
              "      <td>0.776325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.486500</td>\n",
              "      <td>0.545714</td>\n",
              "      <td>0.728750</td>\n",
              "      <td>0.708725</td>\n",
              "      <td>0.727462</td>\n",
              "      <td>0.765217</td>\n",
              "      <td>0.660000</td>\n",
              "      <td>0.797500</td>\n",
              "      <td>0.461887</td>\n",
              "      <td>0.807781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.363200</td>\n",
              "      <td>0.904612</td>\n",
              "      <td>0.711250</td>\n",
              "      <td>0.749186</td>\n",
              "      <td>0.704490</td>\n",
              "      <td>0.662188</td>\n",
              "      <td>0.862500</td>\n",
              "      <td>0.560000</td>\n",
              "      <td>0.443267</td>\n",
              "      <td>0.816225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.203300</td>\n",
              "      <td>1.035665</td>\n",
              "      <td>0.757500</td>\n",
              "      <td>0.767386</td>\n",
              "      <td>0.757061</td>\n",
              "      <td>0.737327</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.715000</td>\n",
              "      <td>0.516871</td>\n",
              "      <td>0.815281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.147300</td>\n",
              "      <td>1.216461</td>\n",
              "      <td>0.752500</td>\n",
              "      <td>0.765403</td>\n",
              "      <td>0.751749</td>\n",
              "      <td>0.727477</td>\n",
              "      <td>0.807500</td>\n",
              "      <td>0.697500</td>\n",
              "      <td>0.508083</td>\n",
              "      <td>0.816537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.167500</td>\n",
              "      <td>1.314078</td>\n",
              "      <td>0.755000</td>\n",
              "      <td>0.768322</td>\n",
              "      <td>0.754187</td>\n",
              "      <td>0.728700</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.697500</td>\n",
              "      <td>0.513406</td>\n",
              "      <td>0.816600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 323, total number of training (for each informative and uninform class) and test samples: 800, 6400 0.1 DISRoBERTa-B 323 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilbert/distilroberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [600/600 00:19, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.664700</td>\n",
              "      <td>0.635927</td>\n",
              "      <td>0.642500</td>\n",
              "      <td>0.712274</td>\n",
              "      <td>0.620163</td>\n",
              "      <td>0.595960</td>\n",
              "      <td>0.885000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.325895</td>\n",
              "      <td>0.780125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.569400</td>\n",
              "      <td>0.545693</td>\n",
              "      <td>0.726250</td>\n",
              "      <td>0.740828</td>\n",
              "      <td>0.725381</td>\n",
              "      <td>0.703371</td>\n",
              "      <td>0.782500</td>\n",
              "      <td>0.670000</td>\n",
              "      <td>0.455391</td>\n",
              "      <td>0.806181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.398100</td>\n",
              "      <td>0.610775</td>\n",
              "      <td>0.730000</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.729958</td>\n",
              "      <td>0.724390</td>\n",
              "      <td>0.742500</td>\n",
              "      <td>0.717500</td>\n",
              "      <td>0.460144</td>\n",
              "      <td>0.813056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.286800</td>\n",
              "      <td>0.816798</td>\n",
              "      <td>0.746250</td>\n",
              "      <td>0.755716</td>\n",
              "      <td>0.745868</td>\n",
              "      <td>0.728538</td>\n",
              "      <td>0.785000</td>\n",
              "      <td>0.707500</td>\n",
              "      <td>0.493986</td>\n",
              "      <td>0.812931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.121200</td>\n",
              "      <td>1.064796</td>\n",
              "      <td>0.735000</td>\n",
              "      <td>0.755196</td>\n",
              "      <td>0.733184</td>\n",
              "      <td>0.701717</td>\n",
              "      <td>0.817500</td>\n",
              "      <td>0.652500</td>\n",
              "      <td>0.476532</td>\n",
              "      <td>0.817000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.119600</td>\n",
              "      <td>1.154116</td>\n",
              "      <td>0.738750</td>\n",
              "      <td>0.764374</td>\n",
              "      <td>0.735623</td>\n",
              "      <td>0.696099</td>\n",
              "      <td>0.847500</td>\n",
              "      <td>0.630000</td>\n",
              "      <td>0.489212</td>\n",
              "      <td>0.814050</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 1694, total number of training (for each informative and uninform class) and test samples: 800, 6400 0.1 DISRoBERTa-B 1694 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilbert/distilroberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [600/600 00:19, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.627400</td>\n",
              "      <td>0.624889</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.735099</td>\n",
              "      <td>0.694639</td>\n",
              "      <td>0.658103</td>\n",
              "      <td>0.832500</td>\n",
              "      <td>0.567500</td>\n",
              "      <td>0.414831</td>\n",
              "      <td>0.766550</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.555400</td>\n",
              "      <td>0.536880</td>\n",
              "      <td>0.728750</td>\n",
              "      <td>0.702332</td>\n",
              "      <td>0.726597</td>\n",
              "      <td>0.778116</td>\n",
              "      <td>0.640000</td>\n",
              "      <td>0.817500</td>\n",
              "      <td>0.464882</td>\n",
              "      <td>0.812269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.346200</td>\n",
              "      <td>0.665188</td>\n",
              "      <td>0.740000</td>\n",
              "      <td>0.741935</td>\n",
              "      <td>0.739985</td>\n",
              "      <td>0.736453</td>\n",
              "      <td>0.747500</td>\n",
              "      <td>0.732500</td>\n",
              "      <td>0.480054</td>\n",
              "      <td>0.818644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.236600</td>\n",
              "      <td>0.794864</td>\n",
              "      <td>0.755000</td>\n",
              "      <td>0.751269</td>\n",
              "      <td>0.754945</td>\n",
              "      <td>0.762887</td>\n",
              "      <td>0.740000</td>\n",
              "      <td>0.770000</td>\n",
              "      <td>0.510230</td>\n",
              "      <td>0.828119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.208600</td>\n",
              "      <td>1.030104</td>\n",
              "      <td>0.757500</td>\n",
              "      <td>0.777011</td>\n",
              "      <td>0.755629</td>\n",
              "      <td>0.719149</td>\n",
              "      <td>0.845000</td>\n",
              "      <td>0.670000</td>\n",
              "      <td>0.523072</td>\n",
              "      <td>0.829400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.047200</td>\n",
              "      <td>1.059247</td>\n",
              "      <td>0.757500</td>\n",
              "      <td>0.767386</td>\n",
              "      <td>0.757061</td>\n",
              "      <td>0.737327</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.715000</td>\n",
              "      <td>0.516871</td>\n",
              "      <td>0.830313</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 9741, total number of training (for each informative and uninform class) and test samples: 800, 6400 0.1 DISRoBERTa-B 9741 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilbert/distilroberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [600/600 00:19, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.673800</td>\n",
              "      <td>0.589806</td>\n",
              "      <td>0.707500</td>\n",
              "      <td>0.665714</td>\n",
              "      <td>0.702857</td>\n",
              "      <td>0.776667</td>\n",
              "      <td>0.582500</td>\n",
              "      <td>0.832500</td>\n",
              "      <td>0.428610</td>\n",
              "      <td>0.799944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.566200</td>\n",
              "      <td>0.672034</td>\n",
              "      <td>0.712500</td>\n",
              "      <td>0.652568</td>\n",
              "      <td>0.703683</td>\n",
              "      <td>0.824427</td>\n",
              "      <td>0.540000</td>\n",
              "      <td>0.885000</td>\n",
              "      <td>0.452801</td>\n",
              "      <td>0.826906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.331000</td>\n",
              "      <td>0.646930</td>\n",
              "      <td>0.761250</td>\n",
              "      <td>0.755442</td>\n",
              "      <td>0.761115</td>\n",
              "      <td>0.774278</td>\n",
              "      <td>0.737500</td>\n",
              "      <td>0.785000</td>\n",
              "      <td>0.523090</td>\n",
              "      <td>0.840775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.302500</td>\n",
              "      <td>1.090306</td>\n",
              "      <td>0.753750</td>\n",
              "      <td>0.749682</td>\n",
              "      <td>0.753685</td>\n",
              "      <td>0.762274</td>\n",
              "      <td>0.737500</td>\n",
              "      <td>0.770000</td>\n",
              "      <td>0.507768</td>\n",
              "      <td>0.829581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.203400</td>\n",
              "      <td>1.307474</td>\n",
              "      <td>0.752500</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.752475</td>\n",
              "      <td>0.757653</td>\n",
              "      <td>0.742500</td>\n",
              "      <td>0.762500</td>\n",
              "      <td>0.505101</td>\n",
              "      <td>0.828944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.102100</td>\n",
              "      <td>1.321956</td>\n",
              "      <td>0.743750</td>\n",
              "      <td>0.745973</td>\n",
              "      <td>0.743730</td>\n",
              "      <td>0.739558</td>\n",
              "      <td>0.752500</td>\n",
              "      <td>0.735000</td>\n",
              "      <td>0.487575</td>\n",
              "      <td>0.826562</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 200, total number of training (for each informative and uninform class) and test samples: 800, 6400 0.1 DISRoBERTa-B 200 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilbert/distilroberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [600/600 00:19, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.661800</td>\n",
              "      <td>0.609134</td>\n",
              "      <td>0.672500</td>\n",
              "      <td>0.732106</td>\n",
              "      <td>0.655442</td>\n",
              "      <td>0.619377</td>\n",
              "      <td>0.895000</td>\n",
              "      <td>0.450000</td>\n",
              "      <td>0.385246</td>\n",
              "      <td>0.768912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.492100</td>\n",
              "      <td>0.564426</td>\n",
              "      <td>0.710000</td>\n",
              "      <td>0.741071</td>\n",
              "      <td>0.705763</td>\n",
              "      <td>0.669355</td>\n",
              "      <td>0.830000</td>\n",
              "      <td>0.590000</td>\n",
              "      <td>0.432645</td>\n",
              "      <td>0.800450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.430100</td>\n",
              "      <td>0.728340</td>\n",
              "      <td>0.708750</td>\n",
              "      <td>0.691391</td>\n",
              "      <td>0.707826</td>\n",
              "      <td>0.735211</td>\n",
              "      <td>0.652500</td>\n",
              "      <td>0.765000</td>\n",
              "      <td>0.420167</td>\n",
              "      <td>0.802119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.145700</td>\n",
              "      <td>1.063259</td>\n",
              "      <td>0.708750</td>\n",
              "      <td>0.746464</td>\n",
              "      <td>0.702160</td>\n",
              "      <td>0.660886</td>\n",
              "      <td>0.857500</td>\n",
              "      <td>0.560000</td>\n",
              "      <td>0.437300</td>\n",
              "      <td>0.808025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.150600</td>\n",
              "      <td>1.229507</td>\n",
              "      <td>0.728750</td>\n",
              "      <td>0.723567</td>\n",
              "      <td>0.728655</td>\n",
              "      <td>0.737662</td>\n",
              "      <td>0.710000</td>\n",
              "      <td>0.747500</td>\n",
              "      <td>0.457822</td>\n",
              "      <td>0.808331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.040200</td>\n",
              "      <td>1.300623</td>\n",
              "      <td>0.722500</td>\n",
              "      <td>0.727941</td>\n",
              "      <td>0.722389</td>\n",
              "      <td>0.713942</td>\n",
              "      <td>0.742500</td>\n",
              "      <td>0.702500</td>\n",
              "      <td>0.445356</td>\n",
              "      <td>0.810712</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 999, total number of training (for each informative and uninform class) and test samples: 800, 6400 0.1 DISRoBERTa-B 999 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilbert/distilroberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [600/600 00:19, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.636600</td>\n",
              "      <td>0.620829</td>\n",
              "      <td>0.648750</td>\n",
              "      <td>0.717019</td>\n",
              "      <td>0.627043</td>\n",
              "      <td>0.600337</td>\n",
              "      <td>0.890000</td>\n",
              "      <td>0.407500</td>\n",
              "      <td>0.339652</td>\n",
              "      <td>0.755056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.536100</td>\n",
              "      <td>0.583918</td>\n",
              "      <td>0.711250</td>\n",
              "      <td>0.729825</td>\n",
              "      <td>0.709879</td>\n",
              "      <td>0.685714</td>\n",
              "      <td>0.780000</td>\n",
              "      <td>0.642500</td>\n",
              "      <td>0.426551</td>\n",
              "      <td>0.791469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.423700</td>\n",
              "      <td>0.756567</td>\n",
              "      <td>0.717500</td>\n",
              "      <td>0.713198</td>\n",
              "      <td>0.717436</td>\n",
              "      <td>0.724227</td>\n",
              "      <td>0.702500</td>\n",
              "      <td>0.732500</td>\n",
              "      <td>0.435196</td>\n",
              "      <td>0.790088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.353600</td>\n",
              "      <td>0.992396</td>\n",
              "      <td>0.721250</td>\n",
              "      <td>0.746879</td>\n",
              "      <td>0.718363</td>\n",
              "      <td>0.683992</td>\n",
              "      <td>0.822500</td>\n",
              "      <td>0.620000</td>\n",
              "      <td>0.451862</td>\n",
              "      <td>0.791131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.210500</td>\n",
              "      <td>1.111217</td>\n",
              "      <td>0.727500</td>\n",
              "      <td>0.745327</td>\n",
              "      <td>0.726158</td>\n",
              "      <td>0.699561</td>\n",
              "      <td>0.797500</td>\n",
              "      <td>0.657500</td>\n",
              "      <td>0.459526</td>\n",
              "      <td>0.792612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.083800</td>\n",
              "      <td>1.266050</td>\n",
              "      <td>0.725000</td>\n",
              "      <td>0.742389</td>\n",
              "      <td>0.723741</td>\n",
              "      <td>0.698238</td>\n",
              "      <td>0.792500</td>\n",
              "      <td>0.657500</td>\n",
              "      <td>0.454158</td>\n",
              "      <td>0.788725</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cedf7dbcf69f4b638f09ec52c63db6e2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/760 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4a0cccc528984fbf80eda3970ca3f4dd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "spiece.model:   0%|          | 0.00/798k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "233172b9ba5047a5951529fd5d83376d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.38M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 94, total number of training (for each informative and uninform class) and test samples: 800, 6400 0.1 XLNet-B 94 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "217ea26d6e6248e59bc66698ce28b88e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/467M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [600/600 00:51, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.648700</td>\n",
              "      <td>0.605962</td>\n",
              "      <td>0.662500</td>\n",
              "      <td>0.654731</td>\n",
              "      <td>0.662329</td>\n",
              "      <td>0.670157</td>\n",
              "      <td>0.640000</td>\n",
              "      <td>0.685000</td>\n",
              "      <td>0.325330</td>\n",
              "      <td>0.720750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.560400</td>\n",
              "      <td>0.576546</td>\n",
              "      <td>0.707500</td>\n",
              "      <td>0.717391</td>\n",
              "      <td>0.707141</td>\n",
              "      <td>0.693925</td>\n",
              "      <td>0.742500</td>\n",
              "      <td>0.672500</td>\n",
              "      <td>0.416021</td>\n",
              "      <td>0.765450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.511000</td>\n",
              "      <td>0.643217</td>\n",
              "      <td>0.725000</td>\n",
              "      <td>0.715026</td>\n",
              "      <td>0.724663</td>\n",
              "      <td>0.741935</td>\n",
              "      <td>0.690000</td>\n",
              "      <td>0.760000</td>\n",
              "      <td>0.451107</td>\n",
              "      <td>0.782412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.286300</td>\n",
              "      <td>1.050414</td>\n",
              "      <td>0.703750</td>\n",
              "      <td>0.745981</td>\n",
              "      <td>0.695329</td>\n",
              "      <td>0.652908</td>\n",
              "      <td>0.870000</td>\n",
              "      <td>0.537500</td>\n",
              "      <td>0.432084</td>\n",
              "      <td>0.803100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.151600</td>\n",
              "      <td>1.463386</td>\n",
              "      <td>0.702500</td>\n",
              "      <td>0.746809</td>\n",
              "      <td>0.693101</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>0.877500</td>\n",
              "      <td>0.527500</td>\n",
              "      <td>0.432346</td>\n",
              "      <td>0.806688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.068800</td>\n",
              "      <td>1.334714</td>\n",
              "      <td>0.728750</td>\n",
              "      <td>0.758082</td>\n",
              "      <td>0.724703</td>\n",
              "      <td>0.684105</td>\n",
              "      <td>0.850000</td>\n",
              "      <td>0.607500</td>\n",
              "      <td>0.471576</td>\n",
              "      <td>0.811531</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 791, total number of training (for each informative and uninform class) and test samples: 800, 6400 0.1 XLNet-B 791 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [600/600 00:51, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.664900</td>\n",
              "      <td>0.653633</td>\n",
              "      <td>0.615000</td>\n",
              "      <td>0.696252</td>\n",
              "      <td>0.585328</td>\n",
              "      <td>0.574919</td>\n",
              "      <td>0.882500</td>\n",
              "      <td>0.347500</td>\n",
              "      <td>0.272237</td>\n",
              "      <td>0.720750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.537700</td>\n",
              "      <td>0.650586</td>\n",
              "      <td>0.685000</td>\n",
              "      <td>0.688889</td>\n",
              "      <td>0.684951</td>\n",
              "      <td>0.680488</td>\n",
              "      <td>0.697500</td>\n",
              "      <td>0.672500</td>\n",
              "      <td>0.370116</td>\n",
              "      <td>0.757431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.455600</td>\n",
              "      <td>0.657822</td>\n",
              "      <td>0.713750</td>\n",
              "      <td>0.699869</td>\n",
              "      <td>0.713136</td>\n",
              "      <td>0.735537</td>\n",
              "      <td>0.667500</td>\n",
              "      <td>0.760000</td>\n",
              "      <td>0.429341</td>\n",
              "      <td>0.782194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.291700</td>\n",
              "      <td>1.051571</td>\n",
              "      <td>0.715000</td>\n",
              "      <td>0.698413</td>\n",
              "      <td>0.714135</td>\n",
              "      <td>0.741573</td>\n",
              "      <td>0.660000</td>\n",
              "      <td>0.770000</td>\n",
              "      <td>0.432625</td>\n",
              "      <td>0.771794</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.294400</td>\n",
              "      <td>1.342230</td>\n",
              "      <td>0.715000</td>\n",
              "      <td>0.706186</td>\n",
              "      <td>0.714743</td>\n",
              "      <td>0.728723</td>\n",
              "      <td>0.685000</td>\n",
              "      <td>0.745000</td>\n",
              "      <td>0.430776</td>\n",
              "      <td>0.774181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.097200</td>\n",
              "      <td>1.502721</td>\n",
              "      <td>0.713750</td>\n",
              "      <td>0.732164</td>\n",
              "      <td>0.712391</td>\n",
              "      <td>0.687912</td>\n",
              "      <td>0.782500</td>\n",
              "      <td>0.645000</td>\n",
              "      <td>0.431599</td>\n",
              "      <td>0.774550</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 5, total number of training (for each informative and uninform class) and test samples: 800, 6400 0.1 XLNet-B 5 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [600/600 00:52, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.598400</td>\n",
              "      <td>0.735183</td>\n",
              "      <td>0.623750</td>\n",
              "      <td>0.698699</td>\n",
              "      <td>0.598933</td>\n",
              "      <td>0.582638</td>\n",
              "      <td>0.872500</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.285314</td>\n",
              "      <td>0.730800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.468900</td>\n",
              "      <td>0.604744</td>\n",
              "      <td>0.706250</td>\n",
              "      <td>0.718563</td>\n",
              "      <td>0.705687</td>\n",
              "      <td>0.689655</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.662500</td>\n",
              "      <td>0.414088</td>\n",
              "      <td>0.779931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.442200</td>\n",
              "      <td>0.788764</td>\n",
              "      <td>0.705000</td>\n",
              "      <td>0.724942</td>\n",
              "      <td>0.703441</td>\n",
              "      <td>0.679039</td>\n",
              "      <td>0.777500</td>\n",
              "      <td>0.632500</td>\n",
              "      <td>0.414379</td>\n",
              "      <td>0.785937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.193800</td>\n",
              "      <td>1.413667</td>\n",
              "      <td>0.695000</td>\n",
              "      <td>0.733624</td>\n",
              "      <td>0.688450</td>\n",
              "      <td>0.651163</td>\n",
              "      <td>0.840000</td>\n",
              "      <td>0.550000</td>\n",
              "      <td>0.407512</td>\n",
              "      <td>0.780481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.110600</td>\n",
              "      <td>1.618476</td>\n",
              "      <td>0.716250</td>\n",
              "      <td>0.733880</td>\n",
              "      <td>0.714999</td>\n",
              "      <td>0.690949</td>\n",
              "      <td>0.782500</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>0.436347</td>\n",
              "      <td>0.785937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.055000</td>\n",
              "      <td>1.762314</td>\n",
              "      <td>0.715000</td>\n",
              "      <td>0.735499</td>\n",
              "      <td>0.713278</td>\n",
              "      <td>0.686147</td>\n",
              "      <td>0.792500</td>\n",
              "      <td>0.637500</td>\n",
              "      <td>0.435260</td>\n",
              "      <td>0.780956</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 6932, total number of training (for each informative and uninform class) and test samples: 800, 6400 0.1 XLNet-B 6932 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [600/600 00:52, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.663500</td>\n",
              "      <td>0.620763</td>\n",
              "      <td>0.652500</td>\n",
              "      <td>0.655087</td>\n",
              "      <td>0.652480</td>\n",
              "      <td>0.650246</td>\n",
              "      <td>0.660000</td>\n",
              "      <td>0.645000</td>\n",
              "      <td>0.305034</td>\n",
              "      <td>0.710281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.609800</td>\n",
              "      <td>0.621950</td>\n",
              "      <td>0.690000</td>\n",
              "      <td>0.732181</td>\n",
              "      <td>0.682114</td>\n",
              "      <td>0.644487</td>\n",
              "      <td>0.847500</td>\n",
              "      <td>0.532500</td>\n",
              "      <td>0.400383</td>\n",
              "      <td>0.756412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.412200</td>\n",
              "      <td>0.776383</td>\n",
              "      <td>0.702500</td>\n",
              "      <td>0.679245</td>\n",
              "      <td>0.700928</td>\n",
              "      <td>0.736842</td>\n",
              "      <td>0.630000</td>\n",
              "      <td>0.775000</td>\n",
              "      <td>0.409326</td>\n",
              "      <td>0.773144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.229100</td>\n",
              "      <td>1.103872</td>\n",
              "      <td>0.682500</td>\n",
              "      <td>0.723913</td>\n",
              "      <td>0.675192</td>\n",
              "      <td>0.640385</td>\n",
              "      <td>0.832500</td>\n",
              "      <td>0.532500</td>\n",
              "      <td>0.382624</td>\n",
              "      <td>0.780738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.260900</td>\n",
              "      <td>1.574633</td>\n",
              "      <td>0.696250</td>\n",
              "      <td>0.738428</td>\n",
              "      <td>0.688141</td>\n",
              "      <td>0.648393</td>\n",
              "      <td>0.857500</td>\n",
              "      <td>0.535000</td>\n",
              "      <td>0.414655</td>\n",
              "      <td>0.784450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.138400</td>\n",
              "      <td>1.614281</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.730942</td>\n",
              "      <td>0.695979</td>\n",
              "      <td>0.662602</td>\n",
              "      <td>0.815000</td>\n",
              "      <td>0.585000</td>\n",
              "      <td>0.411019</td>\n",
              "      <td>0.785250</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 1759, total number of training (for each informative and uninform class) and test samples: 800, 6400 0.1 XLNet-B 1759 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [600/600 00:52, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.628100</td>\n",
              "      <td>0.658249</td>\n",
              "      <td>0.645000</td>\n",
              "      <td>0.708419</td>\n",
              "      <td>0.627372</td>\n",
              "      <td>0.601045</td>\n",
              "      <td>0.862500</td>\n",
              "      <td>0.427500</td>\n",
              "      <td>0.322068</td>\n",
              "      <td>0.753262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.615000</td>\n",
              "      <td>0.584284</td>\n",
              "      <td>0.702500</td>\n",
              "      <td>0.719340</td>\n",
              "      <td>0.701425</td>\n",
              "      <td>0.680804</td>\n",
              "      <td>0.762500</td>\n",
              "      <td>0.642500</td>\n",
              "      <td>0.407948</td>\n",
              "      <td>0.772731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.587700</td>\n",
              "      <td>1.042761</td>\n",
              "      <td>0.635000</td>\n",
              "      <td>0.721374</td>\n",
              "      <td>0.596194</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.945000</td>\n",
              "      <td>0.325000</td>\n",
              "      <td>0.344124</td>\n",
              "      <td>0.779894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.393900</td>\n",
              "      <td>0.812984</td>\n",
              "      <td>0.741250</td>\n",
              "      <td>0.744129</td>\n",
              "      <td>0.741217</td>\n",
              "      <td>0.735941</td>\n",
              "      <td>0.752500</td>\n",
              "      <td>0.730000</td>\n",
              "      <td>0.482622</td>\n",
              "      <td>0.801181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.186100</td>\n",
              "      <td>1.156335</td>\n",
              "      <td>0.731250</td>\n",
              "      <td>0.752018</td>\n",
              "      <td>0.729352</td>\n",
              "      <td>0.698073</td>\n",
              "      <td>0.815000</td>\n",
              "      <td>0.647500</td>\n",
              "      <td>0.469128</td>\n",
              "      <td>0.805125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.326600</td>\n",
              "      <td>1.424656</td>\n",
              "      <td>0.721250</td>\n",
              "      <td>0.748023</td>\n",
              "      <td>0.718067</td>\n",
              "      <td>0.682474</td>\n",
              "      <td>0.827500</td>\n",
              "      <td>0.615000</td>\n",
              "      <td>0.452842</td>\n",
              "      <td>0.804331</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 323, total number of training (for each informative and uninform class) and test samples: 800, 6400 0.1 XLNet-B 323 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [600/600 00:52, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.708400</td>\n",
              "      <td>0.659539</td>\n",
              "      <td>0.606250</td>\n",
              "      <td>0.705332</td>\n",
              "      <td>0.556056</td>\n",
              "      <td>0.563528</td>\n",
              "      <td>0.942500</td>\n",
              "      <td>0.270000</td>\n",
              "      <td>0.287124</td>\n",
              "      <td>0.753531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.657100</td>\n",
              "      <td>0.584667</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>0.720982</td>\n",
              "      <td>0.682934</td>\n",
              "      <td>0.651210</td>\n",
              "      <td>0.807500</td>\n",
              "      <td>0.567500</td>\n",
              "      <td>0.386290</td>\n",
              "      <td>0.776975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.508200</td>\n",
              "      <td>0.579781</td>\n",
              "      <td>0.736250</td>\n",
              "      <td>0.746089</td>\n",
              "      <td>0.735853</td>\n",
              "      <td>0.719258</td>\n",
              "      <td>0.775000</td>\n",
              "      <td>0.697500</td>\n",
              "      <td>0.473925</td>\n",
              "      <td>0.802631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.552000</td>\n",
              "      <td>0.818168</td>\n",
              "      <td>0.728750</td>\n",
              "      <td>0.740741</td>\n",
              "      <td>0.728169</td>\n",
              "      <td>0.709382</td>\n",
              "      <td>0.775000</td>\n",
              "      <td>0.682500</td>\n",
              "      <td>0.459470</td>\n",
              "      <td>0.792950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.215600</td>\n",
              "      <td>1.221884</td>\n",
              "      <td>0.726250</td>\n",
              "      <td>0.745645</td>\n",
              "      <td>0.724649</td>\n",
              "      <td>0.696312</td>\n",
              "      <td>0.802500</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>0.457855</td>\n",
              "      <td>0.785438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.119100</td>\n",
              "      <td>1.300447</td>\n",
              "      <td>0.723750</td>\n",
              "      <td>0.742724</td>\n",
              "      <td>0.722239</td>\n",
              "      <td>0.694989</td>\n",
              "      <td>0.797500</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>0.452449</td>\n",
              "      <td>0.788744</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 1694, total number of training (for each informative and uninform class) and test samples: 800, 6400 0.1 XLNet-B 1694 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [600/600 00:52, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.685598</td>\n",
              "      <td>0.575000</td>\n",
              "      <td>0.395018</td>\n",
              "      <td>0.533732</td>\n",
              "      <td>0.685185</td>\n",
              "      <td>0.277500</td>\n",
              "      <td>0.872500</td>\n",
              "      <td>0.186631</td>\n",
              "      <td>0.602125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.663500</td>\n",
              "      <td>0.619381</td>\n",
              "      <td>0.655000</td>\n",
              "      <td>0.629032</td>\n",
              "      <td>0.653301</td>\n",
              "      <td>0.680233</td>\n",
              "      <td>0.585000</td>\n",
              "      <td>0.725000</td>\n",
              "      <td>0.313083</td>\n",
              "      <td>0.720081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.560000</td>\n",
              "      <td>0.595318</td>\n",
              "      <td>0.706250</td>\n",
              "      <td>0.729574</td>\n",
              "      <td>0.704048</td>\n",
              "      <td>0.675906</td>\n",
              "      <td>0.792500</td>\n",
              "      <td>0.620000</td>\n",
              "      <td>0.418778</td>\n",
              "      <td>0.767956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.426700</td>\n",
              "      <td>0.606440</td>\n",
              "      <td>0.713750</td>\n",
              "      <td>0.725090</td>\n",
              "      <td>0.713262</td>\n",
              "      <td>0.697460</td>\n",
              "      <td>0.755000</td>\n",
              "      <td>0.672500</td>\n",
              "      <td>0.428962</td>\n",
              "      <td>0.793519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.470200</td>\n",
              "      <td>0.782624</td>\n",
              "      <td>0.723750</td>\n",
              "      <td>0.758470</td>\n",
              "      <td>0.717921</td>\n",
              "      <td>0.673786</td>\n",
              "      <td>0.867500</td>\n",
              "      <td>0.580000</td>\n",
              "      <td>0.467226</td>\n",
              "      <td>0.802256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.277800</td>\n",
              "      <td>0.776386</td>\n",
              "      <td>0.747500</td>\n",
              "      <td>0.760095</td>\n",
              "      <td>0.746802</td>\n",
              "      <td>0.723982</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.695000</td>\n",
              "      <td>0.497751</td>\n",
              "      <td>0.803288</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 9741, total number of training (for each informative and uninform class) and test samples: 800, 6400 0.1 XLNet-B 9741 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [600/600 00:52, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.709300</td>\n",
              "      <td>0.637335</td>\n",
              "      <td>0.626250</td>\n",
              "      <td>0.457350</td>\n",
              "      <td>0.586158</td>\n",
              "      <td>0.834437</td>\n",
              "      <td>0.315000</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.322634</td>\n",
              "      <td>0.740187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.618900</td>\n",
              "      <td>0.588724</td>\n",
              "      <td>0.686250</td>\n",
              "      <td>0.615620</td>\n",
              "      <td>0.675286</td>\n",
              "      <td>0.794466</td>\n",
              "      <td>0.502500</td>\n",
              "      <td>0.870000</td>\n",
              "      <td>0.400528</td>\n",
              "      <td>0.779713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.376000</td>\n",
              "      <td>0.632773</td>\n",
              "      <td>0.737500</td>\n",
              "      <td>0.746377</td>\n",
              "      <td>0.737178</td>\n",
              "      <td>0.721963</td>\n",
              "      <td>0.772500</td>\n",
              "      <td>0.702500</td>\n",
              "      <td>0.476168</td>\n",
              "      <td>0.813031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.306700</td>\n",
              "      <td>0.848154</td>\n",
              "      <td>0.740000</td>\n",
              "      <td>0.752381</td>\n",
              "      <td>0.739348</td>\n",
              "      <td>0.718182</td>\n",
              "      <td>0.790000</td>\n",
              "      <td>0.690000</td>\n",
              "      <td>0.482418</td>\n",
              "      <td>0.819781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.275500</td>\n",
              "      <td>1.062299</td>\n",
              "      <td>0.740000</td>\n",
              "      <td>0.747573</td>\n",
              "      <td>0.739766</td>\n",
              "      <td>0.726415</td>\n",
              "      <td>0.770000</td>\n",
              "      <td>0.710000</td>\n",
              "      <td>0.480866</td>\n",
              "      <td>0.814350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.139400</td>\n",
              "      <td>1.118843</td>\n",
              "      <td>0.745000</td>\n",
              "      <td>0.748148</td>\n",
              "      <td>0.744960</td>\n",
              "      <td>0.739024</td>\n",
              "      <td>0.757500</td>\n",
              "      <td>0.732500</td>\n",
              "      <td>0.490153</td>\n",
              "      <td>0.816813</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 200, total number of training (for each informative and uninform class) and test samples: 800, 6400 0.1 XLNet-B 200 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [600/600 00:52, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.638600</td>\n",
              "      <td>0.628290</td>\n",
              "      <td>0.668750</td>\n",
              "      <td>0.640434</td>\n",
              "      <td>0.666683</td>\n",
              "      <td>0.700297</td>\n",
              "      <td>0.590000</td>\n",
              "      <td>0.747500</td>\n",
              "      <td>0.341766</td>\n",
              "      <td>0.734619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.556400</td>\n",
              "      <td>0.615282</td>\n",
              "      <td>0.668750</td>\n",
              "      <td>0.729867</td>\n",
              "      <td>0.650879</td>\n",
              "      <td>0.616179</td>\n",
              "      <td>0.895000</td>\n",
              "      <td>0.442500</td>\n",
              "      <td>0.378463</td>\n",
              "      <td>0.787375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.397200</td>\n",
              "      <td>0.648167</td>\n",
              "      <td>0.702500</td>\n",
              "      <td>0.737307</td>\n",
              "      <td>0.697184</td>\n",
              "      <td>0.660079</td>\n",
              "      <td>0.835000</td>\n",
              "      <td>0.570000</td>\n",
              "      <td>0.420016</td>\n",
              "      <td>0.806150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.249100</td>\n",
              "      <td>1.127422</td>\n",
              "      <td>0.697500</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.687078</td>\n",
              "      <td>0.644689</td>\n",
              "      <td>0.880000</td>\n",
              "      <td>0.515000</td>\n",
              "      <td>0.424272</td>\n",
              "      <td>0.805500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.119000</td>\n",
              "      <td>1.205137</td>\n",
              "      <td>0.723750</td>\n",
              "      <td>0.744509</td>\n",
              "      <td>0.721914</td>\n",
              "      <td>0.692473</td>\n",
              "      <td>0.805000</td>\n",
              "      <td>0.642500</td>\n",
              "      <td>0.453528</td>\n",
              "      <td>0.811794</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.157200</td>\n",
              "      <td>1.461708</td>\n",
              "      <td>0.710000</td>\n",
              "      <td>0.739326</td>\n",
              "      <td>0.706283</td>\n",
              "      <td>0.671429</td>\n",
              "      <td>0.822500</td>\n",
              "      <td>0.597500</td>\n",
              "      <td>0.431053</td>\n",
              "      <td>0.808956</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 999, total number of training (for each informative and uninform class) and test samples: 800, 6400 0.1 XLNet-B 999 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [600/600 00:52, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.673600</td>\n",
              "      <td>0.664845</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.678068</td>\n",
              "      <td>0.575008</td>\n",
              "      <td>0.567340</td>\n",
              "      <td>0.842500</td>\n",
              "      <td>0.357500</td>\n",
              "      <td>0.228698</td>\n",
              "      <td>0.692038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.645500</td>\n",
              "      <td>0.622262</td>\n",
              "      <td>0.671250</td>\n",
              "      <td>0.619392</td>\n",
              "      <td>0.665032</td>\n",
              "      <td>0.735395</td>\n",
              "      <td>0.535000</td>\n",
              "      <td>0.807500</td>\n",
              "      <td>0.355971</td>\n",
              "      <td>0.740706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.614900</td>\n",
              "      <td>0.724333</td>\n",
              "      <td>0.691250</td>\n",
              "      <td>0.649645</td>\n",
              "      <td>0.686834</td>\n",
              "      <td>0.750820</td>\n",
              "      <td>0.572500</td>\n",
              "      <td>0.810000</td>\n",
              "      <td>0.393767</td>\n",
              "      <td>0.766119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.361300</td>\n",
              "      <td>0.727561</td>\n",
              "      <td>0.710000</td>\n",
              "      <td>0.704835</td>\n",
              "      <td>0.709911</td>\n",
              "      <td>0.717617</td>\n",
              "      <td>0.692500</td>\n",
              "      <td>0.727500</td>\n",
              "      <td>0.420257</td>\n",
              "      <td>0.774406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.238700</td>\n",
              "      <td>0.908778</td>\n",
              "      <td>0.716250</td>\n",
              "      <td>0.712294</td>\n",
              "      <td>0.716196</td>\n",
              "      <td>0.722365</td>\n",
              "      <td>0.702500</td>\n",
              "      <td>0.730000</td>\n",
              "      <td>0.432664</td>\n",
              "      <td>0.788988</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.105400</td>\n",
              "      <td>1.016728</td>\n",
              "      <td>0.708750</td>\n",
              "      <td>0.709114</td>\n",
              "      <td>0.708750</td>\n",
              "      <td>0.708229</td>\n",
              "      <td>0.710000</td>\n",
              "      <td>0.707500</td>\n",
              "      <td>0.417501</td>\n",
              "      <td>0.785719</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b7acdddd9d744d8d85e99121ff957c50",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/761 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "11d7e1ec7a84467babc54e1e9effe0e0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "spiece.model:   0%|          | 0.00/798k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a1387f79961d4a4fb08eaa00e6323414",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.38M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 94, total number of training (for each informative and uninform class) and test samples: 800, 6400 0.1 XLNet-L 94 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "083b3bc771aa4c3d9ca2847d32979ab4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/1.44G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-large-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [600/600 01:42, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.702800</td>\n",
              "      <td>0.705621</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.004975</td>\n",
              "      <td>0.335543</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.002500</td>\n",
              "      <td>0.997500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.542747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.698600</td>\n",
              "      <td>0.693613</td>\n",
              "      <td>0.501250</td>\n",
              "      <td>0.664987</td>\n",
              "      <td>0.344719</td>\n",
              "      <td>0.500632</td>\n",
              "      <td>0.990000</td>\n",
              "      <td>0.012500</td>\n",
              "      <td>0.011852</td>\n",
              "      <td>0.585216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.705200</td>\n",
              "      <td>0.691392</td>\n",
              "      <td>0.507500</td>\n",
              "      <td>0.663248</td>\n",
              "      <td>0.373484</td>\n",
              "      <td>0.503896</td>\n",
              "      <td>0.970000</td>\n",
              "      <td>0.045000</td>\n",
              "      <td>0.039477</td>\n",
              "      <td>0.606775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.678800</td>\n",
              "      <td>0.669797</td>\n",
              "      <td>0.588750</td>\n",
              "      <td>0.624000</td>\n",
              "      <td>0.585103</td>\n",
              "      <td>0.574737</td>\n",
              "      <td>0.682500</td>\n",
              "      <td>0.495000</td>\n",
              "      <td>0.180705</td>\n",
              "      <td>0.644656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.639100</td>\n",
              "      <td>0.655864</td>\n",
              "      <td>0.616250</td>\n",
              "      <td>0.648339</td>\n",
              "      <td>0.613028</td>\n",
              "      <td>0.598309</td>\n",
              "      <td>0.707500</td>\n",
              "      <td>0.525000</td>\n",
              "      <td>0.236471</td>\n",
              "      <td>0.673825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.622900</td>\n",
              "      <td>0.733955</td>\n",
              "      <td>0.617500</td>\n",
              "      <td>0.623153</td>\n",
              "      <td>0.617414</td>\n",
              "      <td>0.614078</td>\n",
              "      <td>0.632500</td>\n",
              "      <td>0.602500</td>\n",
              "      <td>0.235106</td>\n",
              "      <td>0.677200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 791, total number of training (for each informative and uninform class) and test samples: 800, 6400 0.1 XLNet-L 791 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-large-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [600/600 01:41, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.707000</td>\n",
              "      <td>0.747624</td>\n",
              "      <td>0.520000</td>\n",
              "      <td>0.672913</td>\n",
              "      <td>0.385752</td>\n",
              "      <td>0.510336</td>\n",
              "      <td>0.987500</td>\n",
              "      <td>0.052500</td>\n",
              "      <td>0.112788</td>\n",
              "      <td>0.627541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.585900</td>\n",
              "      <td>0.651022</td>\n",
              "      <td>0.641250</td>\n",
              "      <td>0.679330</td>\n",
              "      <td>0.636119</td>\n",
              "      <td>0.614141</td>\n",
              "      <td>0.760000</td>\n",
              "      <td>0.522500</td>\n",
              "      <td>0.290821</td>\n",
              "      <td>0.713337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.559800</td>\n",
              "      <td>0.754598</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.575071</td>\n",
              "      <td>0.619750</td>\n",
              "      <td>0.663399</td>\n",
              "      <td>0.507500</td>\n",
              "      <td>0.742500</td>\n",
              "      <td>0.257203</td>\n",
              "      <td>0.697631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.409700</td>\n",
              "      <td>0.772767</td>\n",
              "      <td>0.665000</td>\n",
              "      <td>0.597598</td>\n",
              "      <td>0.655330</td>\n",
              "      <td>0.748120</td>\n",
              "      <td>0.497500</td>\n",
              "      <td>0.832500</td>\n",
              "      <td>0.350237</td>\n",
              "      <td>0.743944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.377400</td>\n",
              "      <td>1.035045</td>\n",
              "      <td>0.647500</td>\n",
              "      <td>0.660241</td>\n",
              "      <td>0.647004</td>\n",
              "      <td>0.637209</td>\n",
              "      <td>0.685000</td>\n",
              "      <td>0.610000</td>\n",
              "      <td>0.295833</td>\n",
              "      <td>0.737831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.235500</td>\n",
              "      <td>1.090964</td>\n",
              "      <td>0.671250</td>\n",
              "      <td>0.676507</td>\n",
              "      <td>0.671163</td>\n",
              "      <td>0.665860</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>0.655000</td>\n",
              "      <td>0.342681</td>\n",
              "      <td>0.750787</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 5, total number of training (for each informative and uninform class) and test samples: 800, 6400 0.1 XLNet-L 5 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-large-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [600/600 01:43, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.737500</td>\n",
              "      <td>0.697426</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.459750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.709500</td>\n",
              "      <td>0.703606</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.459075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.712200</td>\n",
              "      <td>0.693604</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.494356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.724500</td>\n",
              "      <td>0.698802</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.445406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.705800</td>\n",
              "      <td>0.710195</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.572450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.723500</td>\n",
              "      <td>0.707210</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.585147</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 6932, total number of training (for each informative and uninform class) and test samples: 800, 6400 0.1 XLNet-L 6932 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-large-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [600/600 01:42, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.770100</td>\n",
              "      <td>0.672042</td>\n",
              "      <td>0.565000</td>\n",
              "      <td>0.644172</td>\n",
              "      <td>0.542343</td>\n",
              "      <td>0.544983</td>\n",
              "      <td>0.787500</td>\n",
              "      <td>0.342500</td>\n",
              "      <td>0.145165</td>\n",
              "      <td>0.655181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.648000</td>\n",
              "      <td>0.629645</td>\n",
              "      <td>0.637500</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0.637418</td>\n",
              "      <td>0.633495</td>\n",
              "      <td>0.652500</td>\n",
              "      <td>0.622500</td>\n",
              "      <td>0.275124</td>\n",
              "      <td>0.713163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.735600</td>\n",
              "      <td>0.726707</td>\n",
              "      <td>0.501250</td>\n",
              "      <td>0.004988</td>\n",
              "      <td>0.336105</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.002500</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.035377</td>\n",
              "      <td>0.700144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.521300</td>\n",
              "      <td>0.653370</td>\n",
              "      <td>0.662500</td>\n",
              "      <td>0.736328</td>\n",
              "      <td>0.633789</td>\n",
              "      <td>0.604167</td>\n",
              "      <td>0.942500</td>\n",
              "      <td>0.382500</td>\n",
              "      <td>0.392279</td>\n",
              "      <td>0.765850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.475800</td>\n",
              "      <td>0.555669</td>\n",
              "      <td>0.713750</td>\n",
              "      <td>0.730905</td>\n",
              "      <td>0.712582</td>\n",
              "      <td>0.689579</td>\n",
              "      <td>0.777500</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>0.431018</td>\n",
              "      <td>0.802194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.369600</td>\n",
              "      <td>0.572801</td>\n",
              "      <td>0.717500</td>\n",
              "      <td>0.744344</td>\n",
              "      <td>0.714351</td>\n",
              "      <td>0.679752</td>\n",
              "      <td>0.822500</td>\n",
              "      <td>0.612500</td>\n",
              "      <td>0.444921</td>\n",
              "      <td>0.807650</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 1759, total number of training (for each informative and uninform class) and test samples: 800, 6400 0.1 XLNet-L 1759 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-large-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [600/600 01:43, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.716900</td>\n",
              "      <td>0.693637</td>\n",
              "      <td>0.513750</td>\n",
              "      <td>0.663203</td>\n",
              "      <td>0.394523</td>\n",
              "      <td>0.507285</td>\n",
              "      <td>0.957500</td>\n",
              "      <td>0.070000</td>\n",
              "      <td>0.059678</td>\n",
              "      <td>0.611000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.666100</td>\n",
              "      <td>0.628249</td>\n",
              "      <td>0.653750</td>\n",
              "      <td>0.663426</td>\n",
              "      <td>0.653464</td>\n",
              "      <td>0.645390</td>\n",
              "      <td>0.682500</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.308010</td>\n",
              "      <td>0.698381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.637400</td>\n",
              "      <td>0.664980</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>0.711340</td>\n",
              "      <td>0.633448</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>0.862500</td>\n",
              "      <td>0.437500</td>\n",
              "      <td>0.331421</td>\n",
              "      <td>0.754869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.534700</td>\n",
              "      <td>0.591319</td>\n",
              "      <td>0.692500</td>\n",
              "      <td>0.682171</td>\n",
              "      <td>0.692175</td>\n",
              "      <td>0.705882</td>\n",
              "      <td>0.660000</td>\n",
              "      <td>0.725000</td>\n",
              "      <td>0.385816</td>\n",
              "      <td>0.761938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.436600</td>\n",
              "      <td>0.679105</td>\n",
              "      <td>0.696250</td>\n",
              "      <td>0.716453</td>\n",
              "      <td>0.694700</td>\n",
              "      <td>0.671772</td>\n",
              "      <td>0.767500</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.396547</td>\n",
              "      <td>0.777081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.357700</td>\n",
              "      <td>0.771602</td>\n",
              "      <td>0.706250</td>\n",
              "      <td>0.721893</td>\n",
              "      <td>0.705318</td>\n",
              "      <td>0.685393</td>\n",
              "      <td>0.762500</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>0.415135</td>\n",
              "      <td>0.781081</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 323, total number of training (for each informative and uninform class) and test samples: 800, 6400 0.1 XLNet-L 323 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-large-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [600/600 01:43, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.715800</td>\n",
              "      <td>0.693073</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.599872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.735400</td>\n",
              "      <td>0.693035</td>\n",
              "      <td>0.501250</td>\n",
              "      <td>0.004988</td>\n",
              "      <td>0.336105</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.002500</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.035377</td>\n",
              "      <td>0.628553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.699600</td>\n",
              "      <td>0.703499</td>\n",
              "      <td>0.502500</td>\n",
              "      <td>0.009950</td>\n",
              "      <td>0.338865</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.005000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.050063</td>\n",
              "      <td>0.619772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.670600</td>\n",
              "      <td>0.697148</td>\n",
              "      <td>0.517500</td>\n",
              "      <td>0.673986</td>\n",
              "      <td>0.373051</td>\n",
              "      <td>0.508929</td>\n",
              "      <td>0.997500</td>\n",
              "      <td>0.037500</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.713194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.644400</td>\n",
              "      <td>0.629212</td>\n",
              "      <td>0.655000</td>\n",
              "      <td>0.709474</td>\n",
              "      <td>0.642429</td>\n",
              "      <td>0.612727</td>\n",
              "      <td>0.842500</td>\n",
              "      <td>0.467500</td>\n",
              "      <td>0.334403</td>\n",
              "      <td>0.751506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.531200</td>\n",
              "      <td>0.634025</td>\n",
              "      <td>0.692500</td>\n",
              "      <td>0.721088</td>\n",
              "      <td>0.689235</td>\n",
              "      <td>0.659751</td>\n",
              "      <td>0.795000</td>\n",
              "      <td>0.590000</td>\n",
              "      <td>0.393354</td>\n",
              "      <td>0.757238</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 1694, total number of training (for each informative and uninform class) and test samples: 800, 6400 0.1 XLNet-L 1694 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-large-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [600/600 01:43, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.729900</td>\n",
              "      <td>0.693416</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.533197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.723500</td>\n",
              "      <td>0.693343</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.554416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.706700</td>\n",
              "      <td>0.693354</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.511737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.717100</td>\n",
              "      <td>0.693304</td>\n",
              "      <td>0.501250</td>\n",
              "      <td>0.014815</td>\n",
              "      <td>0.340462</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.007500</td>\n",
              "      <td>0.995000</td>\n",
              "      <td>0.015861</td>\n",
              "      <td>0.585750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.726600</td>\n",
              "      <td>0.693922</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.562362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.728300</td>\n",
              "      <td>0.694513</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.548706</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 9741, total number of training (for each informative and uninform class) and test samples: 800, 6400 0.1 XLNet-L 9741 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-large-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [600/600 01:42, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.696800</td>\n",
              "      <td>0.709245</td>\n",
              "      <td>0.523750</td>\n",
              "      <td>0.173536</td>\n",
              "      <td>0.419516</td>\n",
              "      <td>0.655738</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.947500</td>\n",
              "      <td>0.089488</td>\n",
              "      <td>0.532925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.684700</td>\n",
              "      <td>0.668117</td>\n",
              "      <td>0.567500</td>\n",
              "      <td>0.302419</td>\n",
              "      <td>0.494507</td>\n",
              "      <td>0.781250</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>0.947500</td>\n",
              "      <td>0.207717</td>\n",
              "      <td>0.703181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.607400</td>\n",
              "      <td>0.562720</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.665738</td>\n",
              "      <td>0.696815</td>\n",
              "      <td>0.751572</td>\n",
              "      <td>0.597500</td>\n",
              "      <td>0.802500</td>\n",
              "      <td>0.408680</td>\n",
              "      <td>0.792562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.518500</td>\n",
              "      <td>0.570888</td>\n",
              "      <td>0.720000</td>\n",
              "      <td>0.737705</td>\n",
              "      <td>0.718718</td>\n",
              "      <td>0.693833</td>\n",
              "      <td>0.787500</td>\n",
              "      <td>0.652500</td>\n",
              "      <td>0.444065</td>\n",
              "      <td>0.802444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.464400</td>\n",
              "      <td>0.676420</td>\n",
              "      <td>0.743750</td>\n",
              "      <td>0.761905</td>\n",
              "      <td>0.742251</td>\n",
              "      <td>0.711497</td>\n",
              "      <td>0.820000</td>\n",
              "      <td>0.667500</td>\n",
              "      <td>0.493270</td>\n",
              "      <td>0.812969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.293800</td>\n",
              "      <td>0.755586</td>\n",
              "      <td>0.743750</td>\n",
              "      <td>0.746601</td>\n",
              "      <td>0.743718</td>\n",
              "      <td>0.738386</td>\n",
              "      <td>0.755000</td>\n",
              "      <td>0.732500</td>\n",
              "      <td>0.487623</td>\n",
              "      <td>0.818163</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 200, total number of training (for each informative and uninform class) and test samples: 800, 6400 0.1 XLNet-L 200 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-large-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [600/600 01:43, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.730800</td>\n",
              "      <td>0.696985</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.576937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.708900</td>\n",
              "      <td>0.686190</td>\n",
              "      <td>0.573750</td>\n",
              "      <td>0.629750</td>\n",
              "      <td>0.563771</td>\n",
              "      <td>0.556622</td>\n",
              "      <td>0.725000</td>\n",
              "      <td>0.422500</td>\n",
              "      <td>0.154750</td>\n",
              "      <td>0.622275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.672200</td>\n",
              "      <td>0.706388</td>\n",
              "      <td>0.525000</td>\n",
              "      <td>0.629630</td>\n",
              "      <td>0.483804</td>\n",
              "      <td>0.515974</td>\n",
              "      <td>0.807500</td>\n",
              "      <td>0.242500</td>\n",
              "      <td>0.060599</td>\n",
              "      <td>0.607200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.562300</td>\n",
              "      <td>0.637675</td>\n",
              "      <td>0.647500</td>\n",
              "      <td>0.690789</td>\n",
              "      <td>0.640453</td>\n",
              "      <td>0.615234</td>\n",
              "      <td>0.787500</td>\n",
              "      <td>0.507500</td>\n",
              "      <td>0.307292</td>\n",
              "      <td>0.734819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.571700</td>\n",
              "      <td>0.610220</td>\n",
              "      <td>0.703750</td>\n",
              "      <td>0.739846</td>\n",
              "      <td>0.697935</td>\n",
              "      <td>0.659491</td>\n",
              "      <td>0.842500</td>\n",
              "      <td>0.565000</td>\n",
              "      <td>0.424159</td>\n",
              "      <td>0.777631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.429700</td>\n",
              "      <td>0.636373</td>\n",
              "      <td>0.721250</td>\n",
              "      <td>0.734207</td>\n",
              "      <td>0.720586</td>\n",
              "      <td>0.701595</td>\n",
              "      <td>0.770000</td>\n",
              "      <td>0.672500</td>\n",
              "      <td>0.444618</td>\n",
              "      <td>0.787588</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 999, total number of training (for each informative and uninform class) and test samples: 800, 6400 0.1 XLNet-L 999 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-large-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [600/600 01:43, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.711200</td>\n",
              "      <td>0.731571</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.544572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.695800</td>\n",
              "      <td>0.695796</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.534303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.725500</td>\n",
              "      <td>0.695410</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.592688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.684300</td>\n",
              "      <td>0.708424</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.629156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.688900</td>\n",
              "      <td>0.702405</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.646619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.675900</td>\n",
              "      <td>0.672984</td>\n",
              "      <td>0.588750</td>\n",
              "      <td>0.466775</td>\n",
              "      <td>0.566042</td>\n",
              "      <td>0.663594</td>\n",
              "      <td>0.360000</td>\n",
              "      <td>0.817500</td>\n",
              "      <td>0.199615</td>\n",
              "      <td>0.670319</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "92952d2e8732453dbbcea1d39f740f7d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8c2ce2a56ad54328b3fe326e9dd4b355",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/474 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "62161c843b54409ea85e34f4a511327a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0951edcd8691435a9fac2badba0582d1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 94, total number of training (for each informative and uninform class) and test samples: 800, 6400 0.1 DEBERT-B 94 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "686de9d417384f7b99cc71e31187c9f8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/559M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [600/600 01:04, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.696700</td>\n",
              "      <td>0.693359</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.560359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.704500</td>\n",
              "      <td>0.693279</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.535566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.693300</td>\n",
              "      <td>0.694117</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.510097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.713100</td>\n",
              "      <td>0.693442</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.604000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.692800</td>\n",
              "      <td>0.693240</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.565919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.694000</td>\n",
              "      <td>0.693227</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.575659</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 791, total number of training (for each informative and uninform class) and test samples: 800, 6400 0.1 DEBERT-B 791 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [600/600 01:04, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.632700</td>\n",
              "      <td>0.616919</td>\n",
              "      <td>0.661250</td>\n",
              "      <td>0.707659</td>\n",
              "      <td>0.652492</td>\n",
              "      <td>0.622391</td>\n",
              "      <td>0.820000</td>\n",
              "      <td>0.502500</td>\n",
              "      <td>0.340097</td>\n",
              "      <td>0.752106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.383000</td>\n",
              "      <td>0.792698</td>\n",
              "      <td>0.693750</td>\n",
              "      <td>0.690265</td>\n",
              "      <td>0.693711</td>\n",
              "      <td>0.698210</td>\n",
              "      <td>0.682500</td>\n",
              "      <td>0.705000</td>\n",
              "      <td>0.387598</td>\n",
              "      <td>0.760763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.216800</td>\n",
              "      <td>1.173338</td>\n",
              "      <td>0.693750</td>\n",
              "      <td>0.707986</td>\n",
              "      <td>0.693020</td>\n",
              "      <td>0.676538</td>\n",
              "      <td>0.742500</td>\n",
              "      <td>0.645000</td>\n",
              "      <td>0.389355</td>\n",
              "      <td>0.769616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.120100</td>\n",
              "      <td>1.484764</td>\n",
              "      <td>0.691250</td>\n",
              "      <td>0.731813</td>\n",
              "      <td>0.684021</td>\n",
              "      <td>0.646833</td>\n",
              "      <td>0.842500</td>\n",
              "      <td>0.540000</td>\n",
              "      <td>0.401301</td>\n",
              "      <td>0.754544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.220900</td>\n",
              "      <td>1.586416</td>\n",
              "      <td>0.691250</td>\n",
              "      <td>0.734123</td>\n",
              "      <td>0.683008</td>\n",
              "      <td>0.644612</td>\n",
              "      <td>0.852500</td>\n",
              "      <td>0.530000</td>\n",
              "      <td>0.404091</td>\n",
              "      <td>0.720581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.095900</td>\n",
              "      <td>1.578017</td>\n",
              "      <td>0.702500</td>\n",
              "      <td>0.726437</td>\n",
              "      <td>0.700205</td>\n",
              "      <td>0.672340</td>\n",
              "      <td>0.790000</td>\n",
              "      <td>0.615000</td>\n",
              "      <td>0.411348</td>\n",
              "      <td>0.744681</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 5, total number of training (for each informative and uninform class) and test samples: 800, 6400 0.1 DEBERT-B 5 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [600/600 01:05, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.550800</td>\n",
              "      <td>0.610910</td>\n",
              "      <td>0.680000</td>\n",
              "      <td>0.693046</td>\n",
              "      <td>0.679421</td>\n",
              "      <td>0.665899</td>\n",
              "      <td>0.722500</td>\n",
              "      <td>0.637500</td>\n",
              "      <td>0.361308</td>\n",
              "      <td>0.754306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.481600</td>\n",
              "      <td>0.596394</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.721578</td>\n",
              "      <td>0.698187</td>\n",
              "      <td>0.673160</td>\n",
              "      <td>0.777500</td>\n",
              "      <td>0.622500</td>\n",
              "      <td>0.404893</td>\n",
              "      <td>0.794444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.440500</td>\n",
              "      <td>0.852527</td>\n",
              "      <td>0.705000</td>\n",
              "      <td>0.731818</td>\n",
              "      <td>0.702020</td>\n",
              "      <td>0.670833</td>\n",
              "      <td>0.805000</td>\n",
              "      <td>0.605000</td>\n",
              "      <td>0.418454</td>\n",
              "      <td>0.786675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.215800</td>\n",
              "      <td>1.325842</td>\n",
              "      <td>0.725000</td>\n",
              "      <td>0.754464</td>\n",
              "      <td>0.720982</td>\n",
              "      <td>0.681452</td>\n",
              "      <td>0.845000</td>\n",
              "      <td>0.605000</td>\n",
              "      <td>0.463548</td>\n",
              "      <td>0.791850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.144000</td>\n",
              "      <td>1.449280</td>\n",
              "      <td>0.733750</td>\n",
              "      <td>0.749117</td>\n",
              "      <td>0.732747</td>\n",
              "      <td>0.708241</td>\n",
              "      <td>0.795000</td>\n",
              "      <td>0.672500</td>\n",
              "      <td>0.471048</td>\n",
              "      <td>0.796419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.052900</td>\n",
              "      <td>1.533935</td>\n",
              "      <td>0.732500</td>\n",
              "      <td>0.752887</td>\n",
              "      <td>0.730667</td>\n",
              "      <td>0.699571</td>\n",
              "      <td>0.815000</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>0.471462</td>\n",
              "      <td>0.794544</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 6932, total number of training (for each informative and uninform class) and test samples: 800, 6400 0.1 DEBERT-B 6932 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [600/600 01:06, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.633500</td>\n",
              "      <td>0.632758</td>\n",
              "      <td>0.666250</td>\n",
              "      <td>0.734856</td>\n",
              "      <td>0.642302</td>\n",
              "      <td>0.609555</td>\n",
              "      <td>0.925000</td>\n",
              "      <td>0.407500</td>\n",
              "      <td>0.388578</td>\n",
              "      <td>0.764381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.466300</td>\n",
              "      <td>0.587796</td>\n",
              "      <td>0.727500</td>\n",
              "      <td>0.752273</td>\n",
              "      <td>0.724747</td>\n",
              "      <td>0.689583</td>\n",
              "      <td>0.827500</td>\n",
              "      <td>0.627500</td>\n",
              "      <td>0.464382</td>\n",
              "      <td>0.805088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.445500</td>\n",
              "      <td>0.981812</td>\n",
              "      <td>0.740000</td>\n",
              "      <td>0.734015</td>\n",
              "      <td>0.739868</td>\n",
              "      <td>0.751309</td>\n",
              "      <td>0.717500</td>\n",
              "      <td>0.762500</td>\n",
              "      <td>0.480487</td>\n",
              "      <td>0.816331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.166600</td>\n",
              "      <td>1.158969</td>\n",
              "      <td>0.738750</td>\n",
              "      <td>0.765957</td>\n",
              "      <td>0.735171</td>\n",
              "      <td>0.693712</td>\n",
              "      <td>0.855000</td>\n",
              "      <td>0.622500</td>\n",
              "      <td>0.490954</td>\n",
              "      <td>0.819806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.050900</td>\n",
              "      <td>1.410925</td>\n",
              "      <td>0.737500</td>\n",
              "      <td>0.738155</td>\n",
              "      <td>0.737498</td>\n",
              "      <td>0.736318</td>\n",
              "      <td>0.740000</td>\n",
              "      <td>0.735000</td>\n",
              "      <td>0.475006</td>\n",
              "      <td>0.814325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.092600</td>\n",
              "      <td>1.433433</td>\n",
              "      <td>0.740000</td>\n",
              "      <td>0.755869</td>\n",
              "      <td>0.738897</td>\n",
              "      <td>0.712389</td>\n",
              "      <td>0.805000</td>\n",
              "      <td>0.675000</td>\n",
              "      <td>0.484108</td>\n",
              "      <td>0.815131</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 1759, total number of training (for each informative and uninform class) and test samples: 800, 6400 0.1 DEBERT-B 1759 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [600/600 01:05, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.551200</td>\n",
              "      <td>0.581706</td>\n",
              "      <td>0.705000</td>\n",
              "      <td>0.701266</td>\n",
              "      <td>0.704954</td>\n",
              "      <td>0.710256</td>\n",
              "      <td>0.692500</td>\n",
              "      <td>0.717500</td>\n",
              "      <td>0.410128</td>\n",
              "      <td>0.781362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.493200</td>\n",
              "      <td>0.528017</td>\n",
              "      <td>0.738750</td>\n",
              "      <td>0.730323</td>\n",
              "      <td>0.738495</td>\n",
              "      <td>0.754667</td>\n",
              "      <td>0.707500</td>\n",
              "      <td>0.770000</td>\n",
              "      <td>0.478435</td>\n",
              "      <td>0.819825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.324300</td>\n",
              "      <td>0.940277</td>\n",
              "      <td>0.727500</td>\n",
              "      <td>0.758315</td>\n",
              "      <td>0.722997</td>\n",
              "      <td>0.681275</td>\n",
              "      <td>0.855000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.470556</td>\n",
              "      <td>0.819412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.259000</td>\n",
              "      <td>1.227754</td>\n",
              "      <td>0.736250</td>\n",
              "      <td>0.718291</td>\n",
              "      <td>0.735174</td>\n",
              "      <td>0.770774</td>\n",
              "      <td>0.672500</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.476388</td>\n",
              "      <td>0.813256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.088800</td>\n",
              "      <td>1.437812</td>\n",
              "      <td>0.748750</td>\n",
              "      <td>0.742638</td>\n",
              "      <td>0.748608</td>\n",
              "      <td>0.761155</td>\n",
              "      <td>0.725000</td>\n",
              "      <td>0.772500</td>\n",
              "      <td>0.498062</td>\n",
              "      <td>0.808144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.109300</td>\n",
              "      <td>1.493969</td>\n",
              "      <td>0.740000</td>\n",
              "      <td>0.741935</td>\n",
              "      <td>0.739985</td>\n",
              "      <td>0.736453</td>\n",
              "      <td>0.747500</td>\n",
              "      <td>0.732500</td>\n",
              "      <td>0.480054</td>\n",
              "      <td>0.809850</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 323, total number of training (for each informative and uninform class) and test samples: 800, 6400 0.1 DEBERT-B 323 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [600/600 01:04, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.672200</td>\n",
              "      <td>0.715136</td>\n",
              "      <td>0.567500</td>\n",
              "      <td>0.691622</td>\n",
              "      <td>0.483886</td>\n",
              "      <td>0.537396</td>\n",
              "      <td>0.970000</td>\n",
              "      <td>0.165000</td>\n",
              "      <td>0.227551</td>\n",
              "      <td>0.745169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.541600</td>\n",
              "      <td>0.573095</td>\n",
              "      <td>0.710000</td>\n",
              "      <td>0.719128</td>\n",
              "      <td>0.709693</td>\n",
              "      <td>0.697183</td>\n",
              "      <td>0.742500</td>\n",
              "      <td>0.677500</td>\n",
              "      <td>0.420890</td>\n",
              "      <td>0.780094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.399600</td>\n",
              "      <td>0.733729</td>\n",
              "      <td>0.701250</td>\n",
              "      <td>0.731762</td>\n",
              "      <td>0.697334</td>\n",
              "      <td>0.663951</td>\n",
              "      <td>0.815000</td>\n",
              "      <td>0.587500</td>\n",
              "      <td>0.413339</td>\n",
              "      <td>0.783913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.291600</td>\n",
              "      <td>1.301468</td>\n",
              "      <td>0.686250</td>\n",
              "      <td>0.729817</td>\n",
              "      <td>0.677874</td>\n",
              "      <td>0.640832</td>\n",
              "      <td>0.847500</td>\n",
              "      <td>0.525000</td>\n",
              "      <td>0.393526</td>\n",
              "      <td>0.788494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.086800</td>\n",
              "      <td>1.604916</td>\n",
              "      <td>0.675000</td>\n",
              "      <td>0.727463</td>\n",
              "      <td>0.662493</td>\n",
              "      <td>0.626354</td>\n",
              "      <td>0.867500</td>\n",
              "      <td>0.482500</td>\n",
              "      <td>0.379233</td>\n",
              "      <td>0.782919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.048300</td>\n",
              "      <td>1.587346</td>\n",
              "      <td>0.698750</td>\n",
              "      <td>0.722670</td>\n",
              "      <td>0.696492</td>\n",
              "      <td>0.669510</td>\n",
              "      <td>0.785000</td>\n",
              "      <td>0.612500</td>\n",
              "      <td>0.403549</td>\n",
              "      <td>0.779081</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 1694, total number of training (for each informative and uninform class) and test samples: 800, 6400 0.1 DEBERT-B 1694 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [600/600 01:05, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.718600</td>\n",
              "      <td>0.697370</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666110</td>\n",
              "      <td>0.335543</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.997500</td>\n",
              "      <td>0.002500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.568806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.651100</td>\n",
              "      <td>0.587597</td>\n",
              "      <td>0.706250</td>\n",
              "      <td>0.726426</td>\n",
              "      <td>0.704644</td>\n",
              "      <td>0.679739</td>\n",
              "      <td>0.780000</td>\n",
              "      <td>0.632500</td>\n",
              "      <td>0.417062</td>\n",
              "      <td>0.764569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.419600</td>\n",
              "      <td>0.599627</td>\n",
              "      <td>0.725000</td>\n",
              "      <td>0.734300</td>\n",
              "      <td>0.724663</td>\n",
              "      <td>0.710280</td>\n",
              "      <td>0.760000</td>\n",
              "      <td>0.690000</td>\n",
              "      <td>0.451107</td>\n",
              "      <td>0.781525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.291300</td>\n",
              "      <td>0.731858</td>\n",
              "      <td>0.730000</td>\n",
              "      <td>0.720207</td>\n",
              "      <td>0.729669</td>\n",
              "      <td>0.747312</td>\n",
              "      <td>0.695000</td>\n",
              "      <td>0.765000</td>\n",
              "      <td>0.461131</td>\n",
              "      <td>0.792444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.227100</td>\n",
              "      <td>0.894100</td>\n",
              "      <td>0.752500</td>\n",
              "      <td>0.759709</td>\n",
              "      <td>0.752277</td>\n",
              "      <td>0.738208</td>\n",
              "      <td>0.782500</td>\n",
              "      <td>0.722500</td>\n",
              "      <td>0.505911</td>\n",
              "      <td>0.803956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.192000</td>\n",
              "      <td>1.002657</td>\n",
              "      <td>0.747500</td>\n",
              "      <td>0.764019</td>\n",
              "      <td>0.746257</td>\n",
              "      <td>0.717105</td>\n",
              "      <td>0.817500</td>\n",
              "      <td>0.677500</td>\n",
              "      <td>0.499923</td>\n",
              "      <td>0.803906</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 9741, total number of training (for each informative and uninform class) and test samples: 800, 6400 0.1 DEBERT-B 9741 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [600/600 01:04, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.694500</td>\n",
              "      <td>0.692851</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.679488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.691500</td>\n",
              "      <td>0.696666</td>\n",
              "      <td>0.615000</td>\n",
              "      <td>0.496732</td>\n",
              "      <td>0.592496</td>\n",
              "      <td>0.716981</td>\n",
              "      <td>0.380000</td>\n",
              "      <td>0.850000</td>\n",
              "      <td>0.260574</td>\n",
              "      <td>0.722819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.596900</td>\n",
              "      <td>0.591830</td>\n",
              "      <td>0.697500</td>\n",
              "      <td>0.668493</td>\n",
              "      <td>0.695166</td>\n",
              "      <td>0.739394</td>\n",
              "      <td>0.610000</td>\n",
              "      <td>0.785000</td>\n",
              "      <td>0.401191</td>\n",
              "      <td>0.774519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.435600</td>\n",
              "      <td>0.624752</td>\n",
              "      <td>0.727500</td>\n",
              "      <td>0.727500</td>\n",
              "      <td>0.727500</td>\n",
              "      <td>0.727500</td>\n",
              "      <td>0.727500</td>\n",
              "      <td>0.727500</td>\n",
              "      <td>0.455000</td>\n",
              "      <td>0.794419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.263800</td>\n",
              "      <td>0.877127</td>\n",
              "      <td>0.726250</td>\n",
              "      <td>0.742656</td>\n",
              "      <td>0.725133</td>\n",
              "      <td>0.700665</td>\n",
              "      <td>0.790000</td>\n",
              "      <td>0.662500</td>\n",
              "      <td>0.456223</td>\n",
              "      <td>0.791725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.268900</td>\n",
              "      <td>0.993881</td>\n",
              "      <td>0.726250</td>\n",
              "      <td>0.740828</td>\n",
              "      <td>0.725381</td>\n",
              "      <td>0.703371</td>\n",
              "      <td>0.782500</td>\n",
              "      <td>0.670000</td>\n",
              "      <td>0.455391</td>\n",
              "      <td>0.791712</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 200, total number of training (for each informative and uninform class) and test samples: 800, 6400 0.1 DEBERT-B 200 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [600/600 01:05, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.637500</td>\n",
              "      <td>0.614989</td>\n",
              "      <td>0.670000</td>\n",
              "      <td>0.604790</td>\n",
              "      <td>0.660764</td>\n",
              "      <td>0.753731</td>\n",
              "      <td>0.505000</td>\n",
              "      <td>0.835000</td>\n",
              "      <td>0.360177</td>\n",
              "      <td>0.741200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.512500</td>\n",
              "      <td>0.556646</td>\n",
              "      <td>0.711250</td>\n",
              "      <td>0.749186</td>\n",
              "      <td>0.704490</td>\n",
              "      <td>0.662188</td>\n",
              "      <td>0.862500</td>\n",
              "      <td>0.560000</td>\n",
              "      <td>0.443267</td>\n",
              "      <td>0.806412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.298000</td>\n",
              "      <td>0.703827</td>\n",
              "      <td>0.727500</td>\n",
              "      <td>0.740476</td>\n",
              "      <td>0.726817</td>\n",
              "      <td>0.706818</td>\n",
              "      <td>0.777500</td>\n",
              "      <td>0.677500</td>\n",
              "      <td>0.457292</td>\n",
              "      <td>0.806412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.319800</td>\n",
              "      <td>1.099197</td>\n",
              "      <td>0.721250</td>\n",
              "      <td>0.752497</td>\n",
              "      <td>0.716735</td>\n",
              "      <td>0.676647</td>\n",
              "      <td>0.847500</td>\n",
              "      <td>0.595000</td>\n",
              "      <td>0.457319</td>\n",
              "      <td>0.809656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.109800</td>\n",
              "      <td>1.356312</td>\n",
              "      <td>0.745000</td>\n",
              "      <td>0.746898</td>\n",
              "      <td>0.744986</td>\n",
              "      <td>0.741379</td>\n",
              "      <td>0.752500</td>\n",
              "      <td>0.737500</td>\n",
              "      <td>0.490055</td>\n",
              "      <td>0.807169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.037000</td>\n",
              "      <td>1.412076</td>\n",
              "      <td>0.740000</td>\n",
              "      <td>0.742574</td>\n",
              "      <td>0.739974</td>\n",
              "      <td>0.735294</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.730000</td>\n",
              "      <td>0.480096</td>\n",
              "      <td>0.809850</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 999, total number of training (for each informative and uninform class) and test samples: 800, 6400 0.1 DEBERT-B 999 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [600/600 01:06, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.710700</td>\n",
              "      <td>0.637652</td>\n",
              "      <td>0.602500</td>\n",
              "      <td>0.708257</td>\n",
              "      <td>0.542364</td>\n",
              "      <td>0.559420</td>\n",
              "      <td>0.965000</td>\n",
              "      <td>0.240000</td>\n",
              "      <td>0.297641</td>\n",
              "      <td>0.613894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.587800</td>\n",
              "      <td>0.581634</td>\n",
              "      <td>0.703750</td>\n",
              "      <td>0.715486</td>\n",
              "      <td>0.703245</td>\n",
              "      <td>0.688222</td>\n",
              "      <td>0.745000</td>\n",
              "      <td>0.662500</td>\n",
              "      <td>0.408894</td>\n",
              "      <td>0.765950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.476400</td>\n",
              "      <td>0.671592</td>\n",
              "      <td>0.735000</td>\n",
              "      <td>0.732323</td>\n",
              "      <td>0.734973</td>\n",
              "      <td>0.739796</td>\n",
              "      <td>0.725000</td>\n",
              "      <td>0.745000</td>\n",
              "      <td>0.470094</td>\n",
              "      <td>0.789525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.308900</td>\n",
              "      <td>1.195611</td>\n",
              "      <td>0.705000</td>\n",
              "      <td>0.734831</td>\n",
              "      <td>0.701219</td>\n",
              "      <td>0.667347</td>\n",
              "      <td>0.817500</td>\n",
              "      <td>0.592500</td>\n",
              "      <td>0.420790</td>\n",
              "      <td>0.784663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.174400</td>\n",
              "      <td>1.262734</td>\n",
              "      <td>0.717500</td>\n",
              "      <td>0.735981</td>\n",
              "      <td>0.716109</td>\n",
              "      <td>0.690789</td>\n",
              "      <td>0.787500</td>\n",
              "      <td>0.647500</td>\n",
              "      <td>0.439327</td>\n",
              "      <td>0.776100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.068200</td>\n",
              "      <td>1.369297</td>\n",
              "      <td>0.715000</td>\n",
              "      <td>0.736111</td>\n",
              "      <td>0.713164</td>\n",
              "      <td>0.685345</td>\n",
              "      <td>0.795000</td>\n",
              "      <td>0.635000</td>\n",
              "      <td>0.435612</td>\n",
              "      <td>0.772687</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 94, total number of training (for each informative and uninform class) and test samples: 400, 6800 0.05 ALBERT-L 94 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:29, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.706500</td>\n",
              "      <td>0.686336</td>\n",
              "      <td>0.545000</td>\n",
              "      <td>0.673250</td>\n",
              "      <td>0.462139</td>\n",
              "      <td>0.525210</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.152500</td>\n",
              "      <td>0.145279</td>\n",
              "      <td>0.591075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.712100</td>\n",
              "      <td>0.689503</td>\n",
              "      <td>0.545000</td>\n",
              "      <td>0.580645</td>\n",
              "      <td>0.541689</td>\n",
              "      <td>0.538462</td>\n",
              "      <td>0.630000</td>\n",
              "      <td>0.460000</td>\n",
              "      <td>0.091329</td>\n",
              "      <td>0.550394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.726200</td>\n",
              "      <td>0.701886</td>\n",
              "      <td>0.492500</td>\n",
              "      <td>0.634892</td>\n",
              "      <td>0.401462</td>\n",
              "      <td>0.495787</td>\n",
              "      <td>0.882500</td>\n",
              "      <td>0.102500</td>\n",
              "      <td>-0.023970</td>\n",
              "      <td>0.509637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.717600</td>\n",
              "      <td>0.699061</td>\n",
              "      <td>0.515000</td>\n",
              "      <td>0.564045</td>\n",
              "      <td>0.508783</td>\n",
              "      <td>0.512245</td>\n",
              "      <td>0.627500</td>\n",
              "      <td>0.402500</td>\n",
              "      <td>0.030789</td>\n",
              "      <td>0.497787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.717900</td>\n",
              "      <td>0.700754</td>\n",
              "      <td>0.476250</td>\n",
              "      <td>0.066815</td>\n",
              "      <td>0.351392</td>\n",
              "      <td>0.306122</td>\n",
              "      <td>0.037500</td>\n",
              "      <td>0.915000</td>\n",
              "      <td>-0.099046</td>\n",
              "      <td>0.489063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.709900</td>\n",
              "      <td>0.691404</td>\n",
              "      <td>0.513750</td>\n",
              "      <td>0.508217</td>\n",
              "      <td>0.513688</td>\n",
              "      <td>0.514066</td>\n",
              "      <td>0.502500</td>\n",
              "      <td>0.525000</td>\n",
              "      <td>0.027507</td>\n",
              "      <td>0.536412</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 791, total number of training (for each informative and uninform class) and test samples: 400, 6800 0.05 ALBERT-L 791 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:29, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.681400</td>\n",
              "      <td>0.655131</td>\n",
              "      <td>0.630000</td>\n",
              "      <td>0.647619</td>\n",
              "      <td>0.629073</td>\n",
              "      <td>0.618182</td>\n",
              "      <td>0.680000</td>\n",
              "      <td>0.580000</td>\n",
              "      <td>0.261310</td>\n",
              "      <td>0.665931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.571100</td>\n",
              "      <td>0.589277</td>\n",
              "      <td>0.697500</td>\n",
              "      <td>0.723112</td>\n",
              "      <td>0.694889</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.790000</td>\n",
              "      <td>0.605000</td>\n",
              "      <td>0.401938</td>\n",
              "      <td>0.762225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.277400</td>\n",
              "      <td>0.747204</td>\n",
              "      <td>0.702500</td>\n",
              "      <td>0.656069</td>\n",
              "      <td>0.696977</td>\n",
              "      <td>0.777397</td>\n",
              "      <td>0.567500</td>\n",
              "      <td>0.837500</td>\n",
              "      <td>0.420622</td>\n",
              "      <td>0.744506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.195700</td>\n",
              "      <td>0.887333</td>\n",
              "      <td>0.708750</td>\n",
              "      <td>0.709114</td>\n",
              "      <td>0.708750</td>\n",
              "      <td>0.708229</td>\n",
              "      <td>0.710000</td>\n",
              "      <td>0.707500</td>\n",
              "      <td>0.417501</td>\n",
              "      <td>0.770400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.054200</td>\n",
              "      <td>1.132825</td>\n",
              "      <td>0.715000</td>\n",
              "      <td>0.717822</td>\n",
              "      <td>0.714971</td>\n",
              "      <td>0.710784</td>\n",
              "      <td>0.725000</td>\n",
              "      <td>0.705000</td>\n",
              "      <td>0.430086</td>\n",
              "      <td>0.762912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.008300</td>\n",
              "      <td>1.206374</td>\n",
              "      <td>0.703750</td>\n",
              "      <td>0.720189</td>\n",
              "      <td>0.702724</td>\n",
              "      <td>0.682327</td>\n",
              "      <td>0.762500</td>\n",
              "      <td>0.645000</td>\n",
              "      <td>0.410342</td>\n",
              "      <td>0.763338</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 5, total number of training (for each informative and uninform class) and test samples: 400, 6800 0.05 ALBERT-L 5 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:29, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.636300</td>\n",
              "      <td>0.581682</td>\n",
              "      <td>0.693750</td>\n",
              "      <td>0.726257</td>\n",
              "      <td>0.689370</td>\n",
              "      <td>0.656566</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.575000</td>\n",
              "      <td>0.398914</td>\n",
              "      <td>0.790681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.468200</td>\n",
              "      <td>0.585899</td>\n",
              "      <td>0.722500</td>\n",
              "      <td>0.738824</td>\n",
              "      <td>0.721412</td>\n",
              "      <td>0.697778</td>\n",
              "      <td>0.785000</td>\n",
              "      <td>0.660000</td>\n",
              "      <td>0.448518</td>\n",
              "      <td>0.793188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.363000</td>\n",
              "      <td>0.686115</td>\n",
              "      <td>0.722500</td>\n",
              "      <td>0.740654</td>\n",
              "      <td>0.721134</td>\n",
              "      <td>0.695175</td>\n",
              "      <td>0.792500</td>\n",
              "      <td>0.652500</td>\n",
              "      <td>0.449426</td>\n",
              "      <td>0.796481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.161800</td>\n",
              "      <td>0.892724</td>\n",
              "      <td>0.747500</td>\n",
              "      <td>0.761229</td>\n",
              "      <td>0.746662</td>\n",
              "      <td>0.721973</td>\n",
              "      <td>0.805000</td>\n",
              "      <td>0.690000</td>\n",
              "      <td>0.498306</td>\n",
              "      <td>0.799363</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.040800</td>\n",
              "      <td>1.219293</td>\n",
              "      <td>0.743750</td>\n",
              "      <td>0.748466</td>\n",
              "      <td>0.743660</td>\n",
              "      <td>0.734940</td>\n",
              "      <td>0.762500</td>\n",
              "      <td>0.725000</td>\n",
              "      <td>0.487843</td>\n",
              "      <td>0.793438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.030900</td>\n",
              "      <td>1.330591</td>\n",
              "      <td>0.748750</td>\n",
              "      <td>0.755177</td>\n",
              "      <td>0.748577</td>\n",
              "      <td>0.736342</td>\n",
              "      <td>0.775000</td>\n",
              "      <td>0.722500</td>\n",
              "      <td>0.498187</td>\n",
              "      <td>0.789394</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 6932, total number of training (for each informative and uninform class) and test samples: 400, 6800 0.05 ALBERT-L 6932 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:29, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.641700</td>\n",
              "      <td>0.607892</td>\n",
              "      <td>0.676250</td>\n",
              "      <td>0.733813</td>\n",
              "      <td>0.660367</td>\n",
              "      <td>0.623037</td>\n",
              "      <td>0.892500</td>\n",
              "      <td>0.460000</td>\n",
              "      <td>0.390957</td>\n",
              "      <td>0.777756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.446100</td>\n",
              "      <td>0.628170</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>0.736287</td>\n",
              "      <td>0.676426</td>\n",
              "      <td>0.636861</td>\n",
              "      <td>0.872500</td>\n",
              "      <td>0.502500</td>\n",
              "      <td>0.403646</td>\n",
              "      <td>0.790875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.282200</td>\n",
              "      <td>0.860455</td>\n",
              "      <td>0.713750</td>\n",
              "      <td>0.681502</td>\n",
              "      <td>0.710785</td>\n",
              "      <td>0.768025</td>\n",
              "      <td>0.612500</td>\n",
              "      <td>0.815000</td>\n",
              "      <td>0.436544</td>\n",
              "      <td>0.780906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.132000</td>\n",
              "      <td>1.054483</td>\n",
              "      <td>0.712500</td>\n",
              "      <td>0.720874</td>\n",
              "      <td>0.712241</td>\n",
              "      <td>0.700472</td>\n",
              "      <td>0.742500</td>\n",
              "      <td>0.682500</td>\n",
              "      <td>0.425767</td>\n",
              "      <td>0.785919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.076300</td>\n",
              "      <td>1.338393</td>\n",
              "      <td>0.720000</td>\n",
              "      <td>0.724138</td>\n",
              "      <td>0.719937</td>\n",
              "      <td>0.713592</td>\n",
              "      <td>0.735000</td>\n",
              "      <td>0.705000</td>\n",
              "      <td>0.440198</td>\n",
              "      <td>0.785937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.043000</td>\n",
              "      <td>1.397138</td>\n",
              "      <td>0.717500</td>\n",
              "      <td>0.723716</td>\n",
              "      <td>0.717357</td>\n",
              "      <td>0.708134</td>\n",
              "      <td>0.740000</td>\n",
              "      <td>0.695000</td>\n",
              "      <td>0.435441</td>\n",
              "      <td>0.785587</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 1759, total number of training (for each informative and uninform class) and test samples: 400, 6800 0.05 ALBERT-L 1759 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:29, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.708000</td>\n",
              "      <td>0.678597</td>\n",
              "      <td>0.586250</td>\n",
              "      <td>0.631813</td>\n",
              "      <td>0.579815</td>\n",
              "      <td>0.569138</td>\n",
              "      <td>0.710000</td>\n",
              "      <td>0.462500</td>\n",
              "      <td>0.178039</td>\n",
              "      <td>0.574362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.641500</td>\n",
              "      <td>0.617323</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>0.703390</td>\n",
              "      <td>0.638280</td>\n",
              "      <td>0.610294</td>\n",
              "      <td>0.830000</td>\n",
              "      <td>0.470000</td>\n",
              "      <td>0.321560</td>\n",
              "      <td>0.753469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.539100</td>\n",
              "      <td>0.595270</td>\n",
              "      <td>0.680000</td>\n",
              "      <td>0.677582</td>\n",
              "      <td>0.679982</td>\n",
              "      <td>0.682741</td>\n",
              "      <td>0.672500</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>0.360041</td>\n",
              "      <td>0.758125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.502700</td>\n",
              "      <td>0.606632</td>\n",
              "      <td>0.701250</td>\n",
              "      <td>0.737651</td>\n",
              "      <td>0.695386</td>\n",
              "      <td>0.657534</td>\n",
              "      <td>0.840000</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>0.418954</td>\n",
              "      <td>0.790006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.289500</td>\n",
              "      <td>0.867369</td>\n",
              "      <td>0.715000</td>\n",
              "      <td>0.748899</td>\n",
              "      <td>0.709709</td>\n",
              "      <td>0.669291</td>\n",
              "      <td>0.850000</td>\n",
              "      <td>0.580000</td>\n",
              "      <td>0.446586</td>\n",
              "      <td>0.797419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.190700</td>\n",
              "      <td>0.940660</td>\n",
              "      <td>0.725000</td>\n",
              "      <td>0.738717</td>\n",
              "      <td>0.724240</td>\n",
              "      <td>0.703620</td>\n",
              "      <td>0.777500</td>\n",
              "      <td>0.672500</td>\n",
              "      <td>0.452501</td>\n",
              "      <td>0.790106</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 323, total number of training (for each informative and uninform class) and test samples: 400, 6800 0.05 ALBERT-L 323 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:29, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.780400</td>\n",
              "      <td>0.761694</td>\n",
              "      <td>0.498750</td>\n",
              "      <td>0.029056</td>\n",
              "      <td>0.345615</td>\n",
              "      <td>0.461538</td>\n",
              "      <td>0.015000</td>\n",
              "      <td>0.982500</td>\n",
              "      <td>-0.009886</td>\n",
              "      <td>0.487831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.733500</td>\n",
              "      <td>0.705954</td>\n",
              "      <td>0.506250</td>\n",
              "      <td>0.211577</td>\n",
              "      <td>0.426080</td>\n",
              "      <td>0.524752</td>\n",
              "      <td>0.132500</td>\n",
              "      <td>0.880000</td>\n",
              "      <td>0.018818</td>\n",
              "      <td>0.515825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.716300</td>\n",
              "      <td>0.698485</td>\n",
              "      <td>0.497500</td>\n",
              "      <td>0.605108</td>\n",
              "      <td>0.457193</td>\n",
              "      <td>0.498382</td>\n",
              "      <td>0.770000</td>\n",
              "      <td>0.225000</td>\n",
              "      <td>-0.005963</td>\n",
              "      <td>0.508319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.706100</td>\n",
              "      <td>0.689573</td>\n",
              "      <td>0.556250</td>\n",
              "      <td>0.561187</td>\n",
              "      <td>0.556194</td>\n",
              "      <td>0.555012</td>\n",
              "      <td>0.567500</td>\n",
              "      <td>0.545000</td>\n",
              "      <td>0.112528</td>\n",
              "      <td>0.554125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.667800</td>\n",
              "      <td>0.707071</td>\n",
              "      <td>0.526250</td>\n",
              "      <td>0.646125</td>\n",
              "      <td>0.464839</td>\n",
              "      <td>0.515648</td>\n",
              "      <td>0.865000</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>0.071378</td>\n",
              "      <td>0.546381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.630200</td>\n",
              "      <td>0.702232</td>\n",
              "      <td>0.563750</td>\n",
              "      <td>0.585018</td>\n",
              "      <td>0.562601</td>\n",
              "      <td>0.557823</td>\n",
              "      <td>0.615000</td>\n",
              "      <td>0.512500</td>\n",
              "      <td>0.128175</td>\n",
              "      <td>0.594719</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 1694, total number of training (for each informative and uninform class) and test samples: 400, 6800 0.05 ALBERT-L 1694 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:29, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.714100</td>\n",
              "      <td>0.698786</td>\n",
              "      <td>0.505000</td>\n",
              "      <td>0.641953</td>\n",
              "      <td>0.420167</td>\n",
              "      <td>0.502833</td>\n",
              "      <td>0.887500</td>\n",
              "      <td>0.122500</td>\n",
              "      <td>0.015527</td>\n",
              "      <td>0.478337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.634900</td>\n",
              "      <td>0.640969</td>\n",
              "      <td>0.631250</td>\n",
              "      <td>0.628931</td>\n",
              "      <td>0.631236</td>\n",
              "      <td>0.632911</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.637500</td>\n",
              "      <td>0.262521</td>\n",
              "      <td>0.688769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.568600</td>\n",
              "      <td>0.663234</td>\n",
              "      <td>0.657500</td>\n",
              "      <td>0.707265</td>\n",
              "      <td>0.647307</td>\n",
              "      <td>0.617537</td>\n",
              "      <td>0.827500</td>\n",
              "      <td>0.487500</td>\n",
              "      <td>0.334955</td>\n",
              "      <td>0.733300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.243200</td>\n",
              "      <td>0.785635</td>\n",
              "      <td>0.691250</td>\n",
              "      <td>0.709753</td>\n",
              "      <td>0.689990</td>\n",
              "      <td>0.669623</td>\n",
              "      <td>0.755000</td>\n",
              "      <td>0.627500</td>\n",
              "      <td>0.385647</td>\n",
              "      <td>0.756594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.117200</td>\n",
              "      <td>1.152949</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.705882</td>\n",
              "      <td>0.699880</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.720000</td>\n",
              "      <td>0.680000</td>\n",
              "      <td>0.400320</td>\n",
              "      <td>0.749656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.062300</td>\n",
              "      <td>1.348336</td>\n",
              "      <td>0.703750</td>\n",
              "      <td>0.705590</td>\n",
              "      <td>0.703738</td>\n",
              "      <td>0.701235</td>\n",
              "      <td>0.710000</td>\n",
              "      <td>0.697500</td>\n",
              "      <td>0.407532</td>\n",
              "      <td>0.748181</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 9741, total number of training (for each informative and uninform class) and test samples: 400, 6800 0.05 ALBERT-L 9741 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:29, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.709500</td>\n",
              "      <td>0.700779</td>\n",
              "      <td>0.486250</td>\n",
              "      <td>0.575851</td>\n",
              "      <td>0.462252</td>\n",
              "      <td>0.490334</td>\n",
              "      <td>0.697500</td>\n",
              "      <td>0.275000</td>\n",
              "      <td>-0.030341</td>\n",
              "      <td>0.438356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.716100</td>\n",
              "      <td>0.690147</td>\n",
              "      <td>0.510000</td>\n",
              "      <td>0.433526</td>\n",
              "      <td>0.500904</td>\n",
              "      <td>0.513699</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.645000</td>\n",
              "      <td>0.020771</td>\n",
              "      <td>0.538750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.700600</td>\n",
              "      <td>0.695293</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.585062</td>\n",
              "      <td>0.478066</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.705000</td>\n",
              "      <td>0.295000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.509669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.716800</td>\n",
              "      <td>0.694896</td>\n",
              "      <td>0.510000</td>\n",
              "      <td>0.644283</td>\n",
              "      <td>0.428567</td>\n",
              "      <td>0.505698</td>\n",
              "      <td>0.887500</td>\n",
              "      <td>0.132500</td>\n",
              "      <td>0.030501</td>\n",
              "      <td>0.529794</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.712400</td>\n",
              "      <td>0.695675</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.480041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.708000</td>\n",
              "      <td>0.695131</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.495266</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 200, total number of training (for each informative and uninform class) and test samples: 400, 6800 0.05 ALBERT-L 200 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:29, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.679000</td>\n",
              "      <td>0.665030</td>\n",
              "      <td>0.581250</td>\n",
              "      <td>0.694064</td>\n",
              "      <td>0.515349</td>\n",
              "      <td>0.546763</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.212500</td>\n",
              "      <td>0.240617</td>\n",
              "      <td>0.701744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.609500</td>\n",
              "      <td>0.647006</td>\n",
              "      <td>0.637500</td>\n",
              "      <td>0.683406</td>\n",
              "      <td>0.629715</td>\n",
              "      <td>0.606589</td>\n",
              "      <td>0.782500</td>\n",
              "      <td>0.492500</td>\n",
              "      <td>0.287348</td>\n",
              "      <td>0.703425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.445400</td>\n",
              "      <td>0.728131</td>\n",
              "      <td>0.672500</td>\n",
              "      <td>0.644022</td>\n",
              "      <td>0.670390</td>\n",
              "      <td>0.705357</td>\n",
              "      <td>0.592500</td>\n",
              "      <td>0.752500</td>\n",
              "      <td>0.349503</td>\n",
              "      <td>0.737569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.322500</td>\n",
              "      <td>0.891602</td>\n",
              "      <td>0.681250</td>\n",
              "      <td>0.716981</td>\n",
              "      <td>0.676087</td>\n",
              "      <td>0.644711</td>\n",
              "      <td>0.807500</td>\n",
              "      <td>0.555000</td>\n",
              "      <td>0.374639</td>\n",
              "      <td>0.767044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.147300</td>\n",
              "      <td>1.152656</td>\n",
              "      <td>0.708750</td>\n",
              "      <td>0.697009</td>\n",
              "      <td>0.708312</td>\n",
              "      <td>0.726287</td>\n",
              "      <td>0.670000</td>\n",
              "      <td>0.747500</td>\n",
              "      <td>0.418759</td>\n",
              "      <td>0.757288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.083800</td>\n",
              "      <td>1.288849</td>\n",
              "      <td>0.702500</td>\n",
              "      <td>0.709046</td>\n",
              "      <td>0.702349</td>\n",
              "      <td>0.693780</td>\n",
              "      <td>0.725000</td>\n",
              "      <td>0.680000</td>\n",
              "      <td>0.405411</td>\n",
              "      <td>0.755481</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 999, total number of training (for each informative and uninform class) and test samples: 400, 6800 0.05 ALBERT-L 999 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:30, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.747100</td>\n",
              "      <td>0.733643</td>\n",
              "      <td>0.498750</td>\n",
              "      <td>0.004963</td>\n",
              "      <td>0.334979</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.002500</td>\n",
              "      <td>0.995000</td>\n",
              "      <td>-0.020451</td>\n",
              "      <td>0.533406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.752800</td>\n",
              "      <td>0.698801</td>\n",
              "      <td>0.505000</td>\n",
              "      <td>0.024631</td>\n",
              "      <td>0.346486</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.012500</td>\n",
              "      <td>0.997500</td>\n",
              "      <td>0.057953</td>\n",
              "      <td>0.472869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.723900</td>\n",
              "      <td>0.703019</td>\n",
              "      <td>0.495000</td>\n",
              "      <td>0.161826</td>\n",
              "      <td>0.400233</td>\n",
              "      <td>0.475610</td>\n",
              "      <td>0.097500</td>\n",
              "      <td>0.892500</td>\n",
              "      <td>-0.016485</td>\n",
              "      <td>0.472625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.680000</td>\n",
              "      <td>0.721366</td>\n",
              "      <td>0.521250</td>\n",
              "      <td>0.631376</td>\n",
              "      <td>0.474333</td>\n",
              "      <td>0.513302</td>\n",
              "      <td>0.820000</td>\n",
              "      <td>0.222500</td>\n",
              "      <td>0.053001</td>\n",
              "      <td>0.531981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.721700</td>\n",
              "      <td>0.702018</td>\n",
              "      <td>0.498750</td>\n",
              "      <td>0.141328</td>\n",
              "      <td>0.393700</td>\n",
              "      <td>0.492537</td>\n",
              "      <td>0.082500</td>\n",
              "      <td>0.915000</td>\n",
              "      <td>-0.004512</td>\n",
              "      <td>0.474231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.700700</td>\n",
              "      <td>0.719223</td>\n",
              "      <td>0.445000</td>\n",
              "      <td>0.562992</td>\n",
              "      <td>0.401359</td>\n",
              "      <td>0.464286</td>\n",
              "      <td>0.715000</td>\n",
              "      <td>0.175000</td>\n",
              "      <td>-0.130693</td>\n",
              "      <td>0.443812</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 94, total number of training (for each informative and uninform class) and test samples: 400, 6800 0.05 DISRoBERTa-B 94 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilbert/distilroberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:10, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.680000</td>\n",
              "      <td>0.652215</td>\n",
              "      <td>0.682500</td>\n",
              "      <td>0.703271</td>\n",
              "      <td>0.680937</td>\n",
              "      <td>0.660088</td>\n",
              "      <td>0.752500</td>\n",
              "      <td>0.612500</td>\n",
              "      <td>0.368630</td>\n",
              "      <td>0.742894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.495900</td>\n",
              "      <td>0.587044</td>\n",
              "      <td>0.708750</td>\n",
              "      <td>0.714810</td>\n",
              "      <td>0.708618</td>\n",
              "      <td>0.700240</td>\n",
              "      <td>0.730000</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>0.417878</td>\n",
              "      <td>0.789238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.438400</td>\n",
              "      <td>0.722902</td>\n",
              "      <td>0.723750</td>\n",
              "      <td>0.711111</td>\n",
              "      <td>0.723220</td>\n",
              "      <td>0.745205</td>\n",
              "      <td>0.680000</td>\n",
              "      <td>0.767500</td>\n",
              "      <td>0.449223</td>\n",
              "      <td>0.793350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.268600</td>\n",
              "      <td>0.854330</td>\n",
              "      <td>0.710000</td>\n",
              "      <td>0.694737</td>\n",
              "      <td>0.709273</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.660000</td>\n",
              "      <td>0.760000</td>\n",
              "      <td>0.422116</td>\n",
              "      <td>0.790675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.313200</td>\n",
              "      <td>1.096115</td>\n",
              "      <td>0.718750</td>\n",
              "      <td>0.738676</td>\n",
              "      <td>0.717105</td>\n",
              "      <td>0.689805</td>\n",
              "      <td>0.795000</td>\n",
              "      <td>0.642500</td>\n",
              "      <td>0.442678</td>\n",
              "      <td>0.790794</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.068200</td>\n",
              "      <td>1.095108</td>\n",
              "      <td>0.722500</td>\n",
              "      <td>0.725926</td>\n",
              "      <td>0.722457</td>\n",
              "      <td>0.717073</td>\n",
              "      <td>0.735000</td>\n",
              "      <td>0.710000</td>\n",
              "      <td>0.445139</td>\n",
              "      <td>0.795469</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 791, total number of training (for each informative and uninform class) and test samples: 400, 6800 0.05 DISRoBERTa-B 791 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilbert/distilroberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:10, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.666900</td>\n",
              "      <td>0.636477</td>\n",
              "      <td>0.646250</td>\n",
              "      <td>0.708548</td>\n",
              "      <td>0.629314</td>\n",
              "      <td>0.602452</td>\n",
              "      <td>0.860000</td>\n",
              "      <td>0.432500</td>\n",
              "      <td>0.323556</td>\n",
              "      <td>0.743306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.492000</td>\n",
              "      <td>0.654506</td>\n",
              "      <td>0.671250</td>\n",
              "      <td>0.724029</td>\n",
              "      <td>0.658769</td>\n",
              "      <td>0.623870</td>\n",
              "      <td>0.862500</td>\n",
              "      <td>0.480000</td>\n",
              "      <td>0.370689</td>\n",
              "      <td>0.774806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.282200</td>\n",
              "      <td>0.742103</td>\n",
              "      <td>0.705000</td>\n",
              "      <td>0.696658</td>\n",
              "      <td>0.704777</td>\n",
              "      <td>0.716931</td>\n",
              "      <td>0.677500</td>\n",
              "      <td>0.732500</td>\n",
              "      <td>0.410622</td>\n",
              "      <td>0.780675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.211700</td>\n",
              "      <td>1.007723</td>\n",
              "      <td>0.715000</td>\n",
              "      <td>0.704663</td>\n",
              "      <td>0.714650</td>\n",
              "      <td>0.731183</td>\n",
              "      <td>0.680000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.431057</td>\n",
              "      <td>0.780488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.259500</td>\n",
              "      <td>1.223885</td>\n",
              "      <td>0.711250</td>\n",
              "      <td>0.729191</td>\n",
              "      <td>0.709977</td>\n",
              "      <td>0.686534</td>\n",
              "      <td>0.777500</td>\n",
              "      <td>0.645000</td>\n",
              "      <td>0.426258</td>\n",
              "      <td>0.779900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.082100</td>\n",
              "      <td>1.225100</td>\n",
              "      <td>0.706250</td>\n",
              "      <td>0.710947</td>\n",
              "      <td>0.706172</td>\n",
              "      <td>0.699758</td>\n",
              "      <td>0.722500</td>\n",
              "      <td>0.690000</td>\n",
              "      <td>0.412718</td>\n",
              "      <td>0.779450</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 5, total number of training (for each informative and uninform class) and test samples: 400, 6800 0.05 DISRoBERTa-B 5 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilbert/distilroberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:10, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.677700</td>\n",
              "      <td>0.647702</td>\n",
              "      <td>0.617500</td>\n",
              "      <td>0.691532</td>\n",
              "      <td>0.594121</td>\n",
              "      <td>0.579392</td>\n",
              "      <td>0.857500</td>\n",
              "      <td>0.377500</td>\n",
              "      <td>0.267877</td>\n",
              "      <td>0.722162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.560000</td>\n",
              "      <td>0.596801</td>\n",
              "      <td>0.683750</td>\n",
              "      <td>0.693333</td>\n",
              "      <td>0.683441</td>\n",
              "      <td>0.672941</td>\n",
              "      <td>0.715000</td>\n",
              "      <td>0.652500</td>\n",
              "      <td>0.368220</td>\n",
              "      <td>0.757925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.479900</td>\n",
              "      <td>0.636795</td>\n",
              "      <td>0.716250</td>\n",
              "      <td>0.724180</td>\n",
              "      <td>0.716015</td>\n",
              "      <td>0.704492</td>\n",
              "      <td>0.745000</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>0.433217</td>\n",
              "      <td>0.785338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.279600</td>\n",
              "      <td>0.799156</td>\n",
              "      <td>0.702500</td>\n",
              "      <td>0.700252</td>\n",
              "      <td>0.702483</td>\n",
              "      <td>0.705584</td>\n",
              "      <td>0.695000</td>\n",
              "      <td>0.710000</td>\n",
              "      <td>0.405046</td>\n",
              "      <td>0.788606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.194200</td>\n",
              "      <td>0.945197</td>\n",
              "      <td>0.707500</td>\n",
              "      <td>0.703046</td>\n",
              "      <td>0.707434</td>\n",
              "      <td>0.713918</td>\n",
              "      <td>0.692500</td>\n",
              "      <td>0.722500</td>\n",
              "      <td>0.415187</td>\n",
              "      <td>0.792006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.119400</td>\n",
              "      <td>1.028605</td>\n",
              "      <td>0.711250</td>\n",
              "      <td>0.712329</td>\n",
              "      <td>0.711246</td>\n",
              "      <td>0.709677</td>\n",
              "      <td>0.715000</td>\n",
              "      <td>0.707500</td>\n",
              "      <td>0.422512</td>\n",
              "      <td>0.792656</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 6932, total number of training (for each informative and uninform class) and test samples: 400, 6800 0.05 DISRoBERTa-B 6932 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilbert/distilroberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:10, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.671800</td>\n",
              "      <td>0.639560</td>\n",
              "      <td>0.621250</td>\n",
              "      <td>0.695477</td>\n",
              "      <td>0.597325</td>\n",
              "      <td>0.581513</td>\n",
              "      <td>0.865000</td>\n",
              "      <td>0.377500</td>\n",
              "      <td>0.277739</td>\n",
              "      <td>0.748606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.476600</td>\n",
              "      <td>0.692513</td>\n",
              "      <td>0.670000</td>\n",
              "      <td>0.717345</td>\n",
              "      <td>0.660474</td>\n",
              "      <td>0.627341</td>\n",
              "      <td>0.837500</td>\n",
              "      <td>0.502500</td>\n",
              "      <td>0.360851</td>\n",
              "      <td>0.777656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.333200</td>\n",
              "      <td>0.716610</td>\n",
              "      <td>0.708750</td>\n",
              "      <td>0.692206</td>\n",
              "      <td>0.707906</td>\n",
              "      <td>0.733894</td>\n",
              "      <td>0.655000</td>\n",
              "      <td>0.762500</td>\n",
              "      <td>0.419933</td>\n",
              "      <td>0.781775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.259200</td>\n",
              "      <td>1.001525</td>\n",
              "      <td>0.696250</td>\n",
              "      <td>0.715789</td>\n",
              "      <td>0.694807</td>\n",
              "      <td>0.672527</td>\n",
              "      <td>0.765000</td>\n",
              "      <td>0.627500</td>\n",
              "      <td>0.396264</td>\n",
              "      <td>0.786800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.096900</td>\n",
              "      <td>1.147410</td>\n",
              "      <td>0.705000</td>\n",
              "      <td>0.699746</td>\n",
              "      <td>0.704910</td>\n",
              "      <td>0.712435</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>0.722500</td>\n",
              "      <td>0.410251</td>\n",
              "      <td>0.785188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.058300</td>\n",
              "      <td>1.207858</td>\n",
              "      <td>0.708750</td>\n",
              "      <td>0.706179</td>\n",
              "      <td>0.708728</td>\n",
              "      <td>0.712468</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.717500</td>\n",
              "      <td>0.417564</td>\n",
              "      <td>0.784600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 1759, total number of training (for each informative and uninform class) and test samples: 400, 6800 0.05 DISRoBERTa-B 1759 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilbert/distilroberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:10, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.691600</td>\n",
              "      <td>0.651721</td>\n",
              "      <td>0.681250</td>\n",
              "      <td>0.660453</td>\n",
              "      <td>0.680050</td>\n",
              "      <td>0.706553</td>\n",
              "      <td>0.620000</td>\n",
              "      <td>0.742500</td>\n",
              "      <td>0.365251</td>\n",
              "      <td>0.754781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.532900</td>\n",
              "      <td>0.588457</td>\n",
              "      <td>0.712500</td>\n",
              "      <td>0.743875</td>\n",
              "      <td>0.708120</td>\n",
              "      <td>0.670683</td>\n",
              "      <td>0.835000</td>\n",
              "      <td>0.590000</td>\n",
              "      <td>0.438360</td>\n",
              "      <td>0.803512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.370000</td>\n",
              "      <td>0.633293</td>\n",
              "      <td>0.722500</td>\n",
              "      <td>0.721805</td>\n",
              "      <td>0.722498</td>\n",
              "      <td>0.723618</td>\n",
              "      <td>0.720000</td>\n",
              "      <td>0.725000</td>\n",
              "      <td>0.445006</td>\n",
              "      <td>0.804881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.233500</td>\n",
              "      <td>0.867920</td>\n",
              "      <td>0.726250</td>\n",
              "      <td>0.715953</td>\n",
              "      <td>0.725890</td>\n",
              "      <td>0.743935</td>\n",
              "      <td>0.690000</td>\n",
              "      <td>0.762500</td>\n",
              "      <td>0.453694</td>\n",
              "      <td>0.808650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.128200</td>\n",
              "      <td>1.120025</td>\n",
              "      <td>0.735000</td>\n",
              "      <td>0.747017</td>\n",
              "      <td>0.734401</td>\n",
              "      <td>0.714612</td>\n",
              "      <td>0.782500</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>0.472135</td>\n",
              "      <td>0.813487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.121800</td>\n",
              "      <td>1.203391</td>\n",
              "      <td>0.737500</td>\n",
              "      <td>0.744526</td>\n",
              "      <td>0.737301</td>\n",
              "      <td>0.725118</td>\n",
              "      <td>0.765000</td>\n",
              "      <td>0.710000</td>\n",
              "      <td>0.475720</td>\n",
              "      <td>0.808888</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 323, total number of training (for each informative and uninform class) and test samples: 400, 6800 0.05 DISRoBERTa-B 323 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilbert/distilroberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:10, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.691200</td>\n",
              "      <td>0.678414</td>\n",
              "      <td>0.672500</td>\n",
              "      <td>0.702273</td>\n",
              "      <td>0.669192</td>\n",
              "      <td>0.643750</td>\n",
              "      <td>0.772500</td>\n",
              "      <td>0.572500</td>\n",
              "      <td>0.352114</td>\n",
              "      <td>0.768788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.620000</td>\n",
              "      <td>0.653038</td>\n",
              "      <td>0.655000</td>\n",
              "      <td>0.721774</td>\n",
              "      <td>0.633913</td>\n",
              "      <td>0.604730</td>\n",
              "      <td>0.895000</td>\n",
              "      <td>0.415000</td>\n",
              "      <td>0.353370</td>\n",
              "      <td>0.788894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.381600</td>\n",
              "      <td>0.737473</td>\n",
              "      <td>0.663750</td>\n",
              "      <td>0.732338</td>\n",
              "      <td>0.640119</td>\n",
              "      <td>0.608264</td>\n",
              "      <td>0.920000</td>\n",
              "      <td>0.407500</td>\n",
              "      <td>0.381396</td>\n",
              "      <td>0.808650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.310100</td>\n",
              "      <td>0.664259</td>\n",
              "      <td>0.718750</td>\n",
              "      <td>0.738676</td>\n",
              "      <td>0.717105</td>\n",
              "      <td>0.689805</td>\n",
              "      <td>0.795000</td>\n",
              "      <td>0.642500</td>\n",
              "      <td>0.442678</td>\n",
              "      <td>0.812281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.204000</td>\n",
              "      <td>1.000303</td>\n",
              "      <td>0.686250</td>\n",
              "      <td>0.740970</td>\n",
              "      <td>0.671594</td>\n",
              "      <td>0.630931</td>\n",
              "      <td>0.897500</td>\n",
              "      <td>0.475000</td>\n",
              "      <td>0.410983</td>\n",
              "      <td>0.807956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.063800</td>\n",
              "      <td>0.909312</td>\n",
              "      <td>0.718750</td>\n",
              "      <td>0.748040</td>\n",
              "      <td>0.714897</td>\n",
              "      <td>0.677485</td>\n",
              "      <td>0.835000</td>\n",
              "      <td>0.602500</td>\n",
              "      <td>0.449827</td>\n",
              "      <td>0.809962</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 1694, total number of training (for each informative and uninform class) and test samples: 400, 6800 0.05 DISRoBERTa-B 1694 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilbert/distilroberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:10, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.705300</td>\n",
              "      <td>0.685868</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.715413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.604700</td>\n",
              "      <td>0.595470</td>\n",
              "      <td>0.668750</td>\n",
              "      <td>0.684148</td>\n",
              "      <td>0.667961</td>\n",
              "      <td>0.653759</td>\n",
              "      <td>0.717500</td>\n",
              "      <td>0.620000</td>\n",
              "      <td>0.339116</td>\n",
              "      <td>0.755556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.473100</td>\n",
              "      <td>0.633198</td>\n",
              "      <td>0.681250</td>\n",
              "      <td>0.711864</td>\n",
              "      <td>0.677611</td>\n",
              "      <td>0.649485</td>\n",
              "      <td>0.787500</td>\n",
              "      <td>0.575000</td>\n",
              "      <td>0.370973</td>\n",
              "      <td>0.768088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.326200</td>\n",
              "      <td>0.752599</td>\n",
              "      <td>0.697500</td>\n",
              "      <td>0.727477</td>\n",
              "      <td>0.693795</td>\n",
              "      <td>0.661885</td>\n",
              "      <td>0.807500</td>\n",
              "      <td>0.587500</td>\n",
              "      <td>0.404921</td>\n",
              "      <td>0.782056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.244900</td>\n",
              "      <td>0.901985</td>\n",
              "      <td>0.696250</td>\n",
              "      <td>0.698885</td>\n",
              "      <td>0.696227</td>\n",
              "      <td>0.692875</td>\n",
              "      <td>0.705000</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>0.392560</td>\n",
              "      <td>0.770056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.119000</td>\n",
              "      <td>0.974932</td>\n",
              "      <td>0.701250</td>\n",
              "      <td>0.713085</td>\n",
              "      <td>0.700741</td>\n",
              "      <td>0.685912</td>\n",
              "      <td>0.742500</td>\n",
              "      <td>0.660000</td>\n",
              "      <td>0.403877</td>\n",
              "      <td>0.772244</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 9741, total number of training (for each informative and uninform class) and test samples: 400, 6800 0.05 DISRoBERTa-B 9741 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilbert/distilroberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:10, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.678300</td>\n",
              "      <td>0.669021</td>\n",
              "      <td>0.592500</td>\n",
              "      <td>0.375479</td>\n",
              "      <td>0.536534</td>\n",
              "      <td>0.803279</td>\n",
              "      <td>0.245000</td>\n",
              "      <td>0.940000</td>\n",
              "      <td>0.257298</td>\n",
              "      <td>0.712925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.612300</td>\n",
              "      <td>0.547771</td>\n",
              "      <td>0.713750</td>\n",
              "      <td>0.721072</td>\n",
              "      <td>0.713553</td>\n",
              "      <td>0.703088</td>\n",
              "      <td>0.740000</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>0.428090</td>\n",
              "      <td>0.798038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.388400</td>\n",
              "      <td>0.579679</td>\n",
              "      <td>0.731250</td>\n",
              "      <td>0.748538</td>\n",
              "      <td>0.729974</td>\n",
              "      <td>0.703297</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.662500</td>\n",
              "      <td>0.466935</td>\n",
              "      <td>0.811419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.248000</td>\n",
              "      <td>0.711641</td>\n",
              "      <td>0.730000</td>\n",
              "      <td>0.732010</td>\n",
              "      <td>0.729985</td>\n",
              "      <td>0.726601</td>\n",
              "      <td>0.737500</td>\n",
              "      <td>0.722500</td>\n",
              "      <td>0.460052</td>\n",
              "      <td>0.820306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.174900</td>\n",
              "      <td>0.874165</td>\n",
              "      <td>0.730000</td>\n",
              "      <td>0.724490</td>\n",
              "      <td>0.729892</td>\n",
              "      <td>0.739583</td>\n",
              "      <td>0.710000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.460368</td>\n",
              "      <td>0.818450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.115600</td>\n",
              "      <td>0.995682</td>\n",
              "      <td>0.733750</td>\n",
              "      <td>0.713324</td>\n",
              "      <td>0.732391</td>\n",
              "      <td>0.772595</td>\n",
              "      <td>0.662500</td>\n",
              "      <td>0.805000</td>\n",
              "      <td>0.472320</td>\n",
              "      <td>0.812637</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 200, total number of training (for each informative and uninform class) and test samples: 400, 6800 0.05 DISRoBERTa-B 200 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilbert/distilroberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:10, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.688400</td>\n",
              "      <td>0.662100</td>\n",
              "      <td>0.613750</td>\n",
              "      <td>0.701449</td>\n",
              "      <td>0.577273</td>\n",
              "      <td>0.571654</td>\n",
              "      <td>0.907500</td>\n",
              "      <td>0.320000</td>\n",
              "      <td>0.281133</td>\n",
              "      <td>0.737863</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.592900</td>\n",
              "      <td>0.565066</td>\n",
              "      <td>0.692500</td>\n",
              "      <td>0.687817</td>\n",
              "      <td>0.692431</td>\n",
              "      <td>0.698454</td>\n",
              "      <td>0.677500</td>\n",
              "      <td>0.707500</td>\n",
              "      <td>0.385173</td>\n",
              "      <td>0.776256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.377600</td>\n",
              "      <td>0.651432</td>\n",
              "      <td>0.702500</td>\n",
              "      <td>0.734375</td>\n",
              "      <td>0.698153</td>\n",
              "      <td>0.663306</td>\n",
              "      <td>0.822500</td>\n",
              "      <td>0.582500</td>\n",
              "      <td>0.417193</td>\n",
              "      <td>0.789781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.289000</td>\n",
              "      <td>0.717769</td>\n",
              "      <td>0.706250</td>\n",
              "      <td>0.741474</td>\n",
              "      <td>0.700694</td>\n",
              "      <td>0.662083</td>\n",
              "      <td>0.842500</td>\n",
              "      <td>0.570000</td>\n",
              "      <td>0.428725</td>\n",
              "      <td>0.791000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.161100</td>\n",
              "      <td>0.889174</td>\n",
              "      <td>0.717500</td>\n",
              "      <td>0.746637</td>\n",
              "      <td>0.713714</td>\n",
              "      <td>0.676829</td>\n",
              "      <td>0.832500</td>\n",
              "      <td>0.602500</td>\n",
              "      <td>0.446983</td>\n",
              "      <td>0.793969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.113300</td>\n",
              "      <td>0.921625</td>\n",
              "      <td>0.720000</td>\n",
              "      <td>0.735849</td>\n",
              "      <td>0.718988</td>\n",
              "      <td>0.696429</td>\n",
              "      <td>0.780000</td>\n",
              "      <td>0.660000</td>\n",
              "      <td>0.443203</td>\n",
              "      <td>0.792350</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 999, total number of training (for each informative and uninform class) and test samples: 400, 6800 0.05 DISRoBERTa-B 999 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilbert/distilroberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:10, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.685800</td>\n",
              "      <td>0.668823</td>\n",
              "      <td>0.616250</td>\n",
              "      <td>0.710650</td>\n",
              "      <td>0.570539</td>\n",
              "      <td>0.570348</td>\n",
              "      <td>0.942500</td>\n",
              "      <td>0.290000</td>\n",
              "      <td>0.306814</td>\n",
              "      <td>0.754800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.638500</td>\n",
              "      <td>0.606980</td>\n",
              "      <td>0.697500</td>\n",
              "      <td>0.640950</td>\n",
              "      <td>0.689805</td>\n",
              "      <td>0.788321</td>\n",
              "      <td>0.540000</td>\n",
              "      <td>0.855000</td>\n",
              "      <td>0.416187</td>\n",
              "      <td>0.792713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.402200</td>\n",
              "      <td>0.559927</td>\n",
              "      <td>0.748750</td>\n",
              "      <td>0.767092</td>\n",
              "      <td>0.747182</td>\n",
              "      <td>0.714903</td>\n",
              "      <td>0.827500</td>\n",
              "      <td>0.670000</td>\n",
              "      <td>0.503788</td>\n",
              "      <td>0.829412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.304600</td>\n",
              "      <td>0.668967</td>\n",
              "      <td>0.742500</td>\n",
              "      <td>0.760465</td>\n",
              "      <td>0.741043</td>\n",
              "      <td>0.710870</td>\n",
              "      <td>0.817500</td>\n",
              "      <td>0.667500</td>\n",
              "      <td>0.490550</td>\n",
              "      <td>0.827362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.122900</td>\n",
              "      <td>0.756555</td>\n",
              "      <td>0.760000</td>\n",
              "      <td>0.768675</td>\n",
              "      <td>0.759662</td>\n",
              "      <td>0.741860</td>\n",
              "      <td>0.797500</td>\n",
              "      <td>0.722500</td>\n",
              "      <td>0.521469</td>\n",
              "      <td>0.827412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.170500</td>\n",
              "      <td>0.833901</td>\n",
              "      <td>0.757500</td>\n",
              "      <td>0.767386</td>\n",
              "      <td>0.757061</td>\n",
              "      <td>0.737327</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.715000</td>\n",
              "      <td>0.516871</td>\n",
              "      <td>0.825975</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 94, total number of training (for each informative and uninform class) and test samples: 400, 6800 0.05 XLNet-B 94 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:27, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.656900</td>\n",
              "      <td>0.598788</td>\n",
              "      <td>0.675000</td>\n",
              "      <td>0.697674</td>\n",
              "      <td>0.673162</td>\n",
              "      <td>0.652174</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.354005</td>\n",
              "      <td>0.734037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.496100</td>\n",
              "      <td>0.669552</td>\n",
              "      <td>0.686250</td>\n",
              "      <td>0.733262</td>\n",
              "      <td>0.676191</td>\n",
              "      <td>0.637708</td>\n",
              "      <td>0.862500</td>\n",
              "      <td>0.510000</td>\n",
              "      <td>0.398050</td>\n",
              "      <td>0.767169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.353500</td>\n",
              "      <td>0.790671</td>\n",
              "      <td>0.695000</td>\n",
              "      <td>0.736501</td>\n",
              "      <td>0.687242</td>\n",
              "      <td>0.648289</td>\n",
              "      <td>0.852500</td>\n",
              "      <td>0.537500</td>\n",
              "      <td>0.410919</td>\n",
              "      <td>0.781119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.194200</td>\n",
              "      <td>1.027877</td>\n",
              "      <td>0.701250</td>\n",
              "      <td>0.685112</td>\n",
              "      <td>0.700463</td>\n",
              "      <td>0.724234</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>0.752500</td>\n",
              "      <td>0.404631</td>\n",
              "      <td>0.774913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.174500</td>\n",
              "      <td>1.238733</td>\n",
              "      <td>0.710000</td>\n",
              "      <td>0.736364</td>\n",
              "      <td>0.707071</td>\n",
              "      <td>0.675000</td>\n",
              "      <td>0.810000</td>\n",
              "      <td>0.610000</td>\n",
              "      <td>0.428661</td>\n",
              "      <td>0.774713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.098300</td>\n",
              "      <td>1.311127</td>\n",
              "      <td>0.710000</td>\n",
              "      <td>0.719807</td>\n",
              "      <td>0.709644</td>\n",
              "      <td>0.696262</td>\n",
              "      <td>0.745000</td>\n",
              "      <td>0.675000</td>\n",
              "      <td>0.421033</td>\n",
              "      <td>0.773687</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 791, total number of training (for each informative and uninform class) and test samples: 400, 6800 0.05 XLNet-B 791 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:27, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.690500</td>\n",
              "      <td>0.681241</td>\n",
              "      <td>0.592500</td>\n",
              "      <td>0.694757</td>\n",
              "      <td>0.540987</td>\n",
              "      <td>0.555389</td>\n",
              "      <td>0.927500</td>\n",
              "      <td>0.257500</td>\n",
              "      <td>0.249205</td>\n",
              "      <td>0.666606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.558500</td>\n",
              "      <td>0.667460</td>\n",
              "      <td>0.657500</td>\n",
              "      <td>0.716942</td>\n",
              "      <td>0.641699</td>\n",
              "      <td>0.610915</td>\n",
              "      <td>0.867500</td>\n",
              "      <td>0.447500</td>\n",
              "      <td>0.347098</td>\n",
              "      <td>0.753656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.409400</td>\n",
              "      <td>0.679648</td>\n",
              "      <td>0.698750</td>\n",
              "      <td>0.679095</td>\n",
              "      <td>0.697616</td>\n",
              "      <td>0.726496</td>\n",
              "      <td>0.637500</td>\n",
              "      <td>0.760000</td>\n",
              "      <td>0.400516</td>\n",
              "      <td>0.764000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.356300</td>\n",
              "      <td>0.761828</td>\n",
              "      <td>0.691250</td>\n",
              "      <td>0.717714</td>\n",
              "      <td>0.688512</td>\n",
              "      <td>0.661053</td>\n",
              "      <td>0.785000</td>\n",
              "      <td>0.597500</td>\n",
              "      <td>0.389406</td>\n",
              "      <td>0.771056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.312000</td>\n",
              "      <td>0.988342</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>0.733475</td>\n",
              "      <td>0.677916</td>\n",
              "      <td>0.639405</td>\n",
              "      <td>0.860000</td>\n",
              "      <td>0.515000</td>\n",
              "      <td>0.399530</td>\n",
              "      <td>0.773900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.110500</td>\n",
              "      <td>0.950831</td>\n",
              "      <td>0.693750</td>\n",
              "      <td>0.717416</td>\n",
              "      <td>0.691587</td>\n",
              "      <td>0.665953</td>\n",
              "      <td>0.777500</td>\n",
              "      <td>0.610000</td>\n",
              "      <td>0.393053</td>\n",
              "      <td>0.775762</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 5, total number of training (for each informative and uninform class) and test samples: 400, 6800 0.05 XLNet-B 5 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:27, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.692700</td>\n",
              "      <td>0.648446</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.694501</td>\n",
              "      <td>0.604532</td>\n",
              "      <td>0.585911</td>\n",
              "      <td>0.852500</td>\n",
              "      <td>0.397500</td>\n",
              "      <td>0.280744</td>\n",
              "      <td>0.696125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.563700</td>\n",
              "      <td>0.670941</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>0.692982</td>\n",
              "      <td>0.643003</td>\n",
              "      <td>0.617188</td>\n",
              "      <td>0.790000</td>\n",
              "      <td>0.510000</td>\n",
              "      <td>0.312500</td>\n",
              "      <td>0.719669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.470500</td>\n",
              "      <td>0.864940</td>\n",
              "      <td>0.662500</td>\n",
              "      <td>0.720497</td>\n",
              "      <td>0.647315</td>\n",
              "      <td>0.614841</td>\n",
              "      <td>0.870000</td>\n",
              "      <td>0.455000</td>\n",
              "      <td>0.357213</td>\n",
              "      <td>0.749912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.323800</td>\n",
              "      <td>0.837602</td>\n",
              "      <td>0.693750</td>\n",
              "      <td>0.714785</td>\n",
              "      <td>0.692075</td>\n",
              "      <td>0.668845</td>\n",
              "      <td>0.767500</td>\n",
              "      <td>0.620000</td>\n",
              "      <td>0.391785</td>\n",
              "      <td>0.747569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.172600</td>\n",
              "      <td>1.037528</td>\n",
              "      <td>0.696250</td>\n",
              "      <td>0.712426</td>\n",
              "      <td>0.695286</td>\n",
              "      <td>0.676404</td>\n",
              "      <td>0.752500</td>\n",
              "      <td>0.640000</td>\n",
              "      <td>0.395008</td>\n",
              "      <td>0.752506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.177200</td>\n",
              "      <td>1.150635</td>\n",
              "      <td>0.695000</td>\n",
              "      <td>0.706731</td>\n",
              "      <td>0.694511</td>\n",
              "      <td>0.680556</td>\n",
              "      <td>0.735000</td>\n",
              "      <td>0.655000</td>\n",
              "      <td>0.391254</td>\n",
              "      <td>0.749869</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 6932, total number of training (for each informative and uninform class) and test samples: 400, 6800 0.05 XLNet-B 6932 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:27, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.687600</td>\n",
              "      <td>0.656940</td>\n",
              "      <td>0.646250</td>\n",
              "      <td>0.696026</td>\n",
              "      <td>0.636503</td>\n",
              "      <td>0.610169</td>\n",
              "      <td>0.810000</td>\n",
              "      <td>0.482500</td>\n",
              "      <td>0.309573</td>\n",
              "      <td>0.713806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.556900</td>\n",
              "      <td>0.635882</td>\n",
              "      <td>0.663750</td>\n",
              "      <td>0.693273</td>\n",
              "      <td>0.660606</td>\n",
              "      <td>0.637317</td>\n",
              "      <td>0.760000</td>\n",
              "      <td>0.567500</td>\n",
              "      <td>0.333742</td>\n",
              "      <td>0.740950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.534400</td>\n",
              "      <td>0.610924</td>\n",
              "      <td>0.697500</td>\n",
              "      <td>0.695214</td>\n",
              "      <td>0.697483</td>\n",
              "      <td>0.700508</td>\n",
              "      <td>0.690000</td>\n",
              "      <td>0.705000</td>\n",
              "      <td>0.395044</td>\n",
              "      <td>0.762050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.376300</td>\n",
              "      <td>0.667253</td>\n",
              "      <td>0.695000</td>\n",
              "      <td>0.677249</td>\n",
              "      <td>0.694075</td>\n",
              "      <td>0.719101</td>\n",
              "      <td>0.640000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.392381</td>\n",
              "      <td>0.771556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.263600</td>\n",
              "      <td>0.829200</td>\n",
              "      <td>0.703750</td>\n",
              "      <td>0.686922</td>\n",
              "      <td>0.702892</td>\n",
              "      <td>0.728291</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>0.757500</td>\n",
              "      <td>0.409875</td>\n",
              "      <td>0.767125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.167600</td>\n",
              "      <td>0.929147</td>\n",
              "      <td>0.703750</td>\n",
              "      <td>0.681879</td>\n",
              "      <td>0.702343</td>\n",
              "      <td>0.736232</td>\n",
              "      <td>0.635000</td>\n",
              "      <td>0.772500</td>\n",
              "      <td>0.411408</td>\n",
              "      <td>0.766994</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 1759, total number of training (for each informative and uninform class) and test samples: 400, 6800 0.05 XLNet-B 1759 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:27, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.709600</td>\n",
              "      <td>0.668215</td>\n",
              "      <td>0.567500</td>\n",
              "      <td>0.324219</td>\n",
              "      <td>0.503102</td>\n",
              "      <td>0.741071</td>\n",
              "      <td>0.207500</td>\n",
              "      <td>0.927500</td>\n",
              "      <td>0.194532</td>\n",
              "      <td>0.701862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.651400</td>\n",
              "      <td>0.643863</td>\n",
              "      <td>0.636250</td>\n",
              "      <td>0.710448</td>\n",
              "      <td>0.610686</td>\n",
              "      <td>0.590083</td>\n",
              "      <td>0.892500</td>\n",
              "      <td>0.380000</td>\n",
              "      <td>0.317345</td>\n",
              "      <td>0.766806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.586400</td>\n",
              "      <td>0.587975</td>\n",
              "      <td>0.695000</td>\n",
              "      <td>0.648415</td>\n",
              "      <td>0.689550</td>\n",
              "      <td>0.765306</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>0.827500</td>\n",
              "      <td>0.404460</td>\n",
              "      <td>0.789837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.528700</td>\n",
              "      <td>0.662144</td>\n",
              "      <td>0.708750</td>\n",
              "      <td>0.729384</td>\n",
              "      <td>0.707047</td>\n",
              "      <td>0.681128</td>\n",
              "      <td>0.785000</td>\n",
              "      <td>0.632500</td>\n",
              "      <td>0.422441</td>\n",
              "      <td>0.802706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.311100</td>\n",
              "      <td>0.682149</td>\n",
              "      <td>0.730000</td>\n",
              "      <td>0.727960</td>\n",
              "      <td>0.729985</td>\n",
              "      <td>0.733503</td>\n",
              "      <td>0.722500</td>\n",
              "      <td>0.737500</td>\n",
              "      <td>0.460052</td>\n",
              "      <td>0.805662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.287400</td>\n",
              "      <td>0.719817</td>\n",
              "      <td>0.735000</td>\n",
              "      <td>0.735000</td>\n",
              "      <td>0.735000</td>\n",
              "      <td>0.735000</td>\n",
              "      <td>0.735000</td>\n",
              "      <td>0.735000</td>\n",
              "      <td>0.470000</td>\n",
              "      <td>0.807562</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 323, total number of training (for each informative and uninform class) and test samples: 400, 6800 0.05 XLNet-B 323 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:27, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.697000</td>\n",
              "      <td>0.689800</td>\n",
              "      <td>0.571250</td>\n",
              "      <td>0.528198</td>\n",
              "      <td>0.567650</td>\n",
              "      <td>0.587156</td>\n",
              "      <td>0.480000</td>\n",
              "      <td>0.662500</td>\n",
              "      <td>0.144934</td>\n",
              "      <td>0.609019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.690700</td>\n",
              "      <td>0.744950</td>\n",
              "      <td>0.530000</td>\n",
              "      <td>0.669596</td>\n",
              "      <td>0.427871</td>\n",
              "      <td>0.516260</td>\n",
              "      <td>0.952500</td>\n",
              "      <td>0.107500</td>\n",
              "      <td>0.112199</td>\n",
              "      <td>0.717050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.496800</td>\n",
              "      <td>0.777188</td>\n",
              "      <td>0.620000</td>\n",
              "      <td>0.711575</td>\n",
              "      <td>0.577399</td>\n",
              "      <td>0.573394</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.302500</td>\n",
              "      <td>0.310675</td>\n",
              "      <td>0.767244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.423700</td>\n",
              "      <td>0.618978</td>\n",
              "      <td>0.713750</td>\n",
              "      <td>0.711223</td>\n",
              "      <td>0.713728</td>\n",
              "      <td>0.717557</td>\n",
              "      <td>0.705000</td>\n",
              "      <td>0.722500</td>\n",
              "      <td>0.427565</td>\n",
              "      <td>0.779250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.279100</td>\n",
              "      <td>0.878165</td>\n",
              "      <td>0.677500</td>\n",
              "      <td>0.731809</td>\n",
              "      <td>0.663710</td>\n",
              "      <td>0.626335</td>\n",
              "      <td>0.880000</td>\n",
              "      <td>0.475000</td>\n",
              "      <td>0.388268</td>\n",
              "      <td>0.777663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.171400</td>\n",
              "      <td>0.803585</td>\n",
              "      <td>0.712500</td>\n",
              "      <td>0.728132</td>\n",
              "      <td>0.711546</td>\n",
              "      <td>0.690583</td>\n",
              "      <td>0.770000</td>\n",
              "      <td>0.655000</td>\n",
              "      <td>0.427838</td>\n",
              "      <td>0.781331</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 1694, total number of training (for each informative and uninform class) and test samples: 400, 6800 0.05 XLNet-B 1694 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:27, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.715000</td>\n",
              "      <td>0.659503</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.532164</td>\n",
              "      <td>0.591409</td>\n",
              "      <td>0.640845</td>\n",
              "      <td>0.455000</td>\n",
              "      <td>0.745000</td>\n",
              "      <td>0.208981</td>\n",
              "      <td>0.630756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.614400</td>\n",
              "      <td>0.711174</td>\n",
              "      <td>0.616250</td>\n",
              "      <td>0.686415</td>\n",
              "      <td>0.596025</td>\n",
              "      <td>0.580311</td>\n",
              "      <td>0.840000</td>\n",
              "      <td>0.392500</td>\n",
              "      <td>0.259985</td>\n",
              "      <td>0.684931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.552000</td>\n",
              "      <td>0.642106</td>\n",
              "      <td>0.677500</td>\n",
              "      <td>0.691388</td>\n",
              "      <td>0.676846</td>\n",
              "      <td>0.662844</td>\n",
              "      <td>0.722500</td>\n",
              "      <td>0.632500</td>\n",
              "      <td>0.356447</td>\n",
              "      <td>0.727856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.426700</td>\n",
              "      <td>0.761418</td>\n",
              "      <td>0.655000</td>\n",
              "      <td>0.709474</td>\n",
              "      <td>0.642429</td>\n",
              "      <td>0.612727</td>\n",
              "      <td>0.842500</td>\n",
              "      <td>0.467500</td>\n",
              "      <td>0.334403</td>\n",
              "      <td>0.740519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.339900</td>\n",
              "      <td>0.777309</td>\n",
              "      <td>0.675000</td>\n",
              "      <td>0.703196</td>\n",
              "      <td>0.672040</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.770000</td>\n",
              "      <td>0.580000</td>\n",
              "      <td>0.356494</td>\n",
              "      <td>0.745650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.304300</td>\n",
              "      <td>0.817915</td>\n",
              "      <td>0.683750</td>\n",
              "      <td>0.716685</td>\n",
              "      <td>0.679418</td>\n",
              "      <td>0.649087</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.567500</td>\n",
              "      <td>0.377855</td>\n",
              "      <td>0.749437</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 9741, total number of training (for each informative and uninform class) and test samples: 400, 6800 0.05 XLNet-B 9741 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:27, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.717600</td>\n",
              "      <td>0.656388</td>\n",
              "      <td>0.608750</td>\n",
              "      <td>0.598203</td>\n",
              "      <td>0.608480</td>\n",
              "      <td>0.614776</td>\n",
              "      <td>0.582500</td>\n",
              "      <td>0.635000</td>\n",
              "      <td>0.217800</td>\n",
              "      <td>0.645556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.639700</td>\n",
              "      <td>0.646117</td>\n",
              "      <td>0.637500</td>\n",
              "      <td>0.690171</td>\n",
              "      <td>0.626712</td>\n",
              "      <td>0.602612</td>\n",
              "      <td>0.807500</td>\n",
              "      <td>0.467500</td>\n",
              "      <td>0.292421</td>\n",
              "      <td>0.693488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.517500</td>\n",
              "      <td>0.631160</td>\n",
              "      <td>0.678750</td>\n",
              "      <td>0.714127</td>\n",
              "      <td>0.673754</td>\n",
              "      <td>0.643287</td>\n",
              "      <td>0.802500</td>\n",
              "      <td>0.555000</td>\n",
              "      <td>0.368980</td>\n",
              "      <td>0.745319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.388900</td>\n",
              "      <td>0.821089</td>\n",
              "      <td>0.662500</td>\n",
              "      <td>0.726166</td>\n",
              "      <td>0.643213</td>\n",
              "      <td>0.610922</td>\n",
              "      <td>0.895000</td>\n",
              "      <td>0.430000</td>\n",
              "      <td>0.367103</td>\n",
              "      <td>0.760613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.347100</td>\n",
              "      <td>0.731846</td>\n",
              "      <td>0.698750</td>\n",
              "      <td>0.725200</td>\n",
              "      <td>0.695933</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.795000</td>\n",
              "      <td>0.602500</td>\n",
              "      <td>0.405076</td>\n",
              "      <td>0.773281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.302100</td>\n",
              "      <td>0.783625</td>\n",
              "      <td>0.707500</td>\n",
              "      <td>0.732877</td>\n",
              "      <td>0.704836</td>\n",
              "      <td>0.674370</td>\n",
              "      <td>0.802500</td>\n",
              "      <td>0.612500</td>\n",
              "      <td>0.422700</td>\n",
              "      <td>0.776381</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 200, total number of training (for each informative and uninform class) and test samples: 400, 6800 0.05 XLNet-B 200 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:27, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.697200</td>\n",
              "      <td>0.638758</td>\n",
              "      <td>0.630000</td>\n",
              "      <td>0.676149</td>\n",
              "      <td>0.622331</td>\n",
              "      <td>0.601167</td>\n",
              "      <td>0.772500</td>\n",
              "      <td>0.487500</td>\n",
              "      <td>0.271249</td>\n",
              "      <td>0.695119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.624100</td>\n",
              "      <td>0.593597</td>\n",
              "      <td>0.675000</td>\n",
              "      <td>0.701835</td>\n",
              "      <td>0.672346</td>\n",
              "      <td>0.648305</td>\n",
              "      <td>0.765000</td>\n",
              "      <td>0.585000</td>\n",
              "      <td>0.355812</td>\n",
              "      <td>0.757275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.426000</td>\n",
              "      <td>0.715864</td>\n",
              "      <td>0.653750</td>\n",
              "      <td>0.702470</td>\n",
              "      <td>0.644210</td>\n",
              "      <td>0.615819</td>\n",
              "      <td>0.817500</td>\n",
              "      <td>0.490000</td>\n",
              "      <td>0.325448</td>\n",
              "      <td>0.760300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.352600</td>\n",
              "      <td>0.740571</td>\n",
              "      <td>0.673750</td>\n",
              "      <td>0.712871</td>\n",
              "      <td>0.667579</td>\n",
              "      <td>0.636542</td>\n",
              "      <td>0.810000</td>\n",
              "      <td>0.537500</td>\n",
              "      <td>0.361168</td>\n",
              "      <td>0.769262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.281900</td>\n",
              "      <td>0.883933</td>\n",
              "      <td>0.690000</td>\n",
              "      <td>0.730435</td>\n",
              "      <td>0.682864</td>\n",
              "      <td>0.646154</td>\n",
              "      <td>0.840000</td>\n",
              "      <td>0.540000</td>\n",
              "      <td>0.398348</td>\n",
              "      <td>0.775231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.160000</td>\n",
              "      <td>0.914198</td>\n",
              "      <td>0.702500</td>\n",
              "      <td>0.723898</td>\n",
              "      <td>0.700702</td>\n",
              "      <td>0.675325</td>\n",
              "      <td>0.780000</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.409955</td>\n",
              "      <td>0.775137</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 999, total number of training (for each informative and uninform class) and test samples: 400, 6800 0.05 XLNet-B 999 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:27, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.678100</td>\n",
              "      <td>0.628233</td>\n",
              "      <td>0.655000</td>\n",
              "      <td>0.718367</td>\n",
              "      <td>0.636603</td>\n",
              "      <td>0.606897</td>\n",
              "      <td>0.880000</td>\n",
              "      <td>0.430000</td>\n",
              "      <td>0.347133</td>\n",
              "      <td>0.736431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.597600</td>\n",
              "      <td>0.705432</td>\n",
              "      <td>0.663750</td>\n",
              "      <td>0.573693</td>\n",
              "      <td>0.648043</td>\n",
              "      <td>0.783550</td>\n",
              "      <td>0.452500</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.361334</td>\n",
              "      <td>0.765781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.430800</td>\n",
              "      <td>0.677726</td>\n",
              "      <td>0.716250</td>\n",
              "      <td>0.718711</td>\n",
              "      <td>0.716228</td>\n",
              "      <td>0.712531</td>\n",
              "      <td>0.725000</td>\n",
              "      <td>0.707500</td>\n",
              "      <td>0.432566</td>\n",
              "      <td>0.779444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.312100</td>\n",
              "      <td>0.738466</td>\n",
              "      <td>0.725000</td>\n",
              "      <td>0.722222</td>\n",
              "      <td>0.724972</td>\n",
              "      <td>0.729592</td>\n",
              "      <td>0.715000</td>\n",
              "      <td>0.735000</td>\n",
              "      <td>0.450090</td>\n",
              "      <td>0.787669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.157800</td>\n",
              "      <td>0.820273</td>\n",
              "      <td>0.733750</td>\n",
              "      <td>0.743682</td>\n",
              "      <td>0.733350</td>\n",
              "      <td>0.716937</td>\n",
              "      <td>0.772500</td>\n",
              "      <td>0.695000</td>\n",
              "      <td>0.468910</td>\n",
              "      <td>0.792844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.134100</td>\n",
              "      <td>0.992208</td>\n",
              "      <td>0.715000</td>\n",
              "      <td>0.690217</td>\n",
              "      <td>0.713164</td>\n",
              "      <td>0.755952</td>\n",
              "      <td>0.635000</td>\n",
              "      <td>0.795000</td>\n",
              "      <td>0.435612</td>\n",
              "      <td>0.790956</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 94, total number of training (for each informative and uninform class) and test samples: 400, 6800 0.05 XLNet-L 94 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-large-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:55, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.731200</td>\n",
              "      <td>0.702227</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.573731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.703400</td>\n",
              "      <td>0.704024</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.653603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.685200</td>\n",
              "      <td>0.701278</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.653544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.735100</td>\n",
              "      <td>0.709201</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.650069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.696200</td>\n",
              "      <td>0.696441</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.634394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.706000</td>\n",
              "      <td>0.694256</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.646944</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 791, total number of training (for each informative and uninform class) and test samples: 400, 6800 0.05 XLNet-L 791 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-large-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:55, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.713900</td>\n",
              "      <td>0.770466</td>\n",
              "      <td>0.488750</td>\n",
              "      <td>0.651321</td>\n",
              "      <td>0.346738</td>\n",
              "      <td>0.494179</td>\n",
              "      <td>0.955000</td>\n",
              "      <td>0.022500</td>\n",
              "      <td>-0.062298</td>\n",
              "      <td>0.589081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.660100</td>\n",
              "      <td>0.777534</td>\n",
              "      <td>0.558750</td>\n",
              "      <td>0.687887</td>\n",
              "      <td>0.467611</td>\n",
              "      <td>0.532148</td>\n",
              "      <td>0.972500</td>\n",
              "      <td>0.145000</td>\n",
              "      <td>0.209274</td>\n",
              "      <td>0.648487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.582600</td>\n",
              "      <td>0.725790</td>\n",
              "      <td>0.630000</td>\n",
              "      <td>0.687764</td>\n",
              "      <td>0.616888</td>\n",
              "      <td>0.594891</td>\n",
              "      <td>0.815000</td>\n",
              "      <td>0.445000</td>\n",
              "      <td>0.279861</td>\n",
              "      <td>0.703819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.547000</td>\n",
              "      <td>0.683071</td>\n",
              "      <td>0.671250</td>\n",
              "      <td>0.708749</td>\n",
              "      <td>0.665709</td>\n",
              "      <td>0.636183</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.542500</td>\n",
              "      <td>0.354453</td>\n",
              "      <td>0.728562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.546600</td>\n",
              "      <td>0.946607</td>\n",
              "      <td>0.610000</td>\n",
              "      <td>0.705104</td>\n",
              "      <td>0.564729</td>\n",
              "      <td>0.566869</td>\n",
              "      <td>0.932500</td>\n",
              "      <td>0.287500</td>\n",
              "      <td>0.287889</td>\n",
              "      <td>0.726875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.354400</td>\n",
              "      <td>0.766991</td>\n",
              "      <td>0.653750</td>\n",
              "      <td>0.702470</td>\n",
              "      <td>0.644210</td>\n",
              "      <td>0.615819</td>\n",
              "      <td>0.817500</td>\n",
              "      <td>0.490000</td>\n",
              "      <td>0.325448</td>\n",
              "      <td>0.737550</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 5, total number of training (for each informative and uninform class) and test samples: 400, 6800 0.05 XLNet-L 5 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-large-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:55, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.721100</td>\n",
              "      <td>0.667721</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.594937</td>\n",
              "      <td>0.599937</td>\n",
              "      <td>0.602564</td>\n",
              "      <td>0.587500</td>\n",
              "      <td>0.612500</td>\n",
              "      <td>0.200063</td>\n",
              "      <td>0.628406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.675600</td>\n",
              "      <td>0.650984</td>\n",
              "      <td>0.633750</td>\n",
              "      <td>0.670416</td>\n",
              "      <td>0.629160</td>\n",
              "      <td>0.609407</td>\n",
              "      <td>0.745000</td>\n",
              "      <td>0.522500</td>\n",
              "      <td>0.274378</td>\n",
              "      <td>0.659319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.599300</td>\n",
              "      <td>0.811166</td>\n",
              "      <td>0.590000</td>\n",
              "      <td>0.688213</td>\n",
              "      <td>0.544836</td>\n",
              "      <td>0.555215</td>\n",
              "      <td>0.905000</td>\n",
              "      <td>0.275000</td>\n",
              "      <td>0.231781</td>\n",
              "      <td>0.715387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.500400</td>\n",
              "      <td>0.701441</td>\n",
              "      <td>0.647500</td>\n",
              "      <td>0.694805</td>\n",
              "      <td>0.638823</td>\n",
              "      <td>0.612595</td>\n",
              "      <td>0.802500</td>\n",
              "      <td>0.492500</td>\n",
              "      <td>0.310286</td>\n",
              "      <td>0.727313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.395300</td>\n",
              "      <td>0.728419</td>\n",
              "      <td>0.683750</td>\n",
              "      <td>0.721058</td>\n",
              "      <td>0.677990</td>\n",
              "      <td>0.644970</td>\n",
              "      <td>0.817500</td>\n",
              "      <td>0.550000</td>\n",
              "      <td>0.381399</td>\n",
              "      <td>0.761763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.295300</td>\n",
              "      <td>0.722369</td>\n",
              "      <td>0.698750</td>\n",
              "      <td>0.712753</td>\n",
              "      <td>0.698032</td>\n",
              "      <td>0.681093</td>\n",
              "      <td>0.747500</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>0.399403</td>\n",
              "      <td>0.764906</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 6932, total number of training (for each informative and uninform class) and test samples: 400, 6800 0.05 XLNet-L 6932 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-large-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:55, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.722700</td>\n",
              "      <td>0.691323</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.672694</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.722700</td>\n",
              "      <td>0.652492</td>\n",
              "      <td>0.613750</td>\n",
              "      <td>0.579592</td>\n",
              "      <td>0.611183</td>\n",
              "      <td>0.635821</td>\n",
              "      <td>0.532500</td>\n",
              "      <td>0.695000</td>\n",
              "      <td>0.230565</td>\n",
              "      <td>0.680119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.645800</td>\n",
              "      <td>0.641560</td>\n",
              "      <td>0.636250</td>\n",
              "      <td>0.671928</td>\n",
              "      <td>0.631897</td>\n",
              "      <td>0.611910</td>\n",
              "      <td>0.745000</td>\n",
              "      <td>0.527500</td>\n",
              "      <td>0.279184</td>\n",
              "      <td>0.685994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.679500</td>\n",
              "      <td>0.639180</td>\n",
              "      <td>0.635000</td>\n",
              "      <td>0.696466</td>\n",
              "      <td>0.619393</td>\n",
              "      <td>0.596085</td>\n",
              "      <td>0.837500</td>\n",
              "      <td>0.432500</td>\n",
              "      <td>0.295302</td>\n",
              "      <td>0.679231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.544600</td>\n",
              "      <td>0.614509</td>\n",
              "      <td>0.686250</td>\n",
              "      <td>0.716384</td>\n",
              "      <td>0.682668</td>\n",
              "      <td>0.653608</td>\n",
              "      <td>0.792500</td>\n",
              "      <td>0.580000</td>\n",
              "      <td>0.381206</td>\n",
              "      <td>0.751500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.457000</td>\n",
              "      <td>0.642402</td>\n",
              "      <td>0.693750</td>\n",
              "      <td>0.704463</td>\n",
              "      <td>0.693347</td>\n",
              "      <td>0.680653</td>\n",
              "      <td>0.730000</td>\n",
              "      <td>0.657500</td>\n",
              "      <td>0.388522</td>\n",
              "      <td>0.752713</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 1759, total number of training (for each informative and uninform class) and test samples: 400, 6800 0.05 XLNet-L 1759 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-large-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:55, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.742100</td>\n",
              "      <td>0.685692</td>\n",
              "      <td>0.550000</td>\n",
              "      <td>0.659091</td>\n",
              "      <td>0.498663</td>\n",
              "      <td>0.530488</td>\n",
              "      <td>0.870000</td>\n",
              "      <td>0.230000</td>\n",
              "      <td>0.130145</td>\n",
              "      <td>0.600894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.723000</td>\n",
              "      <td>0.682589</td>\n",
              "      <td>0.517500</td>\n",
              "      <td>0.670085</td>\n",
              "      <td>0.386206</td>\n",
              "      <td>0.509091</td>\n",
              "      <td>0.980000</td>\n",
              "      <td>0.055000</td>\n",
              "      <td>0.092113</td>\n",
              "      <td>0.664331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.717200</td>\n",
              "      <td>0.643284</td>\n",
              "      <td>0.648750</td>\n",
              "      <td>0.684624</td>\n",
              "      <td>0.644146</td>\n",
              "      <td>0.621181</td>\n",
              "      <td>0.762500</td>\n",
              "      <td>0.535000</td>\n",
              "      <td>0.305511</td>\n",
              "      <td>0.701206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.732700</td>\n",
              "      <td>0.722377</td>\n",
              "      <td>0.511250</td>\n",
              "      <td>0.671704</td>\n",
              "      <td>0.357857</td>\n",
              "      <td>0.505689</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.022500</td>\n",
              "      <td>0.106668</td>\n",
              "      <td>0.682869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.634900</td>\n",
              "      <td>0.666641</td>\n",
              "      <td>0.647500</td>\n",
              "      <td>0.622995</td>\n",
              "      <td>0.646004</td>\n",
              "      <td>0.669540</td>\n",
              "      <td>0.582500</td>\n",
              "      <td>0.712500</td>\n",
              "      <td>0.297525</td>\n",
              "      <td>0.689338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.622100</td>\n",
              "      <td>0.675297</td>\n",
              "      <td>0.648750</td>\n",
              "      <td>0.698821</td>\n",
              "      <td>0.638766</td>\n",
              "      <td>0.611632</td>\n",
              "      <td>0.815000</td>\n",
              "      <td>0.482500</td>\n",
              "      <td>0.315448</td>\n",
              "      <td>0.728006</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 323, total number of training (for each informative and uninform class) and test samples: 400, 6800 0.05 XLNet-L 323 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-large-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:55, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.703600</td>\n",
              "      <td>0.704548</td>\n",
              "      <td>0.542500</td>\n",
              "      <td>0.540201</td>\n",
              "      <td>0.542489</td>\n",
              "      <td>0.542929</td>\n",
              "      <td>0.537500</td>\n",
              "      <td>0.547500</td>\n",
              "      <td>0.085004</td>\n",
              "      <td>0.562375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.702300</td>\n",
              "      <td>0.689562</td>\n",
              "      <td>0.558750</td>\n",
              "      <td>0.504909</td>\n",
              "      <td>0.553469</td>\n",
              "      <td>0.575080</td>\n",
              "      <td>0.450000</td>\n",
              "      <td>0.667500</td>\n",
              "      <td>0.120382</td>\n",
              "      <td>0.528625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.699800</td>\n",
              "      <td>0.712753</td>\n",
              "      <td>0.501250</td>\n",
              "      <td>0.661578</td>\n",
              "      <td>0.356917</td>\n",
              "      <td>0.500642</td>\n",
              "      <td>0.975000</td>\n",
              "      <td>0.027500</td>\n",
              "      <td>0.007818</td>\n",
              "      <td>0.581788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.725800</td>\n",
              "      <td>0.696198</td>\n",
              "      <td>0.502500</td>\n",
              "      <td>0.009950</td>\n",
              "      <td>0.338865</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.005000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.050063</td>\n",
              "      <td>0.622262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.702700</td>\n",
              "      <td>0.679221</td>\n",
              "      <td>0.546250</td>\n",
              "      <td>0.670898</td>\n",
              "      <td>0.470258</td>\n",
              "      <td>0.526316</td>\n",
              "      <td>0.925000</td>\n",
              "      <td>0.167500</td>\n",
              "      <td>0.141690</td>\n",
              "      <td>0.658194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.663900</td>\n",
              "      <td>0.662202</td>\n",
              "      <td>0.612500</td>\n",
              "      <td>0.565826</td>\n",
              "      <td>0.607970</td>\n",
              "      <td>0.643312</td>\n",
              "      <td>0.505000</td>\n",
              "      <td>0.720000</td>\n",
              "      <td>0.230388</td>\n",
              "      <td>0.660831</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 1694, total number of training (for each informative and uninform class) and test samples: 400, 6800 0.05 XLNet-L 1694 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-large-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:56, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.703500</td>\n",
              "      <td>0.677087</td>\n",
              "      <td>0.571250</td>\n",
              "      <td>0.564168</td>\n",
              "      <td>0.571137</td>\n",
              "      <td>0.573643</td>\n",
              "      <td>0.555000</td>\n",
              "      <td>0.587500</td>\n",
              "      <td>0.142575</td>\n",
              "      <td>0.605144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>0.712533</td>\n",
              "      <td>0.542500</td>\n",
              "      <td>0.652751</td>\n",
              "      <td>0.491211</td>\n",
              "      <td>0.525994</td>\n",
              "      <td>0.860000</td>\n",
              "      <td>0.225000</td>\n",
              "      <td>0.110031</td>\n",
              "      <td>0.618575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.695300</td>\n",
              "      <td>0.666780</td>\n",
              "      <td>0.580000</td>\n",
              "      <td>0.590244</td>\n",
              "      <td>0.579737</td>\n",
              "      <td>0.576190</td>\n",
              "      <td>0.605000</td>\n",
              "      <td>0.555000</td>\n",
              "      <td>0.160200</td>\n",
              "      <td>0.629956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.665400</td>\n",
              "      <td>0.650638</td>\n",
              "      <td>0.617500</td>\n",
              "      <td>0.640845</td>\n",
              "      <td>0.615877</td>\n",
              "      <td>0.603982</td>\n",
              "      <td>0.682500</td>\n",
              "      <td>0.552500</td>\n",
              "      <td>0.237011</td>\n",
              "      <td>0.676806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.638300</td>\n",
              "      <td>0.646596</td>\n",
              "      <td>0.657500</td>\n",
              "      <td>0.657500</td>\n",
              "      <td>0.657500</td>\n",
              "      <td>0.657500</td>\n",
              "      <td>0.657500</td>\n",
              "      <td>0.657500</td>\n",
              "      <td>0.315000</td>\n",
              "      <td>0.709094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.570200</td>\n",
              "      <td>0.638067</td>\n",
              "      <td>0.656250</td>\n",
              "      <td>0.672229</td>\n",
              "      <td>0.655431</td>\n",
              "      <td>0.642369</td>\n",
              "      <td>0.705000</td>\n",
              "      <td>0.607500</td>\n",
              "      <td>0.313996</td>\n",
              "      <td>0.729262</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 9741, total number of training (for each informative and uninform class) and test samples: 400, 6800 0.05 XLNet-L 9741 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-large-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:55, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.701300</td>\n",
              "      <td>0.685447</td>\n",
              "      <td>0.547500</td>\n",
              "      <td>0.666052</td>\n",
              "      <td>0.482251</td>\n",
              "      <td>0.527778</td>\n",
              "      <td>0.902500</td>\n",
              "      <td>0.192500</td>\n",
              "      <td>0.134905</td>\n",
              "      <td>0.604837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.696200</td>\n",
              "      <td>0.718419</td>\n",
              "      <td>0.466250</td>\n",
              "      <td>0.569990</td>\n",
              "      <td>0.433265</td>\n",
              "      <td>0.477234</td>\n",
              "      <td>0.707500</td>\n",
              "      <td>0.225000</td>\n",
              "      <td>-0.077064</td>\n",
              "      <td>0.476106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.682700</td>\n",
              "      <td>0.693900</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.555362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.719900</td>\n",
              "      <td>0.695227</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.551828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.710500</td>\n",
              "      <td>0.698084</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.543653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.725600</td>\n",
              "      <td>0.696424</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.553100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 200, total number of training (for each informative and uninform class) and test samples: 400, 6800 0.05 XLNet-L 200 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-large-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:55, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.708800</td>\n",
              "      <td>0.689095</td>\n",
              "      <td>0.547500</td>\n",
              "      <td>0.423567</td>\n",
              "      <td>0.525569</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.332500</td>\n",
              "      <td>0.762500</td>\n",
              "      <td>0.105225</td>\n",
              "      <td>0.548906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.715000</td>\n",
              "      <td>0.681297</td>\n",
              "      <td>0.602500</td>\n",
              "      <td>0.614078</td>\n",
              "      <td>0.602142</td>\n",
              "      <td>0.596698</td>\n",
              "      <td>0.632500</td>\n",
              "      <td>0.572500</td>\n",
              "      <td>0.205370</td>\n",
              "      <td>0.623687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.677200</td>\n",
              "      <td>0.652939</td>\n",
              "      <td>0.608750</td>\n",
              "      <td>0.680286</td>\n",
              "      <td>0.588130</td>\n",
              "      <td>0.575130</td>\n",
              "      <td>0.832500</td>\n",
              "      <td>0.385000</td>\n",
              "      <td>0.243211</td>\n",
              "      <td>0.672613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.587800</td>\n",
              "      <td>0.614210</td>\n",
              "      <td>0.662500</td>\n",
              "      <td>0.643799</td>\n",
              "      <td>0.661567</td>\n",
              "      <td>0.681564</td>\n",
              "      <td>0.610000</td>\n",
              "      <td>0.715000</td>\n",
              "      <td>0.326807</td>\n",
              "      <td>0.719156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.415900</td>\n",
              "      <td>0.648590</td>\n",
              "      <td>0.677500</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.677159</td>\n",
              "      <td>0.689840</td>\n",
              "      <td>0.645000</td>\n",
              "      <td>0.710000</td>\n",
              "      <td>0.355752</td>\n",
              "      <td>0.749638</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.354300</td>\n",
              "      <td>0.671474</td>\n",
              "      <td>0.683750</td>\n",
              "      <td>0.676884</td>\n",
              "      <td>0.683607</td>\n",
              "      <td>0.691906</td>\n",
              "      <td>0.662500</td>\n",
              "      <td>0.705000</td>\n",
              "      <td>0.367832</td>\n",
              "      <td>0.751819</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 999, total number of training (for each informative and uninform class) and test samples: 400, 6800 0.05 XLNet-L 999 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-large-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:55, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.735300</td>\n",
              "      <td>0.703242</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.556481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.737900</td>\n",
              "      <td>0.702501</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.499928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.694700</td>\n",
              "      <td>0.712894</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.582350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.707900</td>\n",
              "      <td>0.693556</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.480406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.720500</td>\n",
              "      <td>0.726328</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.560037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.757900</td>\n",
              "      <td>0.702606</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.566969</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 94, total number of training (for each informative and uninform class) and test samples: 400, 6800 0.05 DEBERT-B 94 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:34, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.693000</td>\n",
              "      <td>0.689686</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.757988</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.562700</td>\n",
              "      <td>0.594436</td>\n",
              "      <td>0.712500</td>\n",
              "      <td>0.726190</td>\n",
              "      <td>0.711779</td>\n",
              "      <td>0.693182</td>\n",
              "      <td>0.762500</td>\n",
              "      <td>0.662500</td>\n",
              "      <td>0.427141</td>\n",
              "      <td>0.787069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.439900</td>\n",
              "      <td>0.976176</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.758551</td>\n",
              "      <td>0.681256</td>\n",
              "      <td>0.634680</td>\n",
              "      <td>0.942500</td>\n",
              "      <td>0.457500</td>\n",
              "      <td>0.457397</td>\n",
              "      <td>0.813850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.240600</td>\n",
              "      <td>1.154199</td>\n",
              "      <td>0.737500</td>\n",
              "      <td>0.709945</td>\n",
              "      <td>0.735109</td>\n",
              "      <td>0.793210</td>\n",
              "      <td>0.642500</td>\n",
              "      <td>0.832500</td>\n",
              "      <td>0.483813</td>\n",
              "      <td>0.808056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.146100</td>\n",
              "      <td>1.211524</td>\n",
              "      <td>0.756250</td>\n",
              "      <td>0.755332</td>\n",
              "      <td>0.756247</td>\n",
              "      <td>0.758186</td>\n",
              "      <td>0.752500</td>\n",
              "      <td>0.760000</td>\n",
              "      <td>0.512514</td>\n",
              "      <td>0.814100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.060900</td>\n",
              "      <td>1.199613</td>\n",
              "      <td>0.752500</td>\n",
              "      <td>0.771363</td>\n",
              "      <td>0.750804</td>\n",
              "      <td>0.716738</td>\n",
              "      <td>0.835000</td>\n",
              "      <td>0.670000</td>\n",
              "      <td>0.512018</td>\n",
              "      <td>0.816781</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 791, total number of training (for each informative and uninform class) and test samples: 400, 6800 0.05 DEBERT-B 791 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:34, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.685400</td>\n",
              "      <td>0.675661</td>\n",
              "      <td>0.682500</td>\n",
              "      <td>0.717778</td>\n",
              "      <td>0.677460</td>\n",
              "      <td>0.646000</td>\n",
              "      <td>0.807500</td>\n",
              "      <td>0.557500</td>\n",
              "      <td>0.376970</td>\n",
              "      <td>0.748725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.691700</td>\n",
              "      <td>0.625773</td>\n",
              "      <td>0.686250</td>\n",
              "      <td>0.730397</td>\n",
              "      <td>0.677605</td>\n",
              "      <td>0.640301</td>\n",
              "      <td>0.850000</td>\n",
              "      <td>0.522500</td>\n",
              "      <td>0.394242</td>\n",
              "      <td>0.753425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.465700</td>\n",
              "      <td>0.664333</td>\n",
              "      <td>0.697500</td>\n",
              "      <td>0.717949</td>\n",
              "      <td>0.695902</td>\n",
              "      <td>0.672489</td>\n",
              "      <td>0.770000</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.399219</td>\n",
              "      <td>0.774200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.469300</td>\n",
              "      <td>0.645788</td>\n",
              "      <td>0.702500</td>\n",
              "      <td>0.746269</td>\n",
              "      <td>0.693376</td>\n",
              "      <td>0.650558</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.530000</td>\n",
              "      <td>0.431492</td>\n",
              "      <td>0.682687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.348400</td>\n",
              "      <td>0.887037</td>\n",
              "      <td>0.695000</td>\n",
              "      <td>0.746888</td>\n",
              "      <td>0.681620</td>\n",
              "      <td>0.638298</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.490000</td>\n",
              "      <td>0.427591</td>\n",
              "      <td>0.778112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.230300</td>\n",
              "      <td>0.821130</td>\n",
              "      <td>0.718750</td>\n",
              "      <td>0.736225</td>\n",
              "      <td>0.717510</td>\n",
              "      <td>0.693157</td>\n",
              "      <td>0.785000</td>\n",
              "      <td>0.652500</td>\n",
              "      <td>0.441392</td>\n",
              "      <td>0.790094</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 5, total number of training (for each informative and uninform class) and test samples: 400, 6800 0.05 DEBERT-B 5 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:34, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.684900</td>\n",
              "      <td>0.680803</td>\n",
              "      <td>0.583750</td>\n",
              "      <td>0.701880</td>\n",
              "      <td>0.506220</td>\n",
              "      <td>0.546722</td>\n",
              "      <td>0.980000</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>0.274648</td>\n",
              "      <td>0.748962</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.516900</td>\n",
              "      <td>0.589987</td>\n",
              "      <td>0.695000</td>\n",
              "      <td>0.716279</td>\n",
              "      <td>0.693275</td>\n",
              "      <td>0.669565</td>\n",
              "      <td>0.770000</td>\n",
              "      <td>0.620000</td>\n",
              "      <td>0.394463</td>\n",
              "      <td>0.779919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.485100</td>\n",
              "      <td>1.087429</td>\n",
              "      <td>0.713750</td>\n",
              "      <td>0.750816</td>\n",
              "      <td>0.707273</td>\n",
              "      <td>0.664740</td>\n",
              "      <td>0.862500</td>\n",
              "      <td>0.565000</td>\n",
              "      <td>0.447774</td>\n",
              "      <td>0.798837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.231400</td>\n",
              "      <td>1.188554</td>\n",
              "      <td>0.710000</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.709038</td>\n",
              "      <td>0.737288</td>\n",
              "      <td>0.652500</td>\n",
              "      <td>0.767500</td>\n",
              "      <td>0.422805</td>\n",
              "      <td>0.786294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.030400</td>\n",
              "      <td>1.403185</td>\n",
              "      <td>0.722500</td>\n",
              "      <td>0.720403</td>\n",
              "      <td>0.722484</td>\n",
              "      <td>0.725888</td>\n",
              "      <td>0.715000</td>\n",
              "      <td>0.730000</td>\n",
              "      <td>0.445050</td>\n",
              "      <td>0.790631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.051400</td>\n",
              "      <td>1.477059</td>\n",
              "      <td>0.722500</td>\n",
              "      <td>0.738824</td>\n",
              "      <td>0.721412</td>\n",
              "      <td>0.697778</td>\n",
              "      <td>0.785000</td>\n",
              "      <td>0.660000</td>\n",
              "      <td>0.448518</td>\n",
              "      <td>0.796244</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 6932, total number of training (for each informative and uninform class) and test samples: 400, 6800 0.05 DEBERT-B 6932 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:34, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.696000</td>\n",
              "      <td>0.686087</td>\n",
              "      <td>0.543750</td>\n",
              "      <td>0.682884</td>\n",
              "      <td>0.434983</td>\n",
              "      <td>0.523302</td>\n",
              "      <td>0.982500</td>\n",
              "      <td>0.105000</td>\n",
              "      <td>0.182453</td>\n",
              "      <td>0.752512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.569800</td>\n",
              "      <td>0.715605</td>\n",
              "      <td>0.661250</td>\n",
              "      <td>0.720330</td>\n",
              "      <td>0.645427</td>\n",
              "      <td>0.613357</td>\n",
              "      <td>0.872500</td>\n",
              "      <td>0.450000</td>\n",
              "      <td>0.355818</td>\n",
              "      <td>0.735762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.484800</td>\n",
              "      <td>0.711433</td>\n",
              "      <td>0.682500</td>\n",
              "      <td>0.709382</td>\n",
              "      <td>0.679760</td>\n",
              "      <td>0.654008</td>\n",
              "      <td>0.775000</td>\n",
              "      <td>0.590000</td>\n",
              "      <td>0.371411</td>\n",
              "      <td>0.736437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.361700</td>\n",
              "      <td>0.949098</td>\n",
              "      <td>0.677500</td>\n",
              "      <td>0.720779</td>\n",
              "      <td>0.669561</td>\n",
              "      <td>0.635496</td>\n",
              "      <td>0.832500</td>\n",
              "      <td>0.522500</td>\n",
              "      <td>0.373395</td>\n",
              "      <td>0.768038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.319900</td>\n",
              "      <td>1.056395</td>\n",
              "      <td>0.695000</td>\n",
              "      <td>0.698765</td>\n",
              "      <td>0.694952</td>\n",
              "      <td>0.690244</td>\n",
              "      <td>0.707500</td>\n",
              "      <td>0.682500</td>\n",
              "      <td>0.390122</td>\n",
              "      <td>0.764181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.142400</td>\n",
              "      <td>1.136321</td>\n",
              "      <td>0.690000</td>\n",
              "      <td>0.720090</td>\n",
              "      <td>0.686376</td>\n",
              "      <td>0.656379</td>\n",
              "      <td>0.797500</td>\n",
              "      <td>0.582500</td>\n",
              "      <td>0.389099</td>\n",
              "      <td>0.767350</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 1759, total number of training (for each informative and uninform class) and test samples: 400, 6800 0.05 DEBERT-B 1759 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:34, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.695100</td>\n",
              "      <td>0.688589</td>\n",
              "      <td>0.587500</td>\n",
              "      <td>0.628378</td>\n",
              "      <td>0.582448</td>\n",
              "      <td>0.571721</td>\n",
              "      <td>0.697500</td>\n",
              "      <td>0.477500</td>\n",
              "      <td>0.179395</td>\n",
              "      <td>0.685891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.681600</td>\n",
              "      <td>0.648645</td>\n",
              "      <td>0.663750</td>\n",
              "      <td>0.614060</td>\n",
              "      <td>0.658082</td>\n",
              "      <td>0.720539</td>\n",
              "      <td>0.535000</td>\n",
              "      <td>0.792500</td>\n",
              "      <td>0.338929</td>\n",
              "      <td>0.732963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.530500</td>\n",
              "      <td>0.573348</td>\n",
              "      <td>0.727500</td>\n",
              "      <td>0.704607</td>\n",
              "      <td>0.725853</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>0.805000</td>\n",
              "      <td>0.460566</td>\n",
              "      <td>0.796663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.377300</td>\n",
              "      <td>0.623655</td>\n",
              "      <td>0.712500</td>\n",
              "      <td>0.709596</td>\n",
              "      <td>0.712471</td>\n",
              "      <td>0.716837</td>\n",
              "      <td>0.702500</td>\n",
              "      <td>0.722500</td>\n",
              "      <td>0.425085</td>\n",
              "      <td>0.795044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.257100</td>\n",
              "      <td>0.946304</td>\n",
              "      <td>0.727500</td>\n",
              "      <td>0.730864</td>\n",
              "      <td>0.727457</td>\n",
              "      <td>0.721951</td>\n",
              "      <td>0.740000</td>\n",
              "      <td>0.715000</td>\n",
              "      <td>0.455142</td>\n",
              "      <td>0.806294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.191800</td>\n",
              "      <td>1.098926</td>\n",
              "      <td>0.721250</td>\n",
              "      <td>0.729697</td>\n",
              "      <td>0.720978</td>\n",
              "      <td>0.708235</td>\n",
              "      <td>0.752500</td>\n",
              "      <td>0.690000</td>\n",
              "      <td>0.443367</td>\n",
              "      <td>0.803494</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 323, total number of training (for each informative and uninform class) and test samples: 400, 6800 0.05 DEBERT-B 323 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:34, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.678400</td>\n",
              "      <td>0.639193</td>\n",
              "      <td>0.631250</td>\n",
              "      <td>0.693666</td>\n",
              "      <td>0.615279</td>\n",
              "      <td>0.593250</td>\n",
              "      <td>0.835000</td>\n",
              "      <td>0.427500</td>\n",
              "      <td>0.287449</td>\n",
              "      <td>0.732825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.551700</td>\n",
              "      <td>0.617079</td>\n",
              "      <td>0.646250</td>\n",
              "      <td>0.726041</td>\n",
              "      <td>0.613461</td>\n",
              "      <td>0.592417</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.355000</td>\n",
              "      <td>0.359854</td>\n",
              "      <td>0.793944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.294800</td>\n",
              "      <td>0.888627</td>\n",
              "      <td>0.655000</td>\n",
              "      <td>0.732558</td>\n",
              "      <td>0.623321</td>\n",
              "      <td>0.598101</td>\n",
              "      <td>0.945000</td>\n",
              "      <td>0.365000</td>\n",
              "      <td>0.380547</td>\n",
              "      <td>0.802375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.192400</td>\n",
              "      <td>1.085431</td>\n",
              "      <td>0.710000</td>\n",
              "      <td>0.664740</td>\n",
              "      <td>0.704617</td>\n",
              "      <td>0.787671</td>\n",
              "      <td>0.575000</td>\n",
              "      <td>0.845000</td>\n",
              "      <td>0.436200</td>\n",
              "      <td>0.792406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.078400</td>\n",
              "      <td>1.146665</td>\n",
              "      <td>0.726250</td>\n",
              "      <td>0.749714</td>\n",
              "      <td>0.723823</td>\n",
              "      <td>0.690526</td>\n",
              "      <td>0.820000</td>\n",
              "      <td>0.632500</td>\n",
              "      <td>0.460670</td>\n",
              "      <td>0.799987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.038700</td>\n",
              "      <td>1.251253</td>\n",
              "      <td>0.726250</td>\n",
              "      <td>0.746234</td>\n",
              "      <td>0.724542</td>\n",
              "      <td>0.695464</td>\n",
              "      <td>0.805000</td>\n",
              "      <td>0.647500</td>\n",
              "      <td>0.458219</td>\n",
              "      <td>0.798156</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 1694, total number of training (for each informative and uninform class) and test samples: 400, 6800 0.05 DEBERT-B 1694 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:34, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.690200</td>\n",
              "      <td>0.667390</td>\n",
              "      <td>0.636250</td>\n",
              "      <td>0.628352</td>\n",
              "      <td>0.636086</td>\n",
              "      <td>0.642298</td>\n",
              "      <td>0.615000</td>\n",
              "      <td>0.657500</td>\n",
              "      <td>0.272746</td>\n",
              "      <td>0.684875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.659500</td>\n",
              "      <td>0.651591</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>0.690265</td>\n",
              "      <td>0.643983</td>\n",
              "      <td>0.619048</td>\n",
              "      <td>0.780000</td>\n",
              "      <td>0.520000</td>\n",
              "      <td>0.310685</td>\n",
              "      <td>0.713419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.556200</td>\n",
              "      <td>0.647373</td>\n",
              "      <td>0.672500</td>\n",
              "      <td>0.669192</td>\n",
              "      <td>0.672467</td>\n",
              "      <td>0.676020</td>\n",
              "      <td>0.662500</td>\n",
              "      <td>0.682500</td>\n",
              "      <td>0.345069</td>\n",
              "      <td>0.710444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.489300</td>\n",
              "      <td>0.820653</td>\n",
              "      <td>0.668750</td>\n",
              "      <td>0.710383</td>\n",
              "      <td>0.661761</td>\n",
              "      <td>0.631068</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.525000</td>\n",
              "      <td>0.352377</td>\n",
              "      <td>0.713537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.312700</td>\n",
              "      <td>1.115035</td>\n",
              "      <td>0.662500</td>\n",
              "      <td>0.639037</td>\n",
              "      <td>0.661068</td>\n",
              "      <td>0.686782</td>\n",
              "      <td>0.597500</td>\n",
              "      <td>0.727500</td>\n",
              "      <td>0.327782</td>\n",
              "      <td>0.727481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.174500</td>\n",
              "      <td>1.139937</td>\n",
              "      <td>0.671250</td>\n",
              "      <td>0.687277</td>\n",
              "      <td>0.670384</td>\n",
              "      <td>0.655329</td>\n",
              "      <td>0.722500</td>\n",
              "      <td>0.620000</td>\n",
              "      <td>0.344313</td>\n",
              "      <td>0.725781</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 9741, total number of training (for each informative and uninform class) and test samples: 400, 6800 0.05 DEBERT-B 9741 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:34, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.692500</td>\n",
              "      <td>0.690038</td>\n",
              "      <td>0.525000</td>\n",
              "      <td>0.124424</td>\n",
              "      <td>0.399262</td>\n",
              "      <td>0.794118</td>\n",
              "      <td>0.067500</td>\n",
              "      <td>0.982500</td>\n",
              "      <td>0.123930</td>\n",
              "      <td>0.721037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.620100</td>\n",
              "      <td>0.695748</td>\n",
              "      <td>0.688750</td>\n",
              "      <td>0.726073</td>\n",
              "      <td>0.682863</td>\n",
              "      <td>0.648330</td>\n",
              "      <td>0.825000</td>\n",
              "      <td>0.552500</td>\n",
              "      <td>0.392348</td>\n",
              "      <td>0.777981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.509300</td>\n",
              "      <td>0.690407</td>\n",
              "      <td>0.702500</td>\n",
              "      <td>0.720657</td>\n",
              "      <td>0.701238</td>\n",
              "      <td>0.679204</td>\n",
              "      <td>0.767500</td>\n",
              "      <td>0.637500</td>\n",
              "      <td>0.408466</td>\n",
              "      <td>0.783800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.434700</td>\n",
              "      <td>0.734735</td>\n",
              "      <td>0.707500</td>\n",
              "      <td>0.733485</td>\n",
              "      <td>0.704693</td>\n",
              "      <td>0.673640</td>\n",
              "      <td>0.805000</td>\n",
              "      <td>0.610000</td>\n",
              "      <td>0.423123</td>\n",
              "      <td>0.755719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.246400</td>\n",
              "      <td>0.959836</td>\n",
              "      <td>0.720000</td>\n",
              "      <td>0.723457</td>\n",
              "      <td>0.719956</td>\n",
              "      <td>0.714634</td>\n",
              "      <td>0.732500</td>\n",
              "      <td>0.707500</td>\n",
              "      <td>0.440138</td>\n",
              "      <td>0.792531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.183000</td>\n",
              "      <td>1.100042</td>\n",
              "      <td>0.712500</td>\n",
              "      <td>0.705128</td>\n",
              "      <td>0.712320</td>\n",
              "      <td>0.723684</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>0.737500</td>\n",
              "      <td>0.425532</td>\n",
              "      <td>0.790050</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 200, total number of training (for each informative and uninform class) and test samples: 400, 6800 0.05 DEBERT-B 200 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:34, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.674500</td>\n",
              "      <td>0.632227</td>\n",
              "      <td>0.652500</td>\n",
              "      <td>0.648990</td>\n",
              "      <td>0.652465</td>\n",
              "      <td>0.655612</td>\n",
              "      <td>0.642500</td>\n",
              "      <td>0.662500</td>\n",
              "      <td>0.305061</td>\n",
              "      <td>0.726456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.560800</td>\n",
              "      <td>0.568492</td>\n",
              "      <td>0.696250</td>\n",
              "      <td>0.703297</td>\n",
              "      <td>0.696079</td>\n",
              "      <td>0.687351</td>\n",
              "      <td>0.720000</td>\n",
              "      <td>0.672500</td>\n",
              "      <td>0.392944</td>\n",
              "      <td>0.773813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.384800</td>\n",
              "      <td>0.734149</td>\n",
              "      <td>0.691250</td>\n",
              "      <td>0.645624</td>\n",
              "      <td>0.686046</td>\n",
              "      <td>0.757576</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>0.820000</td>\n",
              "      <td>0.395849</td>\n",
              "      <td>0.786706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.178100</td>\n",
              "      <td>0.954448</td>\n",
              "      <td>0.703750</td>\n",
              "      <td>0.731597</td>\n",
              "      <td>0.700526</td>\n",
              "      <td>0.668737</td>\n",
              "      <td>0.807500</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.416567</td>\n",
              "      <td>0.787494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.075700</td>\n",
              "      <td>1.115787</td>\n",
              "      <td>0.716250</td>\n",
              "      <td>0.726835</td>\n",
              "      <td>0.715823</td>\n",
              "      <td>0.700696</td>\n",
              "      <td>0.755000</td>\n",
              "      <td>0.677500</td>\n",
              "      <td>0.433805</td>\n",
              "      <td>0.794231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.023500</td>\n",
              "      <td>1.175251</td>\n",
              "      <td>0.706250</td>\n",
              "      <td>0.726426</td>\n",
              "      <td>0.704644</td>\n",
              "      <td>0.679739</td>\n",
              "      <td>0.780000</td>\n",
              "      <td>0.632500</td>\n",
              "      <td>0.417062</td>\n",
              "      <td>0.793744</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 999, total number of training (for each informative and uninform class) and test samples: 400, 6800 0.05 DEBERT-B 999 2e-05 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:34, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.680600</td>\n",
              "      <td>0.596942</td>\n",
              "      <td>0.680000</td>\n",
              "      <td>0.690073</td>\n",
              "      <td>0.679662</td>\n",
              "      <td>0.669014</td>\n",
              "      <td>0.712500</td>\n",
              "      <td>0.647500</td>\n",
              "      <td>0.360763</td>\n",
              "      <td>0.746463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.617800</td>\n",
              "      <td>0.667248</td>\n",
              "      <td>0.671250</td>\n",
              "      <td>0.612666</td>\n",
              "      <td>0.663553</td>\n",
              "      <td>0.745520</td>\n",
              "      <td>0.520000</td>\n",
              "      <td>0.822500</td>\n",
              "      <td>0.359335</td>\n",
              "      <td>0.759556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.397100</td>\n",
              "      <td>0.720964</td>\n",
              "      <td>0.720000</td>\n",
              "      <td>0.726161</td>\n",
              "      <td>0.719858</td>\n",
              "      <td>0.710526</td>\n",
              "      <td>0.742500</td>\n",
              "      <td>0.697500</td>\n",
              "      <td>0.440446</td>\n",
              "      <td>0.791719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.332100</td>\n",
              "      <td>0.796752</td>\n",
              "      <td>0.722500</td>\n",
              "      <td>0.735084</td>\n",
              "      <td>0.721872</td>\n",
              "      <td>0.703196</td>\n",
              "      <td>0.770000</td>\n",
              "      <td>0.675000</td>\n",
              "      <td>0.447022</td>\n",
              "      <td>0.790162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.096100</td>\n",
              "      <td>1.031741</td>\n",
              "      <td>0.728750</td>\n",
              "      <td>0.746199</td>\n",
              "      <td>0.727462</td>\n",
              "      <td>0.701099</td>\n",
              "      <td>0.797500</td>\n",
              "      <td>0.660000</td>\n",
              "      <td>0.461887</td>\n",
              "      <td>0.796713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.180200</td>\n",
              "      <td>1.132832</td>\n",
              "      <td>0.721250</td>\n",
              "      <td>0.721598</td>\n",
              "      <td>0.721250</td>\n",
              "      <td>0.720698</td>\n",
              "      <td>0.722500</td>\n",
              "      <td>0.720000</td>\n",
              "      <td>0.442501</td>\n",
              "      <td>0.786775</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 94, total number of training (for each informative and uninform class) and test samples: 200, 7000 0.025 ALBERT-L 94 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:29, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.731400</td>\n",
              "      <td>0.713650</td>\n",
              "      <td>0.498750</td>\n",
              "      <td>0.652212</td>\n",
              "      <td>0.377560</td>\n",
              "      <td>0.499336</td>\n",
              "      <td>0.940000</td>\n",
              "      <td>0.057500</td>\n",
              "      <td>-0.005316</td>\n",
              "      <td>0.540812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.717600</td>\n",
              "      <td>0.706938</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.597788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.715300</td>\n",
              "      <td>0.724623</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.637044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.758500</td>\n",
              "      <td>0.697416</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.655844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.681100</td>\n",
              "      <td>0.692280</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.659731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.682100</td>\n",
              "      <td>0.688177</td>\n",
              "      <td>0.532500</td>\n",
              "      <td>0.200855</td>\n",
              "      <td>0.435233</td>\n",
              "      <td>0.691176</td>\n",
              "      <td>0.117500</td>\n",
              "      <td>0.947500</td>\n",
              "      <td>0.116537</td>\n",
              "      <td>0.661162</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 791, total number of training (for each informative and uninform class) and test samples: 200, 7000 0.025 ALBERT-L 791 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:29, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.710400</td>\n",
              "      <td>0.719994</td>\n",
              "      <td>0.495000</td>\n",
              "      <td>0.657627</td>\n",
              "      <td>0.347861</td>\n",
              "      <td>0.497436</td>\n",
              "      <td>0.970000</td>\n",
              "      <td>0.020000</td>\n",
              "      <td>-0.032026</td>\n",
              "      <td>0.508663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.704900</td>\n",
              "      <td>0.707437</td>\n",
              "      <td>0.497500</td>\n",
              "      <td>0.651042</td>\n",
              "      <td>0.376860</td>\n",
              "      <td>0.498670</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.057500</td>\n",
              "      <td>-0.010527</td>\n",
              "      <td>0.445319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.769200</td>\n",
              "      <td>0.695961</td>\n",
              "      <td>0.502500</td>\n",
              "      <td>0.038647</td>\n",
              "      <td>0.351533</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.020000</td>\n",
              "      <td>0.985000</td>\n",
              "      <td>0.019066</td>\n",
              "      <td>0.551619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.714900</td>\n",
              "      <td>0.693647</td>\n",
              "      <td>0.496250</td>\n",
              "      <td>0.411679</td>\n",
              "      <td>0.485621</td>\n",
              "      <td>0.494737</td>\n",
              "      <td>0.352500</td>\n",
              "      <td>0.640000</td>\n",
              "      <td>-0.007831</td>\n",
              "      <td>0.502337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.726500</td>\n",
              "      <td>0.702761</td>\n",
              "      <td>0.506250</td>\n",
              "      <td>0.648264</td>\n",
              "      <td>0.410086</td>\n",
              "      <td>0.503458</td>\n",
              "      <td>0.910000</td>\n",
              "      <td>0.102500</td>\n",
              "      <td>0.021191</td>\n",
              "      <td>0.550506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.694400</td>\n",
              "      <td>0.691485</td>\n",
              "      <td>0.537500</td>\n",
              "      <td>0.588889</td>\n",
              "      <td>0.530159</td>\n",
              "      <td>0.530000</td>\n",
              "      <td>0.662500</td>\n",
              "      <td>0.412500</td>\n",
              "      <td>0.077460</td>\n",
              "      <td>0.537606</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 5, total number of training (for each informative and uninform class) and test samples: 200, 7000 0.025 ALBERT-L 5 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:29, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.703200</td>\n",
              "      <td>0.707690</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.519756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.692400</td>\n",
              "      <td>0.696123</td>\n",
              "      <td>0.512500</td>\n",
              "      <td>0.470109</td>\n",
              "      <td>0.509360</td>\n",
              "      <td>0.514881</td>\n",
              "      <td>0.432500</td>\n",
              "      <td>0.592500</td>\n",
              "      <td>0.025326</td>\n",
              "      <td>0.538650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.728300</td>\n",
              "      <td>0.673318</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.532164</td>\n",
              "      <td>0.591409</td>\n",
              "      <td>0.640845</td>\n",
              "      <td>0.455000</td>\n",
              "      <td>0.745000</td>\n",
              "      <td>0.208981</td>\n",
              "      <td>0.623706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.756500</td>\n",
              "      <td>0.718016</td>\n",
              "      <td>0.505000</td>\n",
              "      <td>0.665541</td>\n",
              "      <td>0.356809</td>\n",
              "      <td>0.502551</td>\n",
              "      <td>0.985000</td>\n",
              "      <td>0.025000</td>\n",
              "      <td>0.035714</td>\n",
              "      <td>0.537438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.735100</td>\n",
              "      <td>0.711493</td>\n",
              "      <td>0.493750</td>\n",
              "      <td>0.661088</td>\n",
              "      <td>0.330544</td>\n",
              "      <td>0.496855</td>\n",
              "      <td>0.987500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.079305</td>\n",
              "      <td>0.532738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.681000</td>\n",
              "      <td>0.686952</td>\n",
              "      <td>0.542500</td>\n",
              "      <td>0.319703</td>\n",
              "      <td>0.487535</td>\n",
              "      <td>0.623188</td>\n",
              "      <td>0.215000</td>\n",
              "      <td>0.870000</td>\n",
              "      <td>0.112489</td>\n",
              "      <td>0.568331</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 6932, total number of training (for each informative and uninform class) and test samples: 200, 7000 0.025 ALBERT-L 6932 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:29, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.666900</td>\n",
              "      <td>0.677075</td>\n",
              "      <td>0.576250</td>\n",
              "      <td>0.615210</td>\n",
              "      <td>0.571861</td>\n",
              "      <td>0.563410</td>\n",
              "      <td>0.677500</td>\n",
              "      <td>0.475000</td>\n",
              "      <td>0.155726</td>\n",
              "      <td>0.605281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.587000</td>\n",
              "      <td>0.663670</td>\n",
              "      <td>0.598750</td>\n",
              "      <td>0.655949</td>\n",
              "      <td>0.587345</td>\n",
              "      <td>0.574109</td>\n",
              "      <td>0.765000</td>\n",
              "      <td>0.432500</td>\n",
              "      <td>0.209415</td>\n",
              "      <td>0.638381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.363200</td>\n",
              "      <td>0.802188</td>\n",
              "      <td>0.623750</td>\n",
              "      <td>0.686785</td>\n",
              "      <td>0.607868</td>\n",
              "      <td>0.588235</td>\n",
              "      <td>0.825000</td>\n",
              "      <td>0.422500</td>\n",
              "      <td>0.270368</td>\n",
              "      <td>0.667900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.558700</td>\n",
              "      <td>1.139201</td>\n",
              "      <td>0.615000</td>\n",
              "      <td>0.567416</td>\n",
              "      <td>0.610284</td>\n",
              "      <td>0.647436</td>\n",
              "      <td>0.505000</td>\n",
              "      <td>0.725000</td>\n",
              "      <td>0.235777</td>\n",
              "      <td>0.656225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.161500</td>\n",
              "      <td>1.397750</td>\n",
              "      <td>0.630000</td>\n",
              "      <td>0.645084</td>\n",
              "      <td>0.629330</td>\n",
              "      <td>0.619816</td>\n",
              "      <td>0.672500</td>\n",
              "      <td>0.587500</td>\n",
              "      <td>0.260944</td>\n",
              "      <td>0.659281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.565900</td>\n",
              "      <td>1.560517</td>\n",
              "      <td>0.636250</td>\n",
              "      <td>0.658851</td>\n",
              "      <td>0.634646</td>\n",
              "      <td>0.620309</td>\n",
              "      <td>0.702500</td>\n",
              "      <td>0.570000</td>\n",
              "      <td>0.274924</td>\n",
              "      <td>0.654494</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 1759, total number of training (for each informative and uninform class) and test samples: 200, 7000 0.025 ALBERT-L 1759 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:29, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.686800</td>\n",
              "      <td>0.776319</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.627350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.642100</td>\n",
              "      <td>0.605030</td>\n",
              "      <td>0.695000</td>\n",
              "      <td>0.736501</td>\n",
              "      <td>0.687242</td>\n",
              "      <td>0.648289</td>\n",
              "      <td>0.852500</td>\n",
              "      <td>0.537500</td>\n",
              "      <td>0.410919</td>\n",
              "      <td>0.773119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.462200</td>\n",
              "      <td>1.154194</td>\n",
              "      <td>0.686250</td>\n",
              "      <td>0.619120</td>\n",
              "      <td>0.676191</td>\n",
              "      <td>0.787645</td>\n",
              "      <td>0.510000</td>\n",
              "      <td>0.862500</td>\n",
              "      <td>0.398050</td>\n",
              "      <td>0.730144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.326100</td>\n",
              "      <td>1.432198</td>\n",
              "      <td>0.726250</td>\n",
              "      <td>0.714472</td>\n",
              "      <td>0.725783</td>\n",
              "      <td>0.746594</td>\n",
              "      <td>0.685000</td>\n",
              "      <td>0.767500</td>\n",
              "      <td>0.454048</td>\n",
              "      <td>0.765563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.000900</td>\n",
              "      <td>1.768639</td>\n",
              "      <td>0.716250</td>\n",
              "      <td>0.736964</td>\n",
              "      <td>0.714479</td>\n",
              "      <td>0.686825</td>\n",
              "      <td>0.795000</td>\n",
              "      <td>0.637500</td>\n",
              "      <td>0.437966</td>\n",
              "      <td>0.769537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.000900</td>\n",
              "      <td>1.885680</td>\n",
              "      <td>0.711250</td>\n",
              "      <td>0.735395</td>\n",
              "      <td>0.708826</td>\n",
              "      <td>0.678647</td>\n",
              "      <td>0.802500</td>\n",
              "      <td>0.620000</td>\n",
              "      <td>0.429717</td>\n",
              "      <td>0.765931</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 323, total number of training (for each informative and uninform class) and test samples: 200, 7000 0.025 ALBERT-L 323 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:29, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.719200</td>\n",
              "      <td>0.722813</td>\n",
              "      <td>0.496250</td>\n",
              "      <td>0.004938</td>\n",
              "      <td>0.333850</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.002500</td>\n",
              "      <td>0.990000</td>\n",
              "      <td>-0.047583</td>\n",
              "      <td>0.427575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.692600</td>\n",
              "      <td>0.730806</td>\n",
              "      <td>0.453750</td>\n",
              "      <td>0.548087</td>\n",
              "      <td>0.428862</td>\n",
              "      <td>0.467372</td>\n",
              "      <td>0.662500</td>\n",
              "      <td>0.245000</td>\n",
              "      <td>-0.101796</td>\n",
              "      <td>0.452062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.751900</td>\n",
              "      <td>0.693194</td>\n",
              "      <td>0.508750</td>\n",
              "      <td>0.630292</td>\n",
              "      <td>0.449224</td>\n",
              "      <td>0.505279</td>\n",
              "      <td>0.837500</td>\n",
              "      <td>0.180000</td>\n",
              "      <td>0.023226</td>\n",
              "      <td>0.493400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.658500</td>\n",
              "      <td>0.696322</td>\n",
              "      <td>0.497500</td>\n",
              "      <td>0.664441</td>\n",
              "      <td>0.332220</td>\n",
              "      <td>0.498747</td>\n",
              "      <td>0.995000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.050063</td>\n",
              "      <td>0.590206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.707800</td>\n",
              "      <td>0.698322</td>\n",
              "      <td>0.506250</td>\n",
              "      <td>0.052758</td>\n",
              "      <td>0.359430</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.027500</td>\n",
              "      <td>0.985000</td>\n",
              "      <td>0.043338</td>\n",
              "      <td>0.520669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.743900</td>\n",
              "      <td>0.700858</td>\n",
              "      <td>0.486250</td>\n",
              "      <td>0.481715</td>\n",
              "      <td>0.486211</td>\n",
              "      <td>0.486005</td>\n",
              "      <td>0.477500</td>\n",
              "      <td>0.495000</td>\n",
              "      <td>-0.027504</td>\n",
              "      <td>0.506956</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 1694, total number of training (for each informative and uninform class) and test samples: 200, 7000 0.025 ALBERT-L 1694 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:29, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.748900</td>\n",
              "      <td>0.694477</td>\n",
              "      <td>0.527500</td>\n",
              "      <td>0.423780</td>\n",
              "      <td>0.511678</td>\n",
              "      <td>0.542969</td>\n",
              "      <td>0.347500</td>\n",
              "      <td>0.707500</td>\n",
              "      <td>0.058953</td>\n",
              "      <td>0.472056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.692600</td>\n",
              "      <td>0.699362</td>\n",
              "      <td>0.502500</td>\n",
              "      <td>0.014851</td>\n",
              "      <td>0.341038</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.007500</td>\n",
              "      <td>0.997500</td>\n",
              "      <td>0.035444</td>\n",
              "      <td>0.429369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.692600</td>\n",
              "      <td>0.727794</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.501269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.715200</td>\n",
              "      <td>0.693386</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.515272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.677200</td>\n",
              "      <td>0.688894</td>\n",
              "      <td>0.558750</td>\n",
              "      <td>0.327619</td>\n",
              "      <td>0.499623</td>\n",
              "      <td>0.688000</td>\n",
              "      <td>0.215000</td>\n",
              "      <td>0.902500</td>\n",
              "      <td>0.161805</td>\n",
              "      <td>0.645425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.702200</td>\n",
              "      <td>0.675389</td>\n",
              "      <td>0.636250</td>\n",
              "      <td>0.628352</td>\n",
              "      <td>0.636086</td>\n",
              "      <td>0.642298</td>\n",
              "      <td>0.615000</td>\n",
              "      <td>0.657500</td>\n",
              "      <td>0.272746</td>\n",
              "      <td>0.677900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 9741, total number of training (for each informative and uninform class) and test samples: 200, 7000 0.025 ALBERT-L 9741 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:29, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.689900</td>\n",
              "      <td>0.735189</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.509875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.678200</td>\n",
              "      <td>0.661062</td>\n",
              "      <td>0.602500</td>\n",
              "      <td>0.693642</td>\n",
              "      <td>0.563903</td>\n",
              "      <td>0.564263</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.305000</td>\n",
              "      <td>0.255062</td>\n",
              "      <td>0.701406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.667700</td>\n",
              "      <td>0.687556</td>\n",
              "      <td>0.545000</td>\n",
              "      <td>0.395349</td>\n",
              "      <td>0.515310</td>\n",
              "      <td>0.589109</td>\n",
              "      <td>0.297500</td>\n",
              "      <td>0.792500</td>\n",
              "      <td>0.103580</td>\n",
              "      <td>0.558262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.638900</td>\n",
              "      <td>0.660291</td>\n",
              "      <td>0.628750</td>\n",
              "      <td>0.623574</td>\n",
              "      <td>0.628680</td>\n",
              "      <td>0.632391</td>\n",
              "      <td>0.615000</td>\n",
              "      <td>0.642500</td>\n",
              "      <td>0.257597</td>\n",
              "      <td>0.653400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.634000</td>\n",
              "      <td>0.661278</td>\n",
              "      <td>0.611250</td>\n",
              "      <td>0.664509</td>\n",
              "      <td>0.601200</td>\n",
              "      <td>0.584440</td>\n",
              "      <td>0.770000</td>\n",
              "      <td>0.452500</td>\n",
              "      <td>0.234641</td>\n",
              "      <td>0.651550</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.547500</td>\n",
              "      <td>0.639016</td>\n",
              "      <td>0.633750</td>\n",
              "      <td>0.698249</td>\n",
              "      <td>0.616215</td>\n",
              "      <td>0.593695</td>\n",
              "      <td>0.847500</td>\n",
              "      <td>0.420000</td>\n",
              "      <td>0.295902</td>\n",
              "      <td>0.696950</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 200, total number of training (for each informative and uninform class) and test samples: 200, 7000 0.025 ALBERT-L 200 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:29, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.696700</td>\n",
              "      <td>0.694764</td>\n",
              "      <td>0.503750</td>\n",
              "      <td>0.546286</td>\n",
              "      <td>0.499350</td>\n",
              "      <td>0.503158</td>\n",
              "      <td>0.597500</td>\n",
              "      <td>0.410000</td>\n",
              "      <td>0.007635</td>\n",
              "      <td>0.562813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.740000</td>\n",
              "      <td>0.683655</td>\n",
              "      <td>0.577500</td>\n",
              "      <td>0.545699</td>\n",
              "      <td>0.575420</td>\n",
              "      <td>0.590116</td>\n",
              "      <td>0.507500</td>\n",
              "      <td>0.647500</td>\n",
              "      <td>0.156542</td>\n",
              "      <td>0.618919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.683500</td>\n",
              "      <td>0.695356</td>\n",
              "      <td>0.502500</td>\n",
              "      <td>0.616570</td>\n",
              "      <td>0.454193</td>\n",
              "      <td>0.501567</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.205000</td>\n",
              "      <td>0.006221</td>\n",
              "      <td>0.475875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.714500</td>\n",
              "      <td>0.698735</td>\n",
              "      <td>0.510000</td>\n",
              "      <td>0.620890</td>\n",
              "      <td>0.464155</td>\n",
              "      <td>0.506309</td>\n",
              "      <td>0.802500</td>\n",
              "      <td>0.217500</td>\n",
              "      <td>0.024660</td>\n",
              "      <td>0.494188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.732900</td>\n",
              "      <td>0.706869</td>\n",
              "      <td>0.492500</td>\n",
              "      <td>0.650602</td>\n",
              "      <td>0.361831</td>\n",
              "      <td>0.496063</td>\n",
              "      <td>0.945000</td>\n",
              "      <td>0.040000</td>\n",
              "      <td>-0.035260</td>\n",
              "      <td>0.474231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.716700</td>\n",
              "      <td>0.703280</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.664430</td>\n",
              "      <td>0.342019</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.990000</td>\n",
              "      <td>0.010000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.560944</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 999, total number of training (for each informative and uninform class) and test samples: 200, 7000 0.025 ALBERT-L 999 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:29, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.731200</td>\n",
              "      <td>0.704052</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.515031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.690400</td>\n",
              "      <td>0.699344</td>\n",
              "      <td>0.496250</td>\n",
              "      <td>0.655850</td>\n",
              "      <td>0.358228</td>\n",
              "      <td>0.498054</td>\n",
              "      <td>0.960000</td>\n",
              "      <td>0.032500</td>\n",
              "      <td>-0.020063</td>\n",
              "      <td>0.471763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.806500</td>\n",
              "      <td>0.719153</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.609544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.763400</td>\n",
              "      <td>0.698878</td>\n",
              "      <td>0.530000</td>\n",
              "      <td>0.534653</td>\n",
              "      <td>0.529953</td>\n",
              "      <td>0.529412</td>\n",
              "      <td>0.540000</td>\n",
              "      <td>0.520000</td>\n",
              "      <td>0.060012</td>\n",
              "      <td>0.523919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.659800</td>\n",
              "      <td>0.708490</td>\n",
              "      <td>0.487500</td>\n",
              "      <td>0.159836</td>\n",
              "      <td>0.395566</td>\n",
              "      <td>0.443182</td>\n",
              "      <td>0.097500</td>\n",
              "      <td>0.877500</td>\n",
              "      <td>-0.039950</td>\n",
              "      <td>0.458250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.746300</td>\n",
              "      <td>0.701687</td>\n",
              "      <td>0.518750</td>\n",
              "      <td>0.202899</td>\n",
              "      <td>0.429113</td>\n",
              "      <td>0.590361</td>\n",
              "      <td>0.122500</td>\n",
              "      <td>0.915000</td>\n",
              "      <td>0.061488</td>\n",
              "      <td>0.525925</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 94, total number of training (for each informative and uninform class) and test samples: 200, 7000 0.025 DISRoBERTa-B 94 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilbert/distilroberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:10, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.669600</td>\n",
              "      <td>0.678990</td>\n",
              "      <td>0.615000</td>\n",
              "      <td>0.696850</td>\n",
              "      <td>0.584727</td>\n",
              "      <td>0.574675</td>\n",
              "      <td>0.885000</td>\n",
              "      <td>0.345000</td>\n",
              "      <td>0.273268</td>\n",
              "      <td>0.725656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.595900</td>\n",
              "      <td>0.582707</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.710145</td>\n",
              "      <td>0.699632</td>\n",
              "      <td>0.686916</td>\n",
              "      <td>0.735000</td>\n",
              "      <td>0.665000</td>\n",
              "      <td>0.400984</td>\n",
              "      <td>0.769344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.519900</td>\n",
              "      <td>0.669769</td>\n",
              "      <td>0.696250</td>\n",
              "      <td>0.734426</td>\n",
              "      <td>0.689841</td>\n",
              "      <td>0.652427</td>\n",
              "      <td>0.840000</td>\n",
              "      <td>0.552500</td>\n",
              "      <td>0.409802</td>\n",
              "      <td>0.778087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.059500</td>\n",
              "      <td>0.864332</td>\n",
              "      <td>0.698750</td>\n",
              "      <td>0.709988</td>\n",
              "      <td>0.698297</td>\n",
              "      <td>0.684455</td>\n",
              "      <td>0.737500</td>\n",
              "      <td>0.660000</td>\n",
              "      <td>0.398699</td>\n",
              "      <td>0.784119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.015400</td>\n",
              "      <td>1.236200</td>\n",
              "      <td>0.690000</td>\n",
              "      <td>0.729847</td>\n",
              "      <td>0.683106</td>\n",
              "      <td>0.646718</td>\n",
              "      <td>0.837500</td>\n",
              "      <td>0.542500</td>\n",
              "      <td>0.397699</td>\n",
              "      <td>0.778738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.104000</td>\n",
              "      <td>1.276052</td>\n",
              "      <td>0.695000</td>\n",
              "      <td>0.727679</td>\n",
              "      <td>0.690544</td>\n",
              "      <td>0.657258</td>\n",
              "      <td>0.815000</td>\n",
              "      <td>0.575000</td>\n",
              "      <td>0.401742</td>\n",
              "      <td>0.777319</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 791, total number of training (for each informative and uninform class) and test samples: 200, 7000 0.025 DISRoBERTa-B 791 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilbert/distilroberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:10, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.692800</td>\n",
              "      <td>0.687124</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.711619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.588700</td>\n",
              "      <td>0.628155</td>\n",
              "      <td>0.653750</td>\n",
              "      <td>0.616874</td>\n",
              "      <td>0.650512</td>\n",
              "      <td>0.690402</td>\n",
              "      <td>0.557500</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.313361</td>\n",
              "      <td>0.741125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.468100</td>\n",
              "      <td>0.848225</td>\n",
              "      <td>0.685000</td>\n",
              "      <td>0.683417</td>\n",
              "      <td>0.684992</td>\n",
              "      <td>0.686869</td>\n",
              "      <td>0.680000</td>\n",
              "      <td>0.690000</td>\n",
              "      <td>0.370019</td>\n",
              "      <td>0.756794</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.115300</td>\n",
              "      <td>1.352373</td>\n",
              "      <td>0.683750</td>\n",
              "      <td>0.718576</td>\n",
              "      <td>0.678832</td>\n",
              "      <td>0.647295</td>\n",
              "      <td>0.807500</td>\n",
              "      <td>0.560000</td>\n",
              "      <td>0.379301</td>\n",
              "      <td>0.762044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.132700</td>\n",
              "      <td>1.539172</td>\n",
              "      <td>0.673750</td>\n",
              "      <td>0.660598</td>\n",
              "      <td>0.673259</td>\n",
              "      <td>0.688347</td>\n",
              "      <td>0.635000</td>\n",
              "      <td>0.712500</td>\n",
              "      <td>0.348548</td>\n",
              "      <td>0.752375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.009100</td>\n",
              "      <td>1.605907</td>\n",
              "      <td>0.681250</td>\n",
              "      <td>0.695341</td>\n",
              "      <td>0.680567</td>\n",
              "      <td>0.665904</td>\n",
              "      <td>0.727500</td>\n",
              "      <td>0.635000</td>\n",
              "      <td>0.364061</td>\n",
              "      <td>0.758838</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 5, total number of training (for each informative and uninform class) and test samples: 200, 7000 0.025 DISRoBERTa-B 5 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilbert/distilroberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:10, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.694100</td>\n",
              "      <td>0.683812</td>\n",
              "      <td>0.510000</td>\n",
              "      <td>0.668919</td>\n",
              "      <td>0.363306</td>\n",
              "      <td>0.505102</td>\n",
              "      <td>0.990000</td>\n",
              "      <td>0.030000</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.723994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.580200</td>\n",
              "      <td>0.626611</td>\n",
              "      <td>0.690000</td>\n",
              "      <td>0.706161</td>\n",
              "      <td>0.689059</td>\n",
              "      <td>0.671171</td>\n",
              "      <td>0.745000</td>\n",
              "      <td>0.635000</td>\n",
              "      <td>0.382320</td>\n",
              "      <td>0.754400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.711800</td>\n",
              "      <td>1.300208</td>\n",
              "      <td>0.647500</td>\n",
              "      <td>0.705637</td>\n",
              "      <td>0.633192</td>\n",
              "      <td>0.605735</td>\n",
              "      <td>0.845000</td>\n",
              "      <td>0.450000</td>\n",
              "      <td>0.321113</td>\n",
              "      <td>0.750337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.076000</td>\n",
              "      <td>1.475476</td>\n",
              "      <td>0.678750</td>\n",
              "      <td>0.698002</td>\n",
              "      <td>0.677439</td>\n",
              "      <td>0.658537</td>\n",
              "      <td>0.742500</td>\n",
              "      <td>0.615000</td>\n",
              "      <td>0.360442</td>\n",
              "      <td>0.751287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.295000</td>\n",
              "      <td>1.707565</td>\n",
              "      <td>0.666250</td>\n",
              "      <td>0.702341</td>\n",
              "      <td>0.661270</td>\n",
              "      <td>0.633803</td>\n",
              "      <td>0.787500</td>\n",
              "      <td>0.545000</td>\n",
              "      <td>0.342730</td>\n",
              "      <td>0.744188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.151900</td>\n",
              "      <td>1.719343</td>\n",
              "      <td>0.673750</td>\n",
              "      <td>0.696158</td>\n",
              "      <td>0.671966</td>\n",
              "      <td>0.651416</td>\n",
              "      <td>0.747500</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.351343</td>\n",
              "      <td>0.746969</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 6932, total number of training (for each informative and uninform class) and test samples: 200, 7000 0.025 DISRoBERTa-B 6932 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilbert/distilroberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:10, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.688500</td>\n",
              "      <td>0.676152</td>\n",
              "      <td>0.643750</td>\n",
              "      <td>0.609053</td>\n",
              "      <td>0.640922</td>\n",
              "      <td>0.674772</td>\n",
              "      <td>0.555000</td>\n",
              "      <td>0.732500</td>\n",
              "      <td>0.292139</td>\n",
              "      <td>0.705438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.445900</td>\n",
              "      <td>0.819703</td>\n",
              "      <td>0.595000</td>\n",
              "      <td>0.677291</td>\n",
              "      <td>0.566833</td>\n",
              "      <td>0.562914</td>\n",
              "      <td>0.850000</td>\n",
              "      <td>0.340000</td>\n",
              "      <td>0.220885</td>\n",
              "      <td>0.706944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.403800</td>\n",
              "      <td>0.939581</td>\n",
              "      <td>0.636250</td>\n",
              "      <td>0.675585</td>\n",
              "      <td>0.630823</td>\n",
              "      <td>0.609658</td>\n",
              "      <td>0.757500</td>\n",
              "      <td>0.515000</td>\n",
              "      <td>0.280884</td>\n",
              "      <td>0.728325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.395800</td>\n",
              "      <td>1.412730</td>\n",
              "      <td>0.660000</td>\n",
              "      <td>0.594030</td>\n",
              "      <td>0.650778</td>\n",
              "      <td>0.737037</td>\n",
              "      <td>0.497500</td>\n",
              "      <td>0.822500</td>\n",
              "      <td>0.338369</td>\n",
              "      <td>0.735313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.185000</td>\n",
              "      <td>1.570221</td>\n",
              "      <td>0.670000</td>\n",
              "      <td>0.657143</td>\n",
              "      <td>0.669535</td>\n",
              "      <td>0.683784</td>\n",
              "      <td>0.632500</td>\n",
              "      <td>0.707500</td>\n",
              "      <td>0.340960</td>\n",
              "      <td>0.730613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.004400</td>\n",
              "      <td>1.631371</td>\n",
              "      <td>0.670000</td>\n",
              "      <td>0.653543</td>\n",
              "      <td>0.669254</td>\n",
              "      <td>0.687845</td>\n",
              "      <td>0.622500</td>\n",
              "      <td>0.717500</td>\n",
              "      <td>0.341545</td>\n",
              "      <td>0.729006</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 1759, total number of training (for each informative and uninform class) and test samples: 200, 7000 0.025 DISRoBERTa-B 1759 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilbert/distilroberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:10, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.677100</td>\n",
              "      <td>0.667708</td>\n",
              "      <td>0.635000</td>\n",
              "      <td>0.715400</td>\n",
              "      <td>0.603344</td>\n",
              "      <td>0.586262</td>\n",
              "      <td>0.917500</td>\n",
              "      <td>0.352500</td>\n",
              "      <td>0.327237</td>\n",
              "      <td>0.723475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.579400</td>\n",
              "      <td>0.573814</td>\n",
              "      <td>0.711250</td>\n",
              "      <td>0.720677</td>\n",
              "      <td>0.710921</td>\n",
              "      <td>0.697892</td>\n",
              "      <td>0.745000</td>\n",
              "      <td>0.677500</td>\n",
              "      <td>0.423466</td>\n",
              "      <td>0.784025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.446700</td>\n",
              "      <td>0.696012</td>\n",
              "      <td>0.718750</td>\n",
              "      <td>0.689655</td>\n",
              "      <td>0.716256</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.445399</td>\n",
              "      <td>0.789631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.533200</td>\n",
              "      <td>1.370027</td>\n",
              "      <td>0.716250</td>\n",
              "      <td>0.712294</td>\n",
              "      <td>0.716196</td>\n",
              "      <td>0.722365</td>\n",
              "      <td>0.702500</td>\n",
              "      <td>0.730000</td>\n",
              "      <td>0.432664</td>\n",
              "      <td>0.783963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.118300</td>\n",
              "      <td>1.548090</td>\n",
              "      <td>0.723750</td>\n",
              "      <td>0.739079</td>\n",
              "      <td>0.722793</td>\n",
              "      <td>0.700224</td>\n",
              "      <td>0.782500</td>\n",
              "      <td>0.665000</td>\n",
              "      <td>0.450622</td>\n",
              "      <td>0.792994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.049600</td>\n",
              "      <td>1.632788</td>\n",
              "      <td>0.723750</td>\n",
              "      <td>0.750846</td>\n",
              "      <td>0.720444</td>\n",
              "      <td>0.683778</td>\n",
              "      <td>0.832500</td>\n",
              "      <td>0.615000</td>\n",
              "      <td>0.458476</td>\n",
              "      <td>0.795259</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 323, total number of training (for each informative and uninform class) and test samples: 200, 7000 0.025 DISRoBERTa-B 323 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilbert/distilroberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:10, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>0.690178</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.746544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.699700</td>\n",
              "      <td>0.642561</td>\n",
              "      <td>0.705000</td>\n",
              "      <td>0.693506</td>\n",
              "      <td>0.704585</td>\n",
              "      <td>0.721622</td>\n",
              "      <td>0.667500</td>\n",
              "      <td>0.742500</td>\n",
              "      <td>0.411158</td>\n",
              "      <td>0.789869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.515700</td>\n",
              "      <td>0.883197</td>\n",
              "      <td>0.632500</td>\n",
              "      <td>0.722117</td>\n",
              "      <td>0.589841</td>\n",
              "      <td>0.580547</td>\n",
              "      <td>0.955000</td>\n",
              "      <td>0.310000</td>\n",
              "      <td>0.346776</td>\n",
              "      <td>0.783669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.258500</td>\n",
              "      <td>0.806582</td>\n",
              "      <td>0.705000</td>\n",
              "      <td>0.737194</td>\n",
              "      <td>0.700506</td>\n",
              "      <td>0.664659</td>\n",
              "      <td>0.827500</td>\n",
              "      <td>0.582500</td>\n",
              "      <td>0.422888</td>\n",
              "      <td>0.782175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.228200</td>\n",
              "      <td>1.053887</td>\n",
              "      <td>0.698750</td>\n",
              "      <td>0.732519</td>\n",
              "      <td>0.693871</td>\n",
              "      <td>0.658683</td>\n",
              "      <td>0.825000</td>\n",
              "      <td>0.572500</td>\n",
              "      <td>0.410812</td>\n",
              "      <td>0.781444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.198400</td>\n",
              "      <td>1.149198</td>\n",
              "      <td>0.702500</td>\n",
              "      <td>0.738462</td>\n",
              "      <td>0.696767</td>\n",
              "      <td>0.658824</td>\n",
              "      <td>0.840000</td>\n",
              "      <td>0.565000</td>\n",
              "      <td>0.421241</td>\n",
              "      <td>0.782863</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 1694, total number of training (for each informative and uninform class) and test samples: 200, 7000 0.025 DISRoBERTa-B 1694 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilbert/distilroberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:10, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.704900</td>\n",
              "      <td>0.677093</td>\n",
              "      <td>0.506250</td>\n",
              "      <td>0.669456</td>\n",
              "      <td>0.347074</td>\n",
              "      <td>0.503145</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.012500</td>\n",
              "      <td>0.079305</td>\n",
              "      <td>0.725394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.474500</td>\n",
              "      <td>0.736566</td>\n",
              "      <td>0.652500</td>\n",
              "      <td>0.715164</td>\n",
              "      <td>0.634826</td>\n",
              "      <td>0.605903</td>\n",
              "      <td>0.872500</td>\n",
              "      <td>0.432500</td>\n",
              "      <td>0.339644</td>\n",
              "      <td>0.739969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.165800</td>\n",
              "      <td>0.900660</td>\n",
              "      <td>0.681250</td>\n",
              "      <td>0.696067</td>\n",
              "      <td>0.680491</td>\n",
              "      <td>0.665148</td>\n",
              "      <td>0.730000</td>\n",
              "      <td>0.632500</td>\n",
              "      <td>0.364235</td>\n",
              "      <td>0.748562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.187600</td>\n",
              "      <td>1.326179</td>\n",
              "      <td>0.686250</td>\n",
              "      <td>0.700119</td>\n",
              "      <td>0.685577</td>\n",
              "      <td>0.670481</td>\n",
              "      <td>0.732500</td>\n",
              "      <td>0.640000</td>\n",
              "      <td>0.374104</td>\n",
              "      <td>0.746069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.056300</td>\n",
              "      <td>1.595387</td>\n",
              "      <td>0.676250</td>\n",
              "      <td>0.654206</td>\n",
              "      <td>0.674929</td>\n",
              "      <td>0.702006</td>\n",
              "      <td>0.612500</td>\n",
              "      <td>0.740000</td>\n",
              "      <td>0.355401</td>\n",
              "      <td>0.733806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.043000</td>\n",
              "      <td>1.629517</td>\n",
              "      <td>0.692500</td>\n",
              "      <td>0.691729</td>\n",
              "      <td>0.692498</td>\n",
              "      <td>0.693467</td>\n",
              "      <td>0.690000</td>\n",
              "      <td>0.695000</td>\n",
              "      <td>0.385005</td>\n",
              "      <td>0.737069</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 9741, total number of training (for each informative and uninform class) and test samples: 200, 7000 0.025 DISRoBERTa-B 9741 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilbert/distilroberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:10, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.684900</td>\n",
              "      <td>0.680479</td>\n",
              "      <td>0.670000</td>\n",
              "      <td>0.697248</td>\n",
              "      <td>0.667305</td>\n",
              "      <td>0.644068</td>\n",
              "      <td>0.760000</td>\n",
              "      <td>0.580000</td>\n",
              "      <td>0.345646</td>\n",
              "      <td>0.708106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.618000</td>\n",
              "      <td>0.820782</td>\n",
              "      <td>0.577500</td>\n",
              "      <td>0.698752</td>\n",
              "      <td>0.495820</td>\n",
              "      <td>0.542936</td>\n",
              "      <td>0.980000</td>\n",
              "      <td>0.175000</td>\n",
              "      <td>0.261262</td>\n",
              "      <td>0.760850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.313100</td>\n",
              "      <td>0.791197</td>\n",
              "      <td>0.690000</td>\n",
              "      <td>0.718821</td>\n",
              "      <td>0.686708</td>\n",
              "      <td>0.657676</td>\n",
              "      <td>0.792500</td>\n",
              "      <td>0.587500</td>\n",
              "      <td>0.388246</td>\n",
              "      <td>0.769575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.028400</td>\n",
              "      <td>1.164798</td>\n",
              "      <td>0.690000</td>\n",
              "      <td>0.698297</td>\n",
              "      <td>0.689765</td>\n",
              "      <td>0.680095</td>\n",
              "      <td>0.717500</td>\n",
              "      <td>0.662500</td>\n",
              "      <td>0.380576</td>\n",
              "      <td>0.772581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.159400</td>\n",
              "      <td>1.385129</td>\n",
              "      <td>0.686250</td>\n",
              "      <td>0.700834</td>\n",
              "      <td>0.685503</td>\n",
              "      <td>0.669704</td>\n",
              "      <td>0.735000</td>\n",
              "      <td>0.637500</td>\n",
              "      <td>0.374283</td>\n",
              "      <td>0.773913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.075700</td>\n",
              "      <td>1.444523</td>\n",
              "      <td>0.690000</td>\n",
              "      <td>0.706161</td>\n",
              "      <td>0.689059</td>\n",
              "      <td>0.671171</td>\n",
              "      <td>0.745000</td>\n",
              "      <td>0.635000</td>\n",
              "      <td>0.382320</td>\n",
              "      <td>0.773919</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 200, total number of training (for each informative and uninform class) and test samples: 200, 7000 0.025 DISRoBERTa-B 200 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilbert/distilroberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:10, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.692200</td>\n",
              "      <td>0.681701</td>\n",
              "      <td>0.640000</td>\n",
              "      <td>0.702479</td>\n",
              "      <td>0.623392</td>\n",
              "      <td>0.598592</td>\n",
              "      <td>0.850000</td>\n",
              "      <td>0.430000</td>\n",
              "      <td>0.308532</td>\n",
              "      <td>0.738750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.563500</td>\n",
              "      <td>0.594838</td>\n",
              "      <td>0.676250</td>\n",
              "      <td>0.700578</td>\n",
              "      <td>0.674099</td>\n",
              "      <td>0.651613</td>\n",
              "      <td>0.757500</td>\n",
              "      <td>0.595000</td>\n",
              "      <td>0.357248</td>\n",
              "      <td>0.755456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.394000</td>\n",
              "      <td>0.711788</td>\n",
              "      <td>0.695000</td>\n",
              "      <td>0.680628</td>\n",
              "      <td>0.694381</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>0.740000</td>\n",
              "      <td>0.391589</td>\n",
              "      <td>0.763213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.627600</td>\n",
              "      <td>1.089945</td>\n",
              "      <td>0.683750</td>\n",
              "      <td>0.699168</td>\n",
              "      <td>0.682917</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.735000</td>\n",
              "      <td>0.632500</td>\n",
              "      <td>0.369446</td>\n",
              "      <td>0.772294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.331200</td>\n",
              "      <td>1.255428</td>\n",
              "      <td>0.690000</td>\n",
              "      <td>0.705463</td>\n",
              "      <td>0.689143</td>\n",
              "      <td>0.671946</td>\n",
              "      <td>0.742500</td>\n",
              "      <td>0.637500</td>\n",
              "      <td>0.382112</td>\n",
              "      <td>0.774944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.090400</td>\n",
              "      <td>1.318912</td>\n",
              "      <td>0.686250</td>\n",
              "      <td>0.700834</td>\n",
              "      <td>0.685503</td>\n",
              "      <td>0.669704</td>\n",
              "      <td>0.735000</td>\n",
              "      <td>0.637500</td>\n",
              "      <td>0.374283</td>\n",
              "      <td>0.774263</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 999, total number of training (for each informative and uninform class) and test samples: 200, 7000 0.025 DISRoBERTa-B 999 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilbert/distilroberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:10, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.717500</td>\n",
              "      <td>0.687758</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.714769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.632500</td>\n",
              "      <td>0.727266</td>\n",
              "      <td>0.556250</td>\n",
              "      <td>0.276986</td>\n",
              "      <td>0.478439</td>\n",
              "      <td>0.747253</td>\n",
              "      <td>0.170000</td>\n",
              "      <td>0.942500</td>\n",
              "      <td>0.177161</td>\n",
              "      <td>0.726588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.619800</td>\n",
              "      <td>0.756593</td>\n",
              "      <td>0.685000</td>\n",
              "      <td>0.688889</td>\n",
              "      <td>0.684951</td>\n",
              "      <td>0.680488</td>\n",
              "      <td>0.697500</td>\n",
              "      <td>0.672500</td>\n",
              "      <td>0.370116</td>\n",
              "      <td>0.750812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.363400</td>\n",
              "      <td>1.093897</td>\n",
              "      <td>0.690000</td>\n",
              "      <td>0.717540</td>\n",
              "      <td>0.687025</td>\n",
              "      <td>0.658996</td>\n",
              "      <td>0.787500</td>\n",
              "      <td>0.592500</td>\n",
              "      <td>0.387438</td>\n",
              "      <td>0.754975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.008300</td>\n",
              "      <td>1.432201</td>\n",
              "      <td>0.668750</td>\n",
              "      <td>0.699887</td>\n",
              "      <td>0.665146</td>\n",
              "      <td>0.639752</td>\n",
              "      <td>0.772500</td>\n",
              "      <td>0.565000</td>\n",
              "      <td>0.345009</td>\n",
              "      <td>0.748050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.287600</td>\n",
              "      <td>1.490528</td>\n",
              "      <td>0.675000</td>\n",
              "      <td>0.680590</td>\n",
              "      <td>0.674900</td>\n",
              "      <td>0.669082</td>\n",
              "      <td>0.692500</td>\n",
              "      <td>0.657500</td>\n",
              "      <td>0.350215</td>\n",
              "      <td>0.746906</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 94, total number of training (for each informative and uninform class) and test samples: 200, 7000 0.025 XLNet-B 94 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:27, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.660500</td>\n",
              "      <td>0.641652</td>\n",
              "      <td>0.630000</td>\n",
              "      <td>0.611549</td>\n",
              "      <td>0.629163</td>\n",
              "      <td>0.643646</td>\n",
              "      <td>0.582500</td>\n",
              "      <td>0.677500</td>\n",
              "      <td>0.261181</td>\n",
              "      <td>0.659738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.694000</td>\n",
              "      <td>0.669872</td>\n",
              "      <td>0.531250</td>\n",
              "      <td>0.677558</td>\n",
              "      <td>0.409717</td>\n",
              "      <td>0.516383</td>\n",
              "      <td>0.985000</td>\n",
              "      <td>0.077500</td>\n",
              "      <td>0.148791</td>\n",
              "      <td>0.722406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.622000</td>\n",
              "      <td>0.737617</td>\n",
              "      <td>0.637500</td>\n",
              "      <td>0.719536</td>\n",
              "      <td>0.603584</td>\n",
              "      <td>0.586751</td>\n",
              "      <td>0.930000</td>\n",
              "      <td>0.345000</td>\n",
              "      <td>0.339074</td>\n",
              "      <td>0.730312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.507000</td>\n",
              "      <td>0.632157</td>\n",
              "      <td>0.712500</td>\n",
              "      <td>0.730679</td>\n",
              "      <td>0.711184</td>\n",
              "      <td>0.687225</td>\n",
              "      <td>0.780000</td>\n",
              "      <td>0.645000</td>\n",
              "      <td>0.428927</td>\n",
              "      <td>0.773863</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.372500</td>\n",
              "      <td>0.692023</td>\n",
              "      <td>0.698750</td>\n",
              "      <td>0.723307</td>\n",
              "      <td>0.696358</td>\n",
              "      <td>0.668790</td>\n",
              "      <td>0.787500</td>\n",
              "      <td>0.610000</td>\n",
              "      <td>0.403914</td>\n",
              "      <td>0.779175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.258600</td>\n",
              "      <td>0.764567</td>\n",
              "      <td>0.691250</td>\n",
              "      <td>0.730643</td>\n",
              "      <td>0.684502</td>\n",
              "      <td>0.647969</td>\n",
              "      <td>0.837500</td>\n",
              "      <td>0.545000</td>\n",
              "      <td>0.399994</td>\n",
              "      <td>0.778706</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 791, total number of training (for each informative and uninform class) and test samples: 200, 7000 0.025 XLNet-B 791 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:28, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.676600</td>\n",
              "      <td>0.680355</td>\n",
              "      <td>0.543750</td>\n",
              "      <td>0.215054</td>\n",
              "      <td>0.446734</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.962500</td>\n",
              "      <td>0.160128</td>\n",
              "      <td>0.618287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.636300</td>\n",
              "      <td>0.646470</td>\n",
              "      <td>0.613750</td>\n",
              "      <td>0.670224</td>\n",
              "      <td>0.602080</td>\n",
              "      <td>0.584730</td>\n",
              "      <td>0.785000</td>\n",
              "      <td>0.442500</td>\n",
              "      <td>0.242145</td>\n",
              "      <td>0.692906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.387700</td>\n",
              "      <td>0.864564</td>\n",
              "      <td>0.635000</td>\n",
              "      <td>0.674833</td>\n",
              "      <td>0.629439</td>\n",
              "      <td>0.608434</td>\n",
              "      <td>0.757500</td>\n",
              "      <td>0.512500</td>\n",
              "      <td>0.278487</td>\n",
              "      <td>0.715900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.241100</td>\n",
              "      <td>1.604349</td>\n",
              "      <td>0.641250</td>\n",
              "      <td>0.712713</td>\n",
              "      <td>0.617588</td>\n",
              "      <td>0.594324</td>\n",
              "      <td>0.890000</td>\n",
              "      <td>0.392500</td>\n",
              "      <td>0.325662</td>\n",
              "      <td>0.731656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.415200</td>\n",
              "      <td>1.717440</td>\n",
              "      <td>0.661250</td>\n",
              "      <td>0.648508</td>\n",
              "      <td>0.660804</td>\n",
              "      <td>0.673854</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.697500</td>\n",
              "      <td>0.323351</td>\n",
              "      <td>0.730200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.020200</td>\n",
              "      <td>1.840635</td>\n",
              "      <td>0.666250</td>\n",
              "      <td>0.687719</td>\n",
              "      <td>0.664665</td>\n",
              "      <td>0.646154</td>\n",
              "      <td>0.735000</td>\n",
              "      <td>0.597500</td>\n",
              "      <td>0.335688</td>\n",
              "      <td>0.733050</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 5, total number of training (for each informative and uninform class) and test samples: 200, 7000 0.025 XLNet-B 5 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:27, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.676400</td>\n",
              "      <td>0.707047</td>\n",
              "      <td>0.535000</td>\n",
              "      <td>0.670796</td>\n",
              "      <td>0.439654</td>\n",
              "      <td>0.519178</td>\n",
              "      <td>0.947500</td>\n",
              "      <td>0.122500</td>\n",
              "      <td>0.123865</td>\n",
              "      <td>0.635712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.640000</td>\n",
              "      <td>0.610454</td>\n",
              "      <td>0.680000</td>\n",
              "      <td>0.673469</td>\n",
              "      <td>0.679872</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>0.660000</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.360288</td>\n",
              "      <td>0.744244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.484700</td>\n",
              "      <td>0.860454</td>\n",
              "      <td>0.671250</td>\n",
              "      <td>0.709392</td>\n",
              "      <td>0.665487</td>\n",
              "      <td>0.635644</td>\n",
              "      <td>0.802500</td>\n",
              "      <td>0.540000</td>\n",
              "      <td>0.354947</td>\n",
              "      <td>0.748700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.377800</td>\n",
              "      <td>1.166632</td>\n",
              "      <td>0.655000</td>\n",
              "      <td>0.680556</td>\n",
              "      <td>0.652778</td>\n",
              "      <td>0.633621</td>\n",
              "      <td>0.735000</td>\n",
              "      <td>0.575000</td>\n",
              "      <td>0.314046</td>\n",
              "      <td>0.738538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.368400</td>\n",
              "      <td>1.760553</td>\n",
              "      <td>0.648750</td>\n",
              "      <td>0.712385</td>\n",
              "      <td>0.630671</td>\n",
              "      <td>0.603120</td>\n",
              "      <td>0.870000</td>\n",
              "      <td>0.427500</td>\n",
              "      <td>0.331747</td>\n",
              "      <td>0.740525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.038300</td>\n",
              "      <td>1.801491</td>\n",
              "      <td>0.651250</td>\n",
              "      <td>0.706006</td>\n",
              "      <td>0.638717</td>\n",
              "      <td>0.610200</td>\n",
              "      <td>0.837500</td>\n",
              "      <td>0.465000</td>\n",
              "      <td>0.325959</td>\n",
              "      <td>0.742169</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 6932, total number of training (for each informative and uninform class) and test samples: 200, 7000 0.025 XLNet-B 6932 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:28, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.699600</td>\n",
              "      <td>0.680119</td>\n",
              "      <td>0.592500</td>\n",
              "      <td>0.605327</td>\n",
              "      <td>0.592069</td>\n",
              "      <td>0.586854</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.560000</td>\n",
              "      <td>0.185392</td>\n",
              "      <td>0.637194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.674100</td>\n",
              "      <td>0.715014</td>\n",
              "      <td>0.571250</td>\n",
              "      <td>0.674264</td>\n",
              "      <td>0.523604</td>\n",
              "      <td>0.543645</td>\n",
              "      <td>0.887500</td>\n",
              "      <td>0.255000</td>\n",
              "      <td>0.183975</td>\n",
              "      <td>0.633625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.536300</td>\n",
              "      <td>0.746543</td>\n",
              "      <td>0.615000</td>\n",
              "      <td>0.608142</td>\n",
              "      <td>0.614882</td>\n",
              "      <td>0.619171</td>\n",
              "      <td>0.597500</td>\n",
              "      <td>0.632500</td>\n",
              "      <td>0.230141</td>\n",
              "      <td>0.672219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.682900</td>\n",
              "      <td>0.787908</td>\n",
              "      <td>0.613750</td>\n",
              "      <td>0.544919</td>\n",
              "      <td>0.604707</td>\n",
              "      <td>0.663082</td>\n",
              "      <td>0.462500</td>\n",
              "      <td>0.765000</td>\n",
              "      <td>0.238682</td>\n",
              "      <td>0.679206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.371800</td>\n",
              "      <td>0.888247</td>\n",
              "      <td>0.652500</td>\n",
              "      <td>0.607345</td>\n",
              "      <td>0.647843</td>\n",
              "      <td>0.698052</td>\n",
              "      <td>0.537500</td>\n",
              "      <td>0.767500</td>\n",
              "      <td>0.313402</td>\n",
              "      <td>0.693975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.224200</td>\n",
              "      <td>0.997248</td>\n",
              "      <td>0.641250</td>\n",
              "      <td>0.613728</td>\n",
              "      <td>0.639419</td>\n",
              "      <td>0.664723</td>\n",
              "      <td>0.570000</td>\n",
              "      <td>0.712500</td>\n",
              "      <td>0.285413</td>\n",
              "      <td>0.692012</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 1759, total number of training (for each informative and uninform class) and test samples: 200, 7000 0.025 XLNet-B 1759 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:28, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.716600</td>\n",
              "      <td>0.671915</td>\n",
              "      <td>0.611250</td>\n",
              "      <td>0.622114</td>\n",
              "      <td>0.610928</td>\n",
              "      <td>0.605201</td>\n",
              "      <td>0.640000</td>\n",
              "      <td>0.582500</td>\n",
              "      <td>0.222869</td>\n",
              "      <td>0.590437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.639500</td>\n",
              "      <td>0.656252</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.642005</td>\n",
              "      <td>0.624152</td>\n",
              "      <td>0.614155</td>\n",
              "      <td>0.672500</td>\n",
              "      <td>0.577500</td>\n",
              "      <td>0.251136</td>\n",
              "      <td>0.640594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.563000</td>\n",
              "      <td>0.812585</td>\n",
              "      <td>0.533750</td>\n",
              "      <td>0.142529</td>\n",
              "      <td>0.411179</td>\n",
              "      <td>0.885714</td>\n",
              "      <td>0.077500</td>\n",
              "      <td>0.990000</td>\n",
              "      <td>0.165006</td>\n",
              "      <td>0.700075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.692800</td>\n",
              "      <td>0.788956</td>\n",
              "      <td>0.652500</td>\n",
              "      <td>0.530405</td>\n",
              "      <td>0.627306</td>\n",
              "      <td>0.817708</td>\n",
              "      <td>0.392500</td>\n",
              "      <td>0.912500</td>\n",
              "      <td>0.357073</td>\n",
              "      <td>0.759331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.290300</td>\n",
              "      <td>0.765372</td>\n",
              "      <td>0.706250</td>\n",
              "      <td>0.736842</td>\n",
              "      <td>0.702226</td>\n",
              "      <td>0.667343</td>\n",
              "      <td>0.822500</td>\n",
              "      <td>0.590000</td>\n",
              "      <td>0.424122</td>\n",
              "      <td>0.778394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.113300</td>\n",
              "      <td>0.863055</td>\n",
              "      <td>0.711250</td>\n",
              "      <td>0.739572</td>\n",
              "      <td>0.707794</td>\n",
              "      <td>0.673511</td>\n",
              "      <td>0.820000</td>\n",
              "      <td>0.602500</td>\n",
              "      <td>0.432863</td>\n",
              "      <td>0.782181</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 323, total number of training (for each informative and uninform class) and test samples: 200, 7000 0.025 XLNet-B 323 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:27, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.721300</td>\n",
              "      <td>0.684082</td>\n",
              "      <td>0.546250</td>\n",
              "      <td>0.582278</td>\n",
              "      <td>0.542849</td>\n",
              "      <td>0.539446</td>\n",
              "      <td>0.632500</td>\n",
              "      <td>0.460000</td>\n",
              "      <td>0.093908</td>\n",
              "      <td>0.542050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.752600</td>\n",
              "      <td>0.684677</td>\n",
              "      <td>0.612500</td>\n",
              "      <td>0.657837</td>\n",
              "      <td>0.605575</td>\n",
              "      <td>0.588933</td>\n",
              "      <td>0.745000</td>\n",
              "      <td>0.480000</td>\n",
              "      <td>0.233342</td>\n",
              "      <td>0.664106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.714200</td>\n",
              "      <td>0.820714</td>\n",
              "      <td>0.597500</td>\n",
              "      <td>0.686160</td>\n",
              "      <td>0.562592</td>\n",
              "      <td>0.562300</td>\n",
              "      <td>0.880000</td>\n",
              "      <td>0.315000</td>\n",
              "      <td>0.236338</td>\n",
              "      <td>0.693544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.558000</td>\n",
              "      <td>0.928843</td>\n",
              "      <td>0.630000</td>\n",
              "      <td>0.634568</td>\n",
              "      <td>0.629942</td>\n",
              "      <td>0.626829</td>\n",
              "      <td>0.642500</td>\n",
              "      <td>0.617500</td>\n",
              "      <td>0.260081</td>\n",
              "      <td>0.693450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.517000</td>\n",
              "      <td>1.205615</td>\n",
              "      <td>0.638750</td>\n",
              "      <td>0.648846</td>\n",
              "      <td>0.638451</td>\n",
              "      <td>0.631206</td>\n",
              "      <td>0.667500</td>\n",
              "      <td>0.610000</td>\n",
              "      <td>0.277960</td>\n",
              "      <td>0.694106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.346000</td>\n",
              "      <td>1.378722</td>\n",
              "      <td>0.647500</td>\n",
              "      <td>0.642132</td>\n",
              "      <td>0.647421</td>\n",
              "      <td>0.652062</td>\n",
              "      <td>0.632500</td>\n",
              "      <td>0.662500</td>\n",
              "      <td>0.295133</td>\n",
              "      <td>0.700231</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 1694, total number of training (for each informative and uninform class) and test samples: 200, 7000 0.025 XLNet-B 1694 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:27, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.739500</td>\n",
              "      <td>0.729957</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.595906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.625300</td>\n",
              "      <td>0.652079</td>\n",
              "      <td>0.603750</td>\n",
              "      <td>0.675537</td>\n",
              "      <td>0.583355</td>\n",
              "      <td>0.571924</td>\n",
              "      <td>0.825000</td>\n",
              "      <td>0.382500</td>\n",
              "      <td>0.231386</td>\n",
              "      <td>0.690638</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.394600</td>\n",
              "      <td>0.682043</td>\n",
              "      <td>0.652500</td>\n",
              "      <td>0.669048</td>\n",
              "      <td>0.651629</td>\n",
              "      <td>0.638636</td>\n",
              "      <td>0.702500</td>\n",
              "      <td>0.602500</td>\n",
              "      <td>0.306537</td>\n",
              "      <td>0.722769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.502800</td>\n",
              "      <td>0.909933</td>\n",
              "      <td>0.671250</td>\n",
              "      <td>0.686532</td>\n",
              "      <td>0.670467</td>\n",
              "      <td>0.656036</td>\n",
              "      <td>0.720000</td>\n",
              "      <td>0.622500</td>\n",
              "      <td>0.344140</td>\n",
              "      <td>0.734237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.127100</td>\n",
              "      <td>1.059775</td>\n",
              "      <td>0.690000</td>\n",
              "      <td>0.676240</td>\n",
              "      <td>0.689439</td>\n",
              "      <td>0.707650</td>\n",
              "      <td>0.647500</td>\n",
              "      <td>0.732500</td>\n",
              "      <td>0.381380</td>\n",
              "      <td>0.742144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.174300</td>\n",
              "      <td>1.228134</td>\n",
              "      <td>0.673750</td>\n",
              "      <td>0.691124</td>\n",
              "      <td>0.672714</td>\n",
              "      <td>0.656180</td>\n",
              "      <td>0.730000</td>\n",
              "      <td>0.617500</td>\n",
              "      <td>0.349720</td>\n",
              "      <td>0.738413</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 9741, total number of training (for each informative and uninform class) and test samples: 200, 7000 0.025 XLNet-B 9741 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:28, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.719200</td>\n",
              "      <td>0.733857</td>\n",
              "      <td>0.581250</td>\n",
              "      <td>0.680648</td>\n",
              "      <td>0.536331</td>\n",
              "      <td>0.550077</td>\n",
              "      <td>0.892500</td>\n",
              "      <td>0.270000</td>\n",
              "      <td>0.207636</td>\n",
              "      <td>0.656112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.807200</td>\n",
              "      <td>0.812104</td>\n",
              "      <td>0.536250</td>\n",
              "      <td>0.679343</td>\n",
              "      <td>0.420936</td>\n",
              "      <td>0.519155</td>\n",
              "      <td>0.982500</td>\n",
              "      <td>0.090000</td>\n",
              "      <td>0.160737</td>\n",
              "      <td>0.665687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.505400</td>\n",
              "      <td>0.640481</td>\n",
              "      <td>0.667500</td>\n",
              "      <td>0.689252</td>\n",
              "      <td>0.665863</td>\n",
              "      <td>0.646930</td>\n",
              "      <td>0.737500</td>\n",
              "      <td>0.597500</td>\n",
              "      <td>0.338332</td>\n",
              "      <td>0.715531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.326700</td>\n",
              "      <td>0.776319</td>\n",
              "      <td>0.660000</td>\n",
              "      <td>0.699115</td>\n",
              "      <td>0.654155</td>\n",
              "      <td>0.626984</td>\n",
              "      <td>0.790000</td>\n",
              "      <td>0.530000</td>\n",
              "      <td>0.331397</td>\n",
              "      <td>0.728062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.372800</td>\n",
              "      <td>0.987580</td>\n",
              "      <td>0.640000</td>\n",
              "      <td>0.701863</td>\n",
              "      <td>0.623802</td>\n",
              "      <td>0.598940</td>\n",
              "      <td>0.847500</td>\n",
              "      <td>0.432500</td>\n",
              "      <td>0.307753</td>\n",
              "      <td>0.725381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.150200</td>\n",
              "      <td>1.010283</td>\n",
              "      <td>0.651250</td>\n",
              "      <td>0.693069</td>\n",
              "      <td>0.644653</td>\n",
              "      <td>0.618861</td>\n",
              "      <td>0.787500</td>\n",
              "      <td>0.515000</td>\n",
              "      <td>0.314398</td>\n",
              "      <td>0.731812</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 200, total number of training (for each informative and uninform class) and test samples: 200, 7000 0.025 XLNet-B 200 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:27, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.716000</td>\n",
              "      <td>0.712975</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.498556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.737800</td>\n",
              "      <td>0.677218</td>\n",
              "      <td>0.575000</td>\n",
              "      <td>0.685185</td>\n",
              "      <td>0.515670</td>\n",
              "      <td>0.544118</td>\n",
              "      <td>0.925000</td>\n",
              "      <td>0.225000</td>\n",
              "      <td>0.210042</td>\n",
              "      <td>0.630175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.633400</td>\n",
              "      <td>0.639955</td>\n",
              "      <td>0.631250</td>\n",
              "      <td>0.617380</td>\n",
              "      <td>0.630765</td>\n",
              "      <td>0.641509</td>\n",
              "      <td>0.595000</td>\n",
              "      <td>0.667500</td>\n",
              "      <td>0.263193</td>\n",
              "      <td>0.684106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.469800</td>\n",
              "      <td>0.773029</td>\n",
              "      <td>0.641250</td>\n",
              "      <td>0.713858</td>\n",
              "      <td>0.616561</td>\n",
              "      <td>0.593698</td>\n",
              "      <td>0.895000</td>\n",
              "      <td>0.387500</td>\n",
              "      <td>0.327859</td>\n",
              "      <td>0.705375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.352600</td>\n",
              "      <td>0.831604</td>\n",
              "      <td>0.675000</td>\n",
              "      <td>0.691943</td>\n",
              "      <td>0.674014</td>\n",
              "      <td>0.657658</td>\n",
              "      <td>0.730000</td>\n",
              "      <td>0.620000</td>\n",
              "      <td>0.352137</td>\n",
              "      <td>0.720319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.265300</td>\n",
              "      <td>0.948138</td>\n",
              "      <td>0.665000</td>\n",
              "      <td>0.706783</td>\n",
              "      <td>0.658056</td>\n",
              "      <td>0.628405</td>\n",
              "      <td>0.807500</td>\n",
              "      <td>0.522500</td>\n",
              "      <td>0.344278</td>\n",
              "      <td>0.717394</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 999, total number of training (for each informative and uninform class) and test samples: 200, 7000 0.025 XLNet-B 999 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:27, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.656900</td>\n",
              "      <td>0.700663</td>\n",
              "      <td>0.563750</td>\n",
              "      <td>0.393043</td>\n",
              "      <td>0.526278</td>\n",
              "      <td>0.645714</td>\n",
              "      <td>0.282500</td>\n",
              "      <td>0.845000</td>\n",
              "      <td>0.154210</td>\n",
              "      <td>0.614219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.662400</td>\n",
              "      <td>0.638211</td>\n",
              "      <td>0.645000</td>\n",
              "      <td>0.654501</td>\n",
              "      <td>0.644731</td>\n",
              "      <td>0.637441</td>\n",
              "      <td>0.672500</td>\n",
              "      <td>0.617500</td>\n",
              "      <td>0.290440</td>\n",
              "      <td>0.692394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.521300</td>\n",
              "      <td>0.731564</td>\n",
              "      <td>0.671250</td>\n",
              "      <td>0.652576</td>\n",
              "      <td>0.670297</td>\n",
              "      <td>0.691877</td>\n",
              "      <td>0.617500</td>\n",
              "      <td>0.725000</td>\n",
              "      <td>0.344496</td>\n",
              "      <td>0.728987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.297000</td>\n",
              "      <td>0.812633</td>\n",
              "      <td>0.686250</td>\n",
              "      <td>0.698679</td>\n",
              "      <td>0.685715</td>\n",
              "      <td>0.672055</td>\n",
              "      <td>0.727500</td>\n",
              "      <td>0.645000</td>\n",
              "      <td>0.373774</td>\n",
              "      <td>0.737194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.059400</td>\n",
              "      <td>1.094880</td>\n",
              "      <td>0.671250</td>\n",
              "      <td>0.681212</td>\n",
              "      <td>0.670929</td>\n",
              "      <td>0.661176</td>\n",
              "      <td>0.702500</td>\n",
              "      <td>0.640000</td>\n",
              "      <td>0.343171</td>\n",
              "      <td>0.735281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.108900</td>\n",
              "      <td>1.347857</td>\n",
              "      <td>0.672500</td>\n",
              "      <td>0.703620</td>\n",
              "      <td>0.668849</td>\n",
              "      <td>0.642562</td>\n",
              "      <td>0.777500</td>\n",
              "      <td>0.567500</td>\n",
              "      <td>0.352868</td>\n",
              "      <td>0.736344</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 94, total number of training (for each informative and uninform class) and test samples: 200, 7000 0.025 XLNet-L 94 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-large-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:56, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.731400</td>\n",
              "      <td>0.685234</td>\n",
              "      <td>0.542500</td>\n",
              "      <td>0.207792</td>\n",
              "      <td>0.443088</td>\n",
              "      <td>0.774194</td>\n",
              "      <td>0.120000</td>\n",
              "      <td>0.965000</td>\n",
              "      <td>0.158948</td>\n",
              "      <td>0.506444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.771600</td>\n",
              "      <td>0.706669</td>\n",
              "      <td>0.507500</td>\n",
              "      <td>0.029557</td>\n",
              "      <td>0.349787</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.015000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.086929</td>\n",
              "      <td>0.482106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.726400</td>\n",
              "      <td>0.694459</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.560609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.824800</td>\n",
              "      <td>0.694290</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.610806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.709300</td>\n",
              "      <td>0.692557</td>\n",
              "      <td>0.507500</td>\n",
              "      <td>0.029557</td>\n",
              "      <td>0.349787</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.015000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.086929</td>\n",
              "      <td>0.591969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.767500</td>\n",
              "      <td>0.693804</td>\n",
              "      <td>0.516250</td>\n",
              "      <td>0.062954</td>\n",
              "      <td>0.368461</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.032500</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.128524</td>\n",
              "      <td>0.589419</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 791, total number of training (for each informative and uninform class) and test samples: 200, 7000 0.025 XLNet-L 791 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-large-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:56, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.633600</td>\n",
              "      <td>0.677682</td>\n",
              "      <td>0.590000</td>\n",
              "      <td>0.549451</td>\n",
              "      <td>0.586652</td>\n",
              "      <td>0.609756</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.680000</td>\n",
              "      <td>0.182989</td>\n",
              "      <td>0.588975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.783100</td>\n",
              "      <td>0.668716</td>\n",
              "      <td>0.580000</td>\n",
              "      <td>0.498507</td>\n",
              "      <td>0.568609</td>\n",
              "      <td>0.618519</td>\n",
              "      <td>0.417500</td>\n",
              "      <td>0.742500</td>\n",
              "      <td>0.169184</td>\n",
              "      <td>0.625344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.796600</td>\n",
              "      <td>0.715124</td>\n",
              "      <td>0.518750</td>\n",
              "      <td>0.672340</td>\n",
              "      <td>0.383229</td>\n",
              "      <td>0.509677</td>\n",
              "      <td>0.987500</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>0.107763</td>\n",
              "      <td>0.639787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.659500</td>\n",
              "      <td>0.685672</td>\n",
              "      <td>0.608750</td>\n",
              "      <td>0.665955</td>\n",
              "      <td>0.596929</td>\n",
              "      <td>0.581006</td>\n",
              "      <td>0.780000</td>\n",
              "      <td>0.437500</td>\n",
              "      <td>0.231502</td>\n",
              "      <td>0.671725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.389800</td>\n",
              "      <td>1.008648</td>\n",
              "      <td>0.616250</td>\n",
              "      <td>0.583446</td>\n",
              "      <td>0.613855</td>\n",
              "      <td>0.637982</td>\n",
              "      <td>0.537500</td>\n",
              "      <td>0.695000</td>\n",
              "      <td>0.235439</td>\n",
              "      <td>0.662700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.306500</td>\n",
              "      <td>1.353065</td>\n",
              "      <td>0.606250</td>\n",
              "      <td>0.484452</td>\n",
              "      <td>0.582974</td>\n",
              "      <td>0.701422</td>\n",
              "      <td>0.370000</td>\n",
              "      <td>0.842500</td>\n",
              "      <td>0.241113</td>\n",
              "      <td>0.661763</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 5, total number of training (for each informative and uninform class) and test samples: 200, 7000 0.025 XLNet-L 5 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-large-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:56, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.752600</td>\n",
              "      <td>0.697899</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.495806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.751100</td>\n",
              "      <td>0.735771</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.527000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.795900</td>\n",
              "      <td>0.693277</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.527913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.690600</td>\n",
              "      <td>0.693071</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.614100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.739900</td>\n",
              "      <td>0.700453</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.639294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.719800</td>\n",
              "      <td>0.693536</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.630694</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 6932, total number of training (for each informative and uninform class) and test samples: 200, 7000 0.025 XLNet-L 6932 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-large-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:56, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.686700</td>\n",
              "      <td>0.696651</td>\n",
              "      <td>0.525000</td>\n",
              "      <td>0.233871</td>\n",
              "      <td>0.444834</td>\n",
              "      <td>0.604167</td>\n",
              "      <td>0.145000</td>\n",
              "      <td>0.905000</td>\n",
              "      <td>0.076932</td>\n",
              "      <td>0.558500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.665400</td>\n",
              "      <td>0.691111</td>\n",
              "      <td>0.542500</td>\n",
              "      <td>0.580275</td>\n",
              "      <td>0.538764</td>\n",
              "      <td>0.536017</td>\n",
              "      <td>0.632500</td>\n",
              "      <td>0.452500</td>\n",
              "      <td>0.086411</td>\n",
              "      <td>0.570594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.783900</td>\n",
              "      <td>0.721725</td>\n",
              "      <td>0.536250</td>\n",
              "      <td>0.672551</td>\n",
              "      <td>0.439059</td>\n",
              "      <td>0.519782</td>\n",
              "      <td>0.952500</td>\n",
              "      <td>0.120000</td>\n",
              "      <td>0.130861</td>\n",
              "      <td>0.614900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.663700</td>\n",
              "      <td>0.681644</td>\n",
              "      <td>0.566250</td>\n",
              "      <td>0.396522</td>\n",
              "      <td>0.528993</td>\n",
              "      <td>0.651429</td>\n",
              "      <td>0.285000</td>\n",
              "      <td>0.847500</td>\n",
              "      <td>0.160257</td>\n",
              "      <td>0.619594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.549600</td>\n",
              "      <td>0.656974</td>\n",
              "      <td>0.617500</td>\n",
              "      <td>0.629540</td>\n",
              "      <td>0.617096</td>\n",
              "      <td>0.610329</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>0.585000</td>\n",
              "      <td>0.235498</td>\n",
              "      <td>0.662088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.713300</td>\n",
              "      <td>0.654386</td>\n",
              "      <td>0.635000</td>\n",
              "      <td>0.667426</td>\n",
              "      <td>0.631497</td>\n",
              "      <td>0.612971</td>\n",
              "      <td>0.732500</td>\n",
              "      <td>0.537500</td>\n",
              "      <td>0.275285</td>\n",
              "      <td>0.672063</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 1759, total number of training (for each informative and uninform class) and test samples: 200, 7000 0.025 XLNet-L 1759 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-large-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:56, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.755900</td>\n",
              "      <td>0.699568</td>\n",
              "      <td>0.501250</td>\n",
              "      <td>0.004988</td>\n",
              "      <td>0.336105</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.002500</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.035377</td>\n",
              "      <td>0.574084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.756100</td>\n",
              "      <td>0.695228</td>\n",
              "      <td>0.510000</td>\n",
              "      <td>0.096774</td>\n",
              "      <td>0.380291</td>\n",
              "      <td>0.617647</td>\n",
              "      <td>0.052500</td>\n",
              "      <td>0.967500</td>\n",
              "      <td>0.049572</td>\n",
              "      <td>0.564722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.779200</td>\n",
              "      <td>0.817408</td>\n",
              "      <td>0.516250</td>\n",
              "      <td>0.110345</td>\n",
              "      <td>0.389078</td>\n",
              "      <td>0.685714</td>\n",
              "      <td>0.060000</td>\n",
              "      <td>0.972500</td>\n",
              "      <td>0.079447</td>\n",
              "      <td>0.506088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.725100</td>\n",
              "      <td>0.656348</td>\n",
              "      <td>0.642500</td>\n",
              "      <td>0.601671</td>\n",
              "      <td>0.638704</td>\n",
              "      <td>0.679245</td>\n",
              "      <td>0.540000</td>\n",
              "      <td>0.745000</td>\n",
              "      <td>0.291184</td>\n",
              "      <td>0.674044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.673500</td>\n",
              "      <td>0.646215</td>\n",
              "      <td>0.656250</td>\n",
              "      <td>0.686431</td>\n",
              "      <td>0.653036</td>\n",
              "      <td>0.631027</td>\n",
              "      <td>0.752500</td>\n",
              "      <td>0.560000</td>\n",
              "      <td>0.318456</td>\n",
              "      <td>0.675700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.562400</td>\n",
              "      <td>0.627541</td>\n",
              "      <td>0.665000</td>\n",
              "      <td>0.678657</td>\n",
              "      <td>0.664394</td>\n",
              "      <td>0.652074</td>\n",
              "      <td>0.707500</td>\n",
              "      <td>0.622500</td>\n",
              "      <td>0.331199</td>\n",
              "      <td>0.703231</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 323, total number of training (for each informative and uninform class) and test samples: 200, 7000 0.025 XLNet-L 323 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-large-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:56, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.746800</td>\n",
              "      <td>0.774791</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.508628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.720900</td>\n",
              "      <td>0.693654</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.444044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.714800</td>\n",
              "      <td>0.703479</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.443563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.735200</td>\n",
              "      <td>0.694008</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.442459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.710100</td>\n",
              "      <td>0.699188</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.456156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.689800</td>\n",
              "      <td>0.709905</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.442738</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 1694, total number of training (for each informative and uninform class) and test samples: 200, 7000 0.025 XLNet-L 1694 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-large-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:56, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.750500</td>\n",
              "      <td>0.668141</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.546828</td>\n",
              "      <td>0.613499</td>\n",
              "      <td>0.690840</td>\n",
              "      <td>0.452500</td>\n",
              "      <td>0.797500</td>\n",
              "      <td>0.266353</td>\n",
              "      <td>0.612450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.714600</td>\n",
              "      <td>0.690925</td>\n",
              "      <td>0.572500</td>\n",
              "      <td>0.674905</td>\n",
              "      <td>0.525409</td>\n",
              "      <td>0.544479</td>\n",
              "      <td>0.887500</td>\n",
              "      <td>0.257500</td>\n",
              "      <td>0.186712</td>\n",
              "      <td>0.664931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.639200</td>\n",
              "      <td>0.703007</td>\n",
              "      <td>0.535000</td>\n",
              "      <td>0.671958</td>\n",
              "      <td>0.436837</td>\n",
              "      <td>0.519074</td>\n",
              "      <td>0.952500</td>\n",
              "      <td>0.117500</td>\n",
              "      <td>0.127215</td>\n",
              "      <td>0.659969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.543600</td>\n",
              "      <td>0.660806</td>\n",
              "      <td>0.617500</td>\n",
              "      <td>0.658482</td>\n",
              "      <td>0.611912</td>\n",
              "      <td>0.594758</td>\n",
              "      <td>0.737500</td>\n",
              "      <td>0.497500</td>\n",
              "      <td>0.242075</td>\n",
              "      <td>0.632581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.572100</td>\n",
              "      <td>0.760307</td>\n",
              "      <td>0.581250</td>\n",
              "      <td>0.681256</td>\n",
              "      <td>0.535528</td>\n",
              "      <td>0.549923</td>\n",
              "      <td>0.895000</td>\n",
              "      <td>0.267500</td>\n",
              "      <td>0.208703</td>\n",
              "      <td>0.685075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.410600</td>\n",
              "      <td>0.728171</td>\n",
              "      <td>0.602500</td>\n",
              "      <td>0.676171</td>\n",
              "      <td>0.580804</td>\n",
              "      <td>0.570447</td>\n",
              "      <td>0.830000</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.230210</td>\n",
              "      <td>0.692381</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 9741, total number of training (for each informative and uninform class) and test samples: 200, 7000 0.025 XLNet-L 9741 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-large-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:56, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.774700</td>\n",
              "      <td>0.703357</td>\n",
              "      <td>0.521250</td>\n",
              "      <td>0.139326</td>\n",
              "      <td>0.403862</td>\n",
              "      <td>0.688889</td>\n",
              "      <td>0.077500</td>\n",
              "      <td>0.965000</td>\n",
              "      <td>0.092229</td>\n",
              "      <td>0.572275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.727300</td>\n",
              "      <td>0.698195</td>\n",
              "      <td>0.518750</td>\n",
              "      <td>0.672897</td>\n",
              "      <td>0.381366</td>\n",
              "      <td>0.509653</td>\n",
              "      <td>0.990000</td>\n",
              "      <td>0.047500</td>\n",
              "      <td>0.112206</td>\n",
              "      <td>0.569575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.692400</td>\n",
              "      <td>0.803741</td>\n",
              "      <td>0.507500</td>\n",
              "      <td>0.670017</td>\n",
              "      <td>0.349787</td>\n",
              "      <td>0.503778</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.015000</td>\n",
              "      <td>0.086929</td>\n",
              "      <td>0.592825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.539200</td>\n",
              "      <td>0.644817</td>\n",
              "      <td>0.640000</td>\n",
              "      <td>0.644444</td>\n",
              "      <td>0.639944</td>\n",
              "      <td>0.636585</td>\n",
              "      <td>0.652500</td>\n",
              "      <td>0.627500</td>\n",
              "      <td>0.280088</td>\n",
              "      <td>0.680131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.511700</td>\n",
              "      <td>0.738429</td>\n",
              "      <td>0.648750</td>\n",
              "      <td>0.711202</td>\n",
              "      <td>0.631518</td>\n",
              "      <td>0.603839</td>\n",
              "      <td>0.865000</td>\n",
              "      <td>0.432500</td>\n",
              "      <td>0.329957</td>\n",
              "      <td>0.727438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.354000</td>\n",
              "      <td>0.741718</td>\n",
              "      <td>0.635000</td>\n",
              "      <td>0.697095</td>\n",
              "      <td>0.618988</td>\n",
              "      <td>0.595745</td>\n",
              "      <td>0.840000</td>\n",
              "      <td>0.430000</td>\n",
              "      <td>0.296025</td>\n",
              "      <td>0.720300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 200, total number of training (for each informative and uninform class) and test samples: 200, 7000 0.025 XLNet-L 200 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-large-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:56, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.681900</td>\n",
              "      <td>0.692328</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.585025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.761000</td>\n",
              "      <td>0.682710</td>\n",
              "      <td>0.573750</td>\n",
              "      <td>0.459588</td>\n",
              "      <td>0.553839</td>\n",
              "      <td>0.627706</td>\n",
              "      <td>0.362500</td>\n",
              "      <td>0.785000</td>\n",
              "      <td>0.162738</td>\n",
              "      <td>0.618250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.709100</td>\n",
              "      <td>0.660620</td>\n",
              "      <td>0.606250</td>\n",
              "      <td>0.563107</td>\n",
              "      <td>0.602373</td>\n",
              "      <td>0.632399</td>\n",
              "      <td>0.507500</td>\n",
              "      <td>0.705000</td>\n",
              "      <td>0.216770</td>\n",
              "      <td>0.662744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.772900</td>\n",
              "      <td>0.750913</td>\n",
              "      <td>0.615000</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>0.611111</td>\n",
              "      <td>0.595833</td>\n",
              "      <td>0.715000</td>\n",
              "      <td>0.515000</td>\n",
              "      <td>0.234743</td>\n",
              "      <td>0.663037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.311300</td>\n",
              "      <td>1.148225</td>\n",
              "      <td>0.618750</td>\n",
              "      <td>0.510433</td>\n",
              "      <td>0.599127</td>\n",
              "      <td>0.713004</td>\n",
              "      <td>0.397500</td>\n",
              "      <td>0.840000</td>\n",
              "      <td>0.264840</td>\n",
              "      <td>0.707031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.295700</td>\n",
              "      <td>1.565016</td>\n",
              "      <td>0.637500</td>\n",
              "      <td>0.620419</td>\n",
              "      <td>0.636764</td>\n",
              "      <td>0.651099</td>\n",
              "      <td>0.592500</td>\n",
              "      <td>0.682500</td>\n",
              "      <td>0.276121</td>\n",
              "      <td>0.686250</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 999, total number of training (for each informative and uninform class) and test samples: 200, 7000 0.025 XLNet-L 999 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-large-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:56, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.716300</td>\n",
              "      <td>0.686767</td>\n",
              "      <td>0.550000</td>\n",
              "      <td>0.557740</td>\n",
              "      <td>0.549862</td>\n",
              "      <td>0.548309</td>\n",
              "      <td>0.567500</td>\n",
              "      <td>0.532500</td>\n",
              "      <td>0.100061</td>\n",
              "      <td>0.550937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.735200</td>\n",
              "      <td>0.696938</td>\n",
              "      <td>0.521250</td>\n",
              "      <td>0.467316</td>\n",
              "      <td>0.516291</td>\n",
              "      <td>0.526646</td>\n",
              "      <td>0.420000</td>\n",
              "      <td>0.622500</td>\n",
              "      <td>0.043399</td>\n",
              "      <td>0.487450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.682500</td>\n",
              "      <td>0.740691</td>\n",
              "      <td>0.508750</td>\n",
              "      <td>0.668354</td>\n",
              "      <td>0.360683</td>\n",
              "      <td>0.504459</td>\n",
              "      <td>0.990000</td>\n",
              "      <td>0.027500</td>\n",
              "      <td>0.064509</td>\n",
              "      <td>0.638950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.600300</td>\n",
              "      <td>0.675724</td>\n",
              "      <td>0.590000</td>\n",
              "      <td>0.623853</td>\n",
              "      <td>0.586652</td>\n",
              "      <td>0.576271</td>\n",
              "      <td>0.680000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.182989</td>\n",
              "      <td>0.642500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.481500</td>\n",
              "      <td>0.671289</td>\n",
              "      <td>0.623750</td>\n",
              "      <td>0.570613</td>\n",
              "      <td>0.617898</td>\n",
              "      <td>0.664452</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.747500</td>\n",
              "      <td>0.255448</td>\n",
              "      <td>0.676219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.371300</td>\n",
              "      <td>0.766293</td>\n",
              "      <td>0.617500</td>\n",
              "      <td>0.658482</td>\n",
              "      <td>0.611912</td>\n",
              "      <td>0.594758</td>\n",
              "      <td>0.737500</td>\n",
              "      <td>0.497500</td>\n",
              "      <td>0.242075</td>\n",
              "      <td>0.670856</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 94, total number of training (for each informative and uninform class) and test samples: 200, 7000 0.025 DEBERT-B 94 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:34, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.650500</td>\n",
              "      <td>0.650411</td>\n",
              "      <td>0.661250</td>\n",
              "      <td>0.634278</td>\n",
              "      <td>0.659397</td>\n",
              "      <td>0.689150</td>\n",
              "      <td>0.587500</td>\n",
              "      <td>0.735000</td>\n",
              "      <td>0.326066</td>\n",
              "      <td>0.700650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.537300</td>\n",
              "      <td>0.623322</td>\n",
              "      <td>0.655000</td>\n",
              "      <td>0.710692</td>\n",
              "      <td>0.641724</td>\n",
              "      <td>0.611913</td>\n",
              "      <td>0.847500</td>\n",
              "      <td>0.462500</td>\n",
              "      <td>0.335892</td>\n",
              "      <td>0.748469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.274500</td>\n",
              "      <td>0.956109</td>\n",
              "      <td>0.692500</td>\n",
              "      <td>0.667568</td>\n",
              "      <td>0.690761</td>\n",
              "      <td>0.726471</td>\n",
              "      <td>0.617500</td>\n",
              "      <td>0.767500</td>\n",
              "      <td>0.389406</td>\n",
              "      <td>0.732662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.077700</td>\n",
              "      <td>1.621733</td>\n",
              "      <td>0.675000</td>\n",
              "      <td>0.701835</td>\n",
              "      <td>0.672346</td>\n",
              "      <td>0.648305</td>\n",
              "      <td>0.765000</td>\n",
              "      <td>0.585000</td>\n",
              "      <td>0.355812</td>\n",
              "      <td>0.724581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.002900</td>\n",
              "      <td>1.819179</td>\n",
              "      <td>0.675000</td>\n",
              "      <td>0.682927</td>\n",
              "      <td>0.674797</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>0.350438</td>\n",
              "      <td>0.720919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.001700</td>\n",
              "      <td>1.851291</td>\n",
              "      <td>0.668750</td>\n",
              "      <td>0.671623</td>\n",
              "      <td>0.668725</td>\n",
              "      <td>0.665848</td>\n",
              "      <td>0.677500</td>\n",
              "      <td>0.660000</td>\n",
              "      <td>0.337552</td>\n",
              "      <td>0.722031</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 791, total number of training (for each informative and uninform class) and test samples: 200, 7000 0.025 DEBERT-B 791 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:34, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.641600</td>\n",
              "      <td>0.640272</td>\n",
              "      <td>0.626250</td>\n",
              "      <td>0.699497</td>\n",
              "      <td>0.602641</td>\n",
              "      <td>0.584874</td>\n",
              "      <td>0.870000</td>\n",
              "      <td>0.382500</td>\n",
              "      <td>0.289192</td>\n",
              "      <td>0.711769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.611200</td>\n",
              "      <td>0.716108</td>\n",
              "      <td>0.618750</td>\n",
              "      <td>0.698318</td>\n",
              "      <td>0.590246</td>\n",
              "      <td>0.577741</td>\n",
              "      <td>0.882500</td>\n",
              "      <td>0.355000</td>\n",
              "      <td>0.279558</td>\n",
              "      <td>0.729169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.179100</td>\n",
              "      <td>1.230520</td>\n",
              "      <td>0.630000</td>\n",
              "      <td>0.580737</td>\n",
              "      <td>0.624820</td>\n",
              "      <td>0.669935</td>\n",
              "      <td>0.512500</td>\n",
              "      <td>0.747500</td>\n",
              "      <td>0.267491</td>\n",
              "      <td>0.695944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.145300</td>\n",
              "      <td>1.855749</td>\n",
              "      <td>0.646250</td>\n",
              "      <td>0.668230</td>\n",
              "      <td>0.644691</td>\n",
              "      <td>0.629139</td>\n",
              "      <td>0.712500</td>\n",
              "      <td>0.580000</td>\n",
              "      <td>0.295102</td>\n",
              "      <td>0.713356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.007900</td>\n",
              "      <td>1.991041</td>\n",
              "      <td>0.636250</td>\n",
              "      <td>0.632111</td>\n",
              "      <td>0.636204</td>\n",
              "      <td>0.639386</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.647500</td>\n",
              "      <td>0.272569</td>\n",
              "      <td>0.703694</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.002200</td>\n",
              "      <td>2.008166</td>\n",
              "      <td>0.640000</td>\n",
              "      <td>0.643564</td>\n",
              "      <td>0.639964</td>\n",
              "      <td>0.637255</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>0.630000</td>\n",
              "      <td>0.280056</td>\n",
              "      <td>0.708281</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 5, total number of training (for each informative and uninform class) and test samples: 200, 7000 0.025 DEBERT-B 5 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:34, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.693100</td>\n",
              "      <td>0.693822</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.681450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.764700</td>\n",
              "      <td>0.675350</td>\n",
              "      <td>0.646250</td>\n",
              "      <td>0.699894</td>\n",
              "      <td>0.634574</td>\n",
              "      <td>0.607735</td>\n",
              "      <td>0.825000</td>\n",
              "      <td>0.467500</td>\n",
              "      <td>0.313198</td>\n",
              "      <td>0.717006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.568500</td>\n",
              "      <td>0.969419</td>\n",
              "      <td>0.660000</td>\n",
              "      <td>0.680000</td>\n",
              "      <td>0.658667</td>\n",
              "      <td>0.642222</td>\n",
              "      <td>0.722500</td>\n",
              "      <td>0.597500</td>\n",
              "      <td>0.322530</td>\n",
              "      <td>0.715369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.023800</td>\n",
              "      <td>1.612703</td>\n",
              "      <td>0.643750</td>\n",
              "      <td>0.698413</td>\n",
              "      <td>0.631649</td>\n",
              "      <td>0.605505</td>\n",
              "      <td>0.825000</td>\n",
              "      <td>0.462500</td>\n",
              "      <td>0.308482</td>\n",
              "      <td>0.711606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.276200</td>\n",
              "      <td>1.792676</td>\n",
              "      <td>0.640000</td>\n",
              "      <td>0.704312</td>\n",
              "      <td>0.622124</td>\n",
              "      <td>0.597561</td>\n",
              "      <td>0.857500</td>\n",
              "      <td>0.422500</td>\n",
              "      <td>0.310962</td>\n",
              "      <td>0.712125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.337600</td>\n",
              "      <td>1.782675</td>\n",
              "      <td>0.653750</td>\n",
              "      <td>0.705005</td>\n",
              "      <td>0.642972</td>\n",
              "      <td>0.614100</td>\n",
              "      <td>0.827500</td>\n",
              "      <td>0.480000</td>\n",
              "      <td>0.327937</td>\n",
              "      <td>0.712006</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 6932, total number of training (for each informative and uninform class) and test samples: 200, 7000 0.025 DEBERT-B 6932 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:34, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.689100</td>\n",
              "      <td>0.655666</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.659864</td>\n",
              "      <td>0.621018</td>\n",
              "      <td>0.603734</td>\n",
              "      <td>0.727500</td>\n",
              "      <td>0.522500</td>\n",
              "      <td>0.255425</td>\n",
              "      <td>0.699063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.479800</td>\n",
              "      <td>0.814340</td>\n",
              "      <td>0.608750</td>\n",
              "      <td>0.692232</td>\n",
              "      <td>0.577677</td>\n",
              "      <td>0.570502</td>\n",
              "      <td>0.880000</td>\n",
              "      <td>0.337500</td>\n",
              "      <td>0.258911</td>\n",
              "      <td>0.718944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.380900</td>\n",
              "      <td>1.483018</td>\n",
              "      <td>0.636250</td>\n",
              "      <td>0.686760</td>\n",
              "      <td>0.626539</td>\n",
              "      <td>0.603025</td>\n",
              "      <td>0.797500</td>\n",
              "      <td>0.475000</td>\n",
              "      <td>0.287882</td>\n",
              "      <td>0.728481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.193700</td>\n",
              "      <td>1.924725</td>\n",
              "      <td>0.647500</td>\n",
              "      <td>0.520408</td>\n",
              "      <td>0.620876</td>\n",
              "      <td>0.813830</td>\n",
              "      <td>0.382500</td>\n",
              "      <td>0.912500</td>\n",
              "      <td>0.347878</td>\n",
              "      <td>0.708019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.229700</td>\n",
              "      <td>1.750561</td>\n",
              "      <td>0.670000</td>\n",
              "      <td>0.631285</td>\n",
              "      <td>0.666321</td>\n",
              "      <td>0.715190</td>\n",
              "      <td>0.565000</td>\n",
              "      <td>0.775000</td>\n",
              "      <td>0.347754</td>\n",
              "      <td>0.727656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.002700</td>\n",
              "      <td>1.808084</td>\n",
              "      <td>0.662500</td>\n",
              "      <td>0.667488</td>\n",
              "      <td>0.662424</td>\n",
              "      <td>0.657767</td>\n",
              "      <td>0.677500</td>\n",
              "      <td>0.647500</td>\n",
              "      <td>0.325146</td>\n",
              "      <td>0.725637</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 1759, total number of training (for each informative and uninform class) and test samples: 200, 7000 0.025 DEBERT-B 1759 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:34, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.691400</td>\n",
              "      <td>0.675258</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.707944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.711900</td>\n",
              "      <td>0.644708</td>\n",
              "      <td>0.690000</td>\n",
              "      <td>0.689223</td>\n",
              "      <td>0.689998</td>\n",
              "      <td>0.690955</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>0.692500</td>\n",
              "      <td>0.380005</td>\n",
              "      <td>0.746269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.541200</td>\n",
              "      <td>1.675772</td>\n",
              "      <td>0.547500</td>\n",
              "      <td>0.177273</td>\n",
              "      <td>0.432602</td>\n",
              "      <td>0.975000</td>\n",
              "      <td>0.097500</td>\n",
              "      <td>0.997500</td>\n",
              "      <td>0.217945</td>\n",
              "      <td>0.698531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.307100</td>\n",
              "      <td>1.137628</td>\n",
              "      <td>0.705000</td>\n",
              "      <td>0.731207</td>\n",
              "      <td>0.702169</td>\n",
              "      <td>0.671548</td>\n",
              "      <td>0.802500</td>\n",
              "      <td>0.607500</td>\n",
              "      <td>0.418025</td>\n",
              "      <td>0.776425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.134600</td>\n",
              "      <td>1.297882</td>\n",
              "      <td>0.698750</td>\n",
              "      <td>0.724571</td>\n",
              "      <td>0.696079</td>\n",
              "      <td>0.667368</td>\n",
              "      <td>0.792500</td>\n",
              "      <td>0.605000</td>\n",
              "      <td>0.404677</td>\n",
              "      <td>0.784825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.124900</td>\n",
              "      <td>1.358456</td>\n",
              "      <td>0.701250</td>\n",
              "      <td>0.731159</td>\n",
              "      <td>0.697506</td>\n",
              "      <td>0.664622</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.590000</td>\n",
              "      <td>0.412849</td>\n",
              "      <td>0.786006</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 323, total number of training (for each informative and uninform class) and test samples: 200, 7000 0.025 DEBERT-B 323 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:34, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.694200</td>\n",
              "      <td>0.692037</td>\n",
              "      <td>0.618750</td>\n",
              "      <td>0.559885</td>\n",
              "      <td>0.611806</td>\n",
              "      <td>0.662116</td>\n",
              "      <td>0.485000</td>\n",
              "      <td>0.752500</td>\n",
              "      <td>0.246482</td>\n",
              "      <td>0.696247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.696700</td>\n",
              "      <td>0.664424</td>\n",
              "      <td>0.636250</td>\n",
              "      <td>0.540284</td>\n",
              "      <td>0.619677</td>\n",
              "      <td>0.733906</td>\n",
              "      <td>0.427500</td>\n",
              "      <td>0.845000</td>\n",
              "      <td>0.299887</td>\n",
              "      <td>0.636038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.538800</td>\n",
              "      <td>0.705666</td>\n",
              "      <td>0.653750</td>\n",
              "      <td>0.691193</td>\n",
              "      <td>0.648584</td>\n",
              "      <td>0.623742</td>\n",
              "      <td>0.775000</td>\n",
              "      <td>0.532500</td>\n",
              "      <td>0.316961</td>\n",
              "      <td>0.731056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.386800</td>\n",
              "      <td>1.293218</td>\n",
              "      <td>0.662500</td>\n",
              "      <td>0.715190</td>\n",
              "      <td>0.650540</td>\n",
              "      <td>0.618613</td>\n",
              "      <td>0.847500</td>\n",
              "      <td>0.477500</td>\n",
              "      <td>0.349827</td>\n",
              "      <td>0.741237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.265700</td>\n",
              "      <td>1.578512</td>\n",
              "      <td>0.675000</td>\n",
              "      <td>0.680590</td>\n",
              "      <td>0.674900</td>\n",
              "      <td>0.669082</td>\n",
              "      <td>0.692500</td>\n",
              "      <td>0.657500</td>\n",
              "      <td>0.350215</td>\n",
              "      <td>0.735694</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.134900</td>\n",
              "      <td>1.690853</td>\n",
              "      <td>0.665000</td>\n",
              "      <td>0.661616</td>\n",
              "      <td>0.664966</td>\n",
              "      <td>0.668367</td>\n",
              "      <td>0.655000</td>\n",
              "      <td>0.675000</td>\n",
              "      <td>0.330066</td>\n",
              "      <td>0.728900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 1694, total number of training (for each informative and uninform class) and test samples: 200, 7000 0.025 DEBERT-B 1694 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:34, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.700300</td>\n",
              "      <td>0.694821</td>\n",
              "      <td>0.501250</td>\n",
              "      <td>0.667223</td>\n",
              "      <td>0.336105</td>\n",
              "      <td>0.500626</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.002500</td>\n",
              "      <td>0.035377</td>\n",
              "      <td>0.513994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.669600</td>\n",
              "      <td>0.693140</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.630631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.697600</td>\n",
              "      <td>0.692243</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.709975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.712500</td>\n",
              "      <td>0.670080</td>\n",
              "      <td>0.668750</td>\n",
              "      <td>0.649934</td>\n",
              "      <td>0.667790</td>\n",
              "      <td>0.689076</td>\n",
              "      <td>0.615000</td>\n",
              "      <td>0.722500</td>\n",
              "      <td>0.339467</td>\n",
              "      <td>0.698688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.550700</td>\n",
              "      <td>0.709513</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>0.569231</td>\n",
              "      <td>0.637247</td>\n",
              "      <td>0.740000</td>\n",
              "      <td>0.462500</td>\n",
              "      <td>0.837500</td>\n",
              "      <td>0.323616</td>\n",
              "      <td>0.729981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.504700</td>\n",
              "      <td>0.695970</td>\n",
              "      <td>0.680000</td>\n",
              "      <td>0.693780</td>\n",
              "      <td>0.679351</td>\n",
              "      <td>0.665138</td>\n",
              "      <td>0.725000</td>\n",
              "      <td>0.635000</td>\n",
              "      <td>0.361467</td>\n",
              "      <td>0.721069</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 9741, total number of training (for each informative and uninform class) and test samples: 200, 7000 0.025 DEBERT-B 9741 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:34, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.700500</td>\n",
              "      <td>0.693614</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.568409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.675200</td>\n",
              "      <td>0.793106</td>\n",
              "      <td>0.501250</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.338296</td>\n",
              "      <td>0.500627</td>\n",
              "      <td>0.997500</td>\n",
              "      <td>0.005000</td>\n",
              "      <td>0.020451</td>\n",
              "      <td>0.606625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.578400</td>\n",
              "      <td>0.619386</td>\n",
              "      <td>0.658750</td>\n",
              "      <td>0.643137</td>\n",
              "      <td>0.658096</td>\n",
              "      <td>0.673973</td>\n",
              "      <td>0.615000</td>\n",
              "      <td>0.702500</td>\n",
              "      <td>0.318722</td>\n",
              "      <td>0.723369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.208400</td>\n",
              "      <td>0.801985</td>\n",
              "      <td>0.703750</td>\n",
              "      <td>0.707046</td>\n",
              "      <td>0.703713</td>\n",
              "      <td>0.699267</td>\n",
              "      <td>0.715000</td>\n",
              "      <td>0.692500</td>\n",
              "      <td>0.407603</td>\n",
              "      <td>0.752100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.106700</td>\n",
              "      <td>1.301257</td>\n",
              "      <td>0.701250</td>\n",
              "      <td>0.700876</td>\n",
              "      <td>0.701250</td>\n",
              "      <td>0.701754</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.702500</td>\n",
              "      <td>0.402501</td>\n",
              "      <td>0.749725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.097200</td>\n",
              "      <td>1.416816</td>\n",
              "      <td>0.691250</td>\n",
              "      <td>0.712456</td>\n",
              "      <td>0.689562</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.765000</td>\n",
              "      <td>0.617500</td>\n",
              "      <td>0.386730</td>\n",
              "      <td>0.752594</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 200, total number of training (for each informative and uninform class) and test samples: 200, 7000 0.025 DEBERT-B 200 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:34, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.709400</td>\n",
              "      <td>0.695419</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.606169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.650900</td>\n",
              "      <td>0.725811</td>\n",
              "      <td>0.627500</td>\n",
              "      <td>0.697154</td>\n",
              "      <td>0.606694</td>\n",
              "      <td>0.587329</td>\n",
              "      <td>0.857500</td>\n",
              "      <td>0.397500</td>\n",
              "      <td>0.287188</td>\n",
              "      <td>0.706631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.619200</td>\n",
              "      <td>0.886195</td>\n",
              "      <td>0.636250</td>\n",
              "      <td>0.648126</td>\n",
              "      <td>0.635835</td>\n",
              "      <td>0.627635</td>\n",
              "      <td>0.670000</td>\n",
              "      <td>0.602500</td>\n",
              "      <td>0.273123</td>\n",
              "      <td>0.699588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.552000</td>\n",
              "      <td>1.095274</td>\n",
              "      <td>0.651250</td>\n",
              "      <td>0.687570</td>\n",
              "      <td>0.646472</td>\n",
              "      <td>0.622718</td>\n",
              "      <td>0.767500</td>\n",
              "      <td>0.535000</td>\n",
              "      <td>0.311023</td>\n",
              "      <td>0.725544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.263200</td>\n",
              "      <td>1.583933</td>\n",
              "      <td>0.666250</td>\n",
              "      <td>0.705623</td>\n",
              "      <td>0.660171</td>\n",
              "      <td>0.631164</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.532500</td>\n",
              "      <td>0.345075</td>\n",
              "      <td>0.723381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.112200</td>\n",
              "      <td>1.669183</td>\n",
              "      <td>0.662500</td>\n",
              "      <td>0.707158</td>\n",
              "      <td>0.654464</td>\n",
              "      <td>0.624521</td>\n",
              "      <td>0.815000</td>\n",
              "      <td>0.510000</td>\n",
              "      <td>0.341260</td>\n",
              "      <td>0.727663</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 999, total number of training (for each informative and uninform class) and test samples: 200, 7000 0.025 DEBERT-B 999 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:35, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.665200</td>\n",
              "      <td>0.830911</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.658319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.622400</td>\n",
              "      <td>0.791423</td>\n",
              "      <td>0.606250</td>\n",
              "      <td>0.470588</td>\n",
              "      <td>0.578578</td>\n",
              "      <td>0.717949</td>\n",
              "      <td>0.350000</td>\n",
              "      <td>0.862500</td>\n",
              "      <td>0.247471</td>\n",
              "      <td>0.706300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.438900</td>\n",
              "      <td>1.285354</td>\n",
              "      <td>0.651250</td>\n",
              "      <td>0.620408</td>\n",
              "      <td>0.648932</td>\n",
              "      <td>0.680597</td>\n",
              "      <td>0.570000</td>\n",
              "      <td>0.732500</td>\n",
              "      <td>0.306575</td>\n",
              "      <td>0.718294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.130900</td>\n",
              "      <td>1.603811</td>\n",
              "      <td>0.680000</td>\n",
              "      <td>0.695238</td>\n",
              "      <td>0.679198</td>\n",
              "      <td>0.663636</td>\n",
              "      <td>0.730000</td>\n",
              "      <td>0.630000</td>\n",
              "      <td>0.361814</td>\n",
              "      <td>0.740537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.001800</td>\n",
              "      <td>1.687209</td>\n",
              "      <td>0.691250</td>\n",
              "      <td>0.706302</td>\n",
              "      <td>0.690437</td>\n",
              "      <td>0.673469</td>\n",
              "      <td>0.742500</td>\n",
              "      <td>0.640000</td>\n",
              "      <td>0.384525</td>\n",
              "      <td>0.745613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.001300</td>\n",
              "      <td>1.741937</td>\n",
              "      <td>0.681250</td>\n",
              "      <td>0.698225</td>\n",
              "      <td>0.680238</td>\n",
              "      <td>0.662921</td>\n",
              "      <td>0.737500</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.364816</td>\n",
              "      <td>0.745812</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 94, total number of training (for each informative and uninform class) and test samples: 80, 7120 0.01 ALBERT-L 94 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 00:16, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.727900</td>\n",
              "      <td>0.689865</td>\n",
              "      <td>0.523750</td>\n",
              "      <td>0.566553</td>\n",
              "      <td>0.519060</td>\n",
              "      <td>0.519833</td>\n",
              "      <td>0.622500</td>\n",
              "      <td>0.425000</td>\n",
              "      <td>0.048454</td>\n",
              "      <td>0.536744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.510800</td>\n",
              "      <td>0.674669</td>\n",
              "      <td>0.608750</td>\n",
              "      <td>0.644722</td>\n",
              "      <td>0.604698</td>\n",
              "      <td>0.590437</td>\n",
              "      <td>0.710000</td>\n",
              "      <td>0.507500</td>\n",
              "      <td>0.222101</td>\n",
              "      <td>0.665431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.186800</td>\n",
              "      <td>0.982278</td>\n",
              "      <td>0.615000</td>\n",
              "      <td>0.635071</td>\n",
              "      <td>0.613832</td>\n",
              "      <td>0.603604</td>\n",
              "      <td>0.670000</td>\n",
              "      <td>0.560000</td>\n",
              "      <td>0.231404</td>\n",
              "      <td>0.675450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.192400</td>\n",
              "      <td>1.298274</td>\n",
              "      <td>0.621250</td>\n",
              "      <td>0.653714</td>\n",
              "      <td>0.617892</td>\n",
              "      <td>0.602105</td>\n",
              "      <td>0.715000</td>\n",
              "      <td>0.527500</td>\n",
              "      <td>0.246878</td>\n",
              "      <td>0.682050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.015500</td>\n",
              "      <td>1.502687</td>\n",
              "      <td>0.623750</td>\n",
              "      <td>0.661417</td>\n",
              "      <td>0.619035</td>\n",
              "      <td>0.601227</td>\n",
              "      <td>0.735000</td>\n",
              "      <td>0.512500</td>\n",
              "      <td>0.253864</td>\n",
              "      <td>0.687444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.088100</td>\n",
              "      <td>1.543117</td>\n",
              "      <td>0.627500</td>\n",
              "      <td>0.667411</td>\n",
              "      <td>0.622058</td>\n",
              "      <td>0.602823</td>\n",
              "      <td>0.747500</td>\n",
              "      <td>0.507500</td>\n",
              "      <td>0.262677</td>\n",
              "      <td>0.685637</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 791, total number of training (for each informative and uninform class) and test samples: 80, 7120 0.01 ALBERT-L 791 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 00:16, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.716500</td>\n",
              "      <td>0.679645</td>\n",
              "      <td>0.541250</td>\n",
              "      <td>0.676081</td>\n",
              "      <td>0.445107</td>\n",
              "      <td>0.522510</td>\n",
              "      <td>0.957500</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.148910</td>\n",
              "      <td>0.646925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.659800</td>\n",
              "      <td>0.682052</td>\n",
              "      <td>0.552500</td>\n",
              "      <td>0.231760</td>\n",
              "      <td>0.458032</td>\n",
              "      <td>0.818182</td>\n",
              "      <td>0.135000</td>\n",
              "      <td>0.970000</td>\n",
              "      <td>0.190822</td>\n",
              "      <td>0.705712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.381700</td>\n",
              "      <td>0.680971</td>\n",
              "      <td>0.666250</td>\n",
              "      <td>0.708197</td>\n",
              "      <td>0.659208</td>\n",
              "      <td>0.629126</td>\n",
              "      <td>0.810000</td>\n",
              "      <td>0.522500</td>\n",
              "      <td>0.347157</td>\n",
              "      <td>0.695850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.222700</td>\n",
              "      <td>0.824705</td>\n",
              "      <td>0.642500</td>\n",
              "      <td>0.526490</td>\n",
              "      <td>0.619671</td>\n",
              "      <td>0.779412</td>\n",
              "      <td>0.397500</td>\n",
              "      <td>0.887500</td>\n",
              "      <td>0.326939</td>\n",
              "      <td>0.723500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.133800</td>\n",
              "      <td>0.950259</td>\n",
              "      <td>0.652500</td>\n",
              "      <td>0.599424</td>\n",
              "      <td>0.646290</td>\n",
              "      <td>0.707483</td>\n",
              "      <td>0.520000</td>\n",
              "      <td>0.785000</td>\n",
              "      <td>0.316309</td>\n",
              "      <td>0.723525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.032600</td>\n",
              "      <td>1.077675</td>\n",
              "      <td>0.657500</td>\n",
              "      <td>0.586103</td>\n",
              "      <td>0.646996</td>\n",
              "      <td>0.740458</td>\n",
              "      <td>0.485000</td>\n",
              "      <td>0.830000</td>\n",
              "      <td>0.335605</td>\n",
              "      <td>0.720691</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 5, total number of training (for each informative and uninform class) and test samples: 80, 7120 0.01 ALBERT-L 5 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 00:16, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.688500</td>\n",
              "      <td>0.662495</td>\n",
              "      <td>0.585000</td>\n",
              "      <td>0.645299</td>\n",
              "      <td>0.572650</td>\n",
              "      <td>0.563433</td>\n",
              "      <td>0.755000</td>\n",
              "      <td>0.415000</td>\n",
              "      <td>0.180769</td>\n",
              "      <td>0.664413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.627300</td>\n",
              "      <td>0.903331</td>\n",
              "      <td>0.532500</td>\n",
              "      <td>0.673077</td>\n",
              "      <td>0.426451</td>\n",
              "      <td>0.517473</td>\n",
              "      <td>0.962500</td>\n",
              "      <td>0.102500</td>\n",
              "      <td>0.127378</td>\n",
              "      <td>0.675319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.275800</td>\n",
              "      <td>0.749523</td>\n",
              "      <td>0.635000</td>\n",
              "      <td>0.681223</td>\n",
              "      <td>0.627161</td>\n",
              "      <td>0.604651</td>\n",
              "      <td>0.780000</td>\n",
              "      <td>0.490000</td>\n",
              "      <td>0.282124</td>\n",
              "      <td>0.687137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.120700</td>\n",
              "      <td>0.956530</td>\n",
              "      <td>0.636250</td>\n",
              "      <td>0.653159</td>\n",
              "      <td>0.635383</td>\n",
              "      <td>0.624146</td>\n",
              "      <td>0.685000</td>\n",
              "      <td>0.587500</td>\n",
              "      <td>0.273805</td>\n",
              "      <td>0.672862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.025200</td>\n",
              "      <td>1.200050</td>\n",
              "      <td>0.642500</td>\n",
              "      <td>0.645161</td>\n",
              "      <td>0.642480</td>\n",
              "      <td>0.640394</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>0.635000</td>\n",
              "      <td>0.285032</td>\n",
              "      <td>0.664669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.012800</td>\n",
              "      <td>1.267151</td>\n",
              "      <td>0.641250</td>\n",
              "      <td>0.650426</td>\n",
              "      <td>0.641003</td>\n",
              "      <td>0.634204</td>\n",
              "      <td>0.667500</td>\n",
              "      <td>0.615000</td>\n",
              "      <td>0.282890</td>\n",
              "      <td>0.669931</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 6932, total number of training (for each informative and uninform class) and test samples: 80, 7120 0.01 ALBERT-L 6932 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 00:16, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.759500</td>\n",
              "      <td>0.692812</td>\n",
              "      <td>0.536250</td>\n",
              "      <td>0.535670</td>\n",
              "      <td>0.536249</td>\n",
              "      <td>0.536341</td>\n",
              "      <td>0.535000</td>\n",
              "      <td>0.537500</td>\n",
              "      <td>0.072500</td>\n",
              "      <td>0.538212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.756100</td>\n",
              "      <td>0.765845</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.488403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.668600</td>\n",
              "      <td>0.750844</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.504519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.762400</td>\n",
              "      <td>0.701315</td>\n",
              "      <td>0.496250</td>\n",
              "      <td>0.645558</td>\n",
              "      <td>0.387574</td>\n",
              "      <td>0.497965</td>\n",
              "      <td>0.917500</td>\n",
              "      <td>0.075000</td>\n",
              "      <td>-0.013923</td>\n",
              "      <td>0.513506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.699600</td>\n",
              "      <td>0.697115</td>\n",
              "      <td>0.501250</td>\n",
              "      <td>0.613746</td>\n",
              "      <td>0.455021</td>\n",
              "      <td>0.500790</td>\n",
              "      <td>0.792500</td>\n",
              "      <td>0.210000</td>\n",
              "      <td>0.003076</td>\n",
              "      <td>0.521763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.651000</td>\n",
              "      <td>0.695410</td>\n",
              "      <td>0.516250</td>\n",
              "      <td>0.642659</td>\n",
              "      <td>0.447055</td>\n",
              "      <td>0.509517</td>\n",
              "      <td>0.870000</td>\n",
              "      <td>0.162500</td>\n",
              "      <td>0.045988</td>\n",
              "      <td>0.525238</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 1759, total number of training (for each informative and uninform class) and test samples: 80, 7120 0.01 ALBERT-L 1759 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 00:16, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.726300</td>\n",
              "      <td>0.685008</td>\n",
              "      <td>0.568750</td>\n",
              "      <td>0.491900</td>\n",
              "      <td>0.558654</td>\n",
              "      <td>0.598566</td>\n",
              "      <td>0.417500</td>\n",
              "      <td>0.720000</td>\n",
              "      <td>0.144259</td>\n",
              "      <td>0.602506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.733600</td>\n",
              "      <td>0.680326</td>\n",
              "      <td>0.577500</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.567100</td>\n",
              "      <td>0.612319</td>\n",
              "      <td>0.422500</td>\n",
              "      <td>0.732500</td>\n",
              "      <td>0.163031</td>\n",
              "      <td>0.615587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.733400</td>\n",
              "      <td>0.699638</td>\n",
              "      <td>0.465000</td>\n",
              "      <td>0.484337</td>\n",
              "      <td>0.464247</td>\n",
              "      <td>0.467442</td>\n",
              "      <td>0.502500</td>\n",
              "      <td>0.427500</td>\n",
              "      <td>-0.070198</td>\n",
              "      <td>0.524781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.677900</td>\n",
              "      <td>0.680125</td>\n",
              "      <td>0.567500</td>\n",
              "      <td>0.649798</td>\n",
              "      <td>0.542219</td>\n",
              "      <td>0.545918</td>\n",
              "      <td>0.802500</td>\n",
              "      <td>0.332500</td>\n",
              "      <td>0.152946</td>\n",
              "      <td>0.657819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.647500</td>\n",
              "      <td>0.661593</td>\n",
              "      <td>0.627500</td>\n",
              "      <td>0.575499</td>\n",
              "      <td>0.621825</td>\n",
              "      <td>0.668874</td>\n",
              "      <td>0.505000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.263016</td>\n",
              "      <td>0.672094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.561100</td>\n",
              "      <td>0.661163</td>\n",
              "      <td>0.595000</td>\n",
              "      <td>0.663900</td>\n",
              "      <td>0.577233</td>\n",
              "      <td>0.567376</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.390000</td>\n",
              "      <td>0.208314</td>\n",
              "      <td>0.671494</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 323, total number of training (for each informative and uninform class) and test samples: 80, 7120 0.01 ALBERT-L 323 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 00:16, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.769800</td>\n",
              "      <td>0.764554</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.511125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.726300</td>\n",
              "      <td>0.753550</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.440100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.807100</td>\n",
              "      <td>0.764421</td>\n",
              "      <td>0.501250</td>\n",
              "      <td>0.019656</td>\n",
              "      <td>0.342603</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.010000</td>\n",
              "      <td>0.992500</td>\n",
              "      <td>0.013422</td>\n",
              "      <td>0.530356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.758200</td>\n",
              "      <td>0.740775</td>\n",
              "      <td>0.498750</td>\n",
              "      <td>0.038369</td>\n",
              "      <td>0.349700</td>\n",
              "      <td>0.470588</td>\n",
              "      <td>0.020000</td>\n",
              "      <td>0.977500</td>\n",
              "      <td>-0.008668</td>\n",
              "      <td>0.532219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.773900</td>\n",
              "      <td>0.814917</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.487094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.745100</td>\n",
              "      <td>0.752133</td>\n",
              "      <td>0.502500</td>\n",
              "      <td>0.009950</td>\n",
              "      <td>0.338865</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.005000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.050063</td>\n",
              "      <td>0.496725</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 1694, total number of training (for each informative and uninform class) and test samples: 80, 7120 0.01 ALBERT-L 1694 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 00:16, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.734900</td>\n",
              "      <td>0.683875</td>\n",
              "      <td>0.561250</td>\n",
              "      <td>0.636269</td>\n",
              "      <td>0.541757</td>\n",
              "      <td>0.543363</td>\n",
              "      <td>0.767500</td>\n",
              "      <td>0.355000</td>\n",
              "      <td>0.134474</td>\n",
              "      <td>0.555250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.571300</td>\n",
              "      <td>0.745389</td>\n",
              "      <td>0.575000</td>\n",
              "      <td>0.647303</td>\n",
              "      <td>0.556356</td>\n",
              "      <td>0.553191</td>\n",
              "      <td>0.780000</td>\n",
              "      <td>0.370000</td>\n",
              "      <td>0.164458</td>\n",
              "      <td>0.614431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.309700</td>\n",
              "      <td>0.928014</td>\n",
              "      <td>0.583750</td>\n",
              "      <td>0.648363</td>\n",
              "      <td>0.569205</td>\n",
              "      <td>0.561243</td>\n",
              "      <td>0.767500</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.180103</td>\n",
              "      <td>0.631719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.264700</td>\n",
              "      <td>1.300197</td>\n",
              "      <td>0.588750</td>\n",
              "      <td>0.677134</td>\n",
              "      <td>0.555435</td>\n",
              "      <td>0.557351</td>\n",
              "      <td>0.862500</td>\n",
              "      <td>0.315000</td>\n",
              "      <td>0.212116</td>\n",
              "      <td>0.647337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.075700</td>\n",
              "      <td>1.635307</td>\n",
              "      <td>0.585000</td>\n",
              "      <td>0.562005</td>\n",
              "      <td>0.583853</td>\n",
              "      <td>0.594972</td>\n",
              "      <td>0.532500</td>\n",
              "      <td>0.637500</td>\n",
              "      <td>0.170945</td>\n",
              "      <td>0.616350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.037200</td>\n",
              "      <td>1.805274</td>\n",
              "      <td>0.583750</td>\n",
              "      <td>0.558940</td>\n",
              "      <td>0.582429</td>\n",
              "      <td>0.594366</td>\n",
              "      <td>0.527500</td>\n",
              "      <td>0.640000</td>\n",
              "      <td>0.168570</td>\n",
              "      <td>0.611475</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 9741, total number of training (for each informative and uninform class) and test samples: 80, 7120 0.01 ALBERT-L 9741 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 00:16, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.765700</td>\n",
              "      <td>0.681549</td>\n",
              "      <td>0.540000</td>\n",
              "      <td>0.269841</td>\n",
              "      <td>0.467037</td>\n",
              "      <td>0.653846</td>\n",
              "      <td>0.170000</td>\n",
              "      <td>0.910000</td>\n",
              "      <td>0.118940</td>\n",
              "      <td>0.616925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.662700</td>\n",
              "      <td>0.689222</td>\n",
              "      <td>0.540000</td>\n",
              "      <td>0.679443</td>\n",
              "      <td>0.432642</td>\n",
              "      <td>0.521390</td>\n",
              "      <td>0.975000</td>\n",
              "      <td>0.105000</td>\n",
              "      <td>0.162255</td>\n",
              "      <td>0.611387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.580200</td>\n",
              "      <td>0.673701</td>\n",
              "      <td>0.595000</td>\n",
              "      <td>0.580311</td>\n",
              "      <td>0.594503</td>\n",
              "      <td>0.602151</td>\n",
              "      <td>0.560000</td>\n",
              "      <td>0.630000</td>\n",
              "      <td>0.190467</td>\n",
              "      <td>0.634138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.301000</td>\n",
              "      <td>0.764943</td>\n",
              "      <td>0.602500</td>\n",
              "      <td>0.626761</td>\n",
              "      <td>0.600813</td>\n",
              "      <td>0.590708</td>\n",
              "      <td>0.667500</td>\n",
              "      <td>0.537500</td>\n",
              "      <td>0.206755</td>\n",
              "      <td>0.642037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.102300</td>\n",
              "      <td>0.973526</td>\n",
              "      <td>0.602500</td>\n",
              "      <td>0.589147</td>\n",
              "      <td>0.602080</td>\n",
              "      <td>0.609626</td>\n",
              "      <td>0.570000</td>\n",
              "      <td>0.635000</td>\n",
              "      <td>0.205434</td>\n",
              "      <td>0.624350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.084600</td>\n",
              "      <td>1.085011</td>\n",
              "      <td>0.602500</td>\n",
              "      <td>0.658065</td>\n",
              "      <td>0.591719</td>\n",
              "      <td>0.577358</td>\n",
              "      <td>0.765000</td>\n",
              "      <td>0.440000</td>\n",
              "      <td>0.216767</td>\n",
              "      <td>0.628825</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 200, total number of training (for each informative and uninform class) and test samples: 80, 7120 0.01 ALBERT-L 200 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 00:16, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.729200</td>\n",
              "      <td>0.697103</td>\n",
              "      <td>0.501250</td>\n",
              "      <td>0.634280</td>\n",
              "      <td>0.425195</td>\n",
              "      <td>0.500724</td>\n",
              "      <td>0.865000</td>\n",
              "      <td>0.137500</td>\n",
              "      <td>0.003644</td>\n",
              "      <td>0.516975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.691700</td>\n",
              "      <td>0.691229</td>\n",
              "      <td>0.538750</td>\n",
              "      <td>0.648236</td>\n",
              "      <td>0.489272</td>\n",
              "      <td>0.523883</td>\n",
              "      <td>0.850000</td>\n",
              "      <td>0.227500</td>\n",
              "      <td>0.099026</td>\n",
              "      <td>0.533531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.729100</td>\n",
              "      <td>0.690096</td>\n",
              "      <td>0.538750</td>\n",
              "      <td>0.592265</td>\n",
              "      <td>0.530665</td>\n",
              "      <td>0.530693</td>\n",
              "      <td>0.670000</td>\n",
              "      <td>0.407500</td>\n",
              "      <td>0.080317</td>\n",
              "      <td>0.521287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.709000</td>\n",
              "      <td>0.694303</td>\n",
              "      <td>0.520000</td>\n",
              "      <td>0.594080</td>\n",
              "      <td>0.503462</td>\n",
              "      <td>0.514652</td>\n",
              "      <td>0.702500</td>\n",
              "      <td>0.337500</td>\n",
              "      <td>0.042964</td>\n",
              "      <td>0.495794</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.691700</td>\n",
              "      <td>0.694079</td>\n",
              "      <td>0.518750</td>\n",
              "      <td>0.580153</td>\n",
              "      <td>0.508232</td>\n",
              "      <td>0.514507</td>\n",
              "      <td>0.665000</td>\n",
              "      <td>0.372500</td>\n",
              "      <td>0.039215</td>\n",
              "      <td>0.516894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.671100</td>\n",
              "      <td>0.694565</td>\n",
              "      <td>0.522500</td>\n",
              "      <td>0.596195</td>\n",
              "      <td>0.506048</td>\n",
              "      <td>0.516484</td>\n",
              "      <td>0.705000</td>\n",
              "      <td>0.340000</td>\n",
              "      <td>0.048335</td>\n",
              "      <td>0.514444</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 999, total number of training (for each informative and uninform class) and test samples: 80, 7120 0.01 ALBERT-L 999 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 00:16, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.715900</td>\n",
              "      <td>0.677406</td>\n",
              "      <td>0.563750</td>\n",
              "      <td>0.384480</td>\n",
              "      <td>0.523314</td>\n",
              "      <td>0.652695</td>\n",
              "      <td>0.272500</td>\n",
              "      <td>0.855000</td>\n",
              "      <td>0.156859</td>\n",
              "      <td>0.631319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.615700</td>\n",
              "      <td>0.642535</td>\n",
              "      <td>0.645000</td>\n",
              "      <td>0.691304</td>\n",
              "      <td>0.636829</td>\n",
              "      <td>0.611538</td>\n",
              "      <td>0.795000</td>\n",
              "      <td>0.495000</td>\n",
              "      <td>0.304003</td>\n",
              "      <td>0.701037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.340300</td>\n",
              "      <td>0.621270</td>\n",
              "      <td>0.668750</td>\n",
              "      <td>0.668335</td>\n",
              "      <td>0.668749</td>\n",
              "      <td>0.669173</td>\n",
              "      <td>0.667500</td>\n",
              "      <td>0.670000</td>\n",
              "      <td>0.337501</td>\n",
              "      <td>0.713706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.113300</td>\n",
              "      <td>0.768244</td>\n",
              "      <td>0.666250</td>\n",
              "      <td>0.716861</td>\n",
              "      <td>0.655234</td>\n",
              "      <td>0.622468</td>\n",
              "      <td>0.845000</td>\n",
              "      <td>0.487500</td>\n",
              "      <td>0.356029</td>\n",
              "      <td>0.718956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.047600</td>\n",
              "      <td>0.887263</td>\n",
              "      <td>0.670000</td>\n",
              "      <td>0.671642</td>\n",
              "      <td>0.669992</td>\n",
              "      <td>0.668317</td>\n",
              "      <td>0.675000</td>\n",
              "      <td>0.665000</td>\n",
              "      <td>0.340017</td>\n",
              "      <td>0.726475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.016300</td>\n",
              "      <td>0.960106</td>\n",
              "      <td>0.668750</td>\n",
              "      <td>0.662420</td>\n",
              "      <td>0.668634</td>\n",
              "      <td>0.675325</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>0.337738</td>\n",
              "      <td>0.725700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 94, total number of training (for each informative and uninform class) and test samples: 80, 7120 0.01 DISRoBERTa-B 94 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilbert/distilroberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 00:05, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.689700</td>\n",
              "      <td>0.690986</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.699066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.677700</td>\n",
              "      <td>0.684037</td>\n",
              "      <td>0.612500</td>\n",
              "      <td>0.448399</td>\n",
              "      <td>0.574874</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.315000</td>\n",
              "      <td>0.910000</td>\n",
              "      <td>0.279946</td>\n",
              "      <td>0.718875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.665100</td>\n",
              "      <td>0.659980</td>\n",
              "      <td>0.575000</td>\n",
              "      <td>0.689781</td>\n",
              "      <td>0.507589</td>\n",
              "      <td>0.543103</td>\n",
              "      <td>0.945000</td>\n",
              "      <td>0.205000</td>\n",
              "      <td>0.223013</td>\n",
              "      <td>0.725353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.500700</td>\n",
              "      <td>0.614748</td>\n",
              "      <td>0.663750</td>\n",
              "      <td>0.670747</td>\n",
              "      <td>0.663598</td>\n",
              "      <td>0.657074</td>\n",
              "      <td>0.685000</td>\n",
              "      <td>0.642500</td>\n",
              "      <td>0.327796</td>\n",
              "      <td>0.727031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.328700</td>\n",
              "      <td>0.614353</td>\n",
              "      <td>0.677500</td>\n",
              "      <td>0.689157</td>\n",
              "      <td>0.677046</td>\n",
              "      <td>0.665116</td>\n",
              "      <td>0.715000</td>\n",
              "      <td>0.640000</td>\n",
              "      <td>0.356003</td>\n",
              "      <td>0.727569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.297300</td>\n",
              "      <td>0.629458</td>\n",
              "      <td>0.673750</td>\n",
              "      <td>0.694021</td>\n",
              "      <td>0.672312</td>\n",
              "      <td>0.653422</td>\n",
              "      <td>0.740000</td>\n",
              "      <td>0.607500</td>\n",
              "      <td>0.350591</td>\n",
              "      <td>0.730187</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 791, total number of training (for each informative and uninform class) and test samples: 80, 7120 0.01 DISRoBERTa-B 791 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilbert/distilroberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 00:05, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.694100</td>\n",
              "      <td>0.694540</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.617381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.685500</td>\n",
              "      <td>0.682909</td>\n",
              "      <td>0.501250</td>\n",
              "      <td>0.666109</td>\n",
              "      <td>0.340462</td>\n",
              "      <td>0.500629</td>\n",
              "      <td>0.995000</td>\n",
              "      <td>0.007500</td>\n",
              "      <td>0.015861</td>\n",
              "      <td>0.663294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.575300</td>\n",
              "      <td>0.672141</td>\n",
              "      <td>0.581250</td>\n",
              "      <td>0.680038</td>\n",
              "      <td>0.537126</td>\n",
              "      <td>0.550232</td>\n",
              "      <td>0.890000</td>\n",
              "      <td>0.272500</td>\n",
              "      <td>0.206593</td>\n",
              "      <td>0.680875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.461200</td>\n",
              "      <td>0.653293</td>\n",
              "      <td>0.642500</td>\n",
              "      <td>0.660333</td>\n",
              "      <td>0.641512</td>\n",
              "      <td>0.628959</td>\n",
              "      <td>0.695000</td>\n",
              "      <td>0.590000</td>\n",
              "      <td>0.286584</td>\n",
              "      <td>0.693037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.334600</td>\n",
              "      <td>0.681386</td>\n",
              "      <td>0.646250</td>\n",
              "      <td>0.661078</td>\n",
              "      <td>0.645572</td>\n",
              "      <td>0.634483</td>\n",
              "      <td>0.690000</td>\n",
              "      <td>0.602500</td>\n",
              "      <td>0.293626</td>\n",
              "      <td>0.699531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.321800</td>\n",
              "      <td>0.690686</td>\n",
              "      <td>0.656250</td>\n",
              "      <td>0.652339</td>\n",
              "      <td>0.656206</td>\n",
              "      <td>0.659847</td>\n",
              "      <td>0.645000</td>\n",
              "      <td>0.667500</td>\n",
              "      <td>0.312579</td>\n",
              "      <td>0.702356</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 5, total number of training (for each informative and uninform class) and test samples: 80, 7120 0.01 DISRoBERTa-B 5 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilbert/distilroberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 00:04, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.697400</td>\n",
              "      <td>0.686307</td>\n",
              "      <td>0.591250</td>\n",
              "      <td>0.675917</td>\n",
              "      <td>0.561309</td>\n",
              "      <td>0.559934</td>\n",
              "      <td>0.852500</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.214041</td>\n",
              "      <td>0.688594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.676300</td>\n",
              "      <td>0.680273</td>\n",
              "      <td>0.505000</td>\n",
              "      <td>0.668896</td>\n",
              "      <td>0.344349</td>\n",
              "      <td>0.502513</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.010000</td>\n",
              "      <td>0.070888</td>\n",
              "      <td>0.717450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.589300</td>\n",
              "      <td>0.647062</td>\n",
              "      <td>0.628750</td>\n",
              "      <td>0.694758</td>\n",
              "      <td>0.610537</td>\n",
              "      <td>0.589878</td>\n",
              "      <td>0.845000</td>\n",
              "      <td>0.412500</td>\n",
              "      <td>0.285593</td>\n",
              "      <td>0.728719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.428700</td>\n",
              "      <td>0.670573</td>\n",
              "      <td>0.632500</td>\n",
              "      <td>0.702429</td>\n",
              "      <td>0.611018</td>\n",
              "      <td>0.590136</td>\n",
              "      <td>0.867500</td>\n",
              "      <td>0.397500</td>\n",
              "      <td>0.300227</td>\n",
              "      <td>0.737875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.272900</td>\n",
              "      <td>0.644180</td>\n",
              "      <td>0.668750</td>\n",
              "      <td>0.703247</td>\n",
              "      <td>0.664212</td>\n",
              "      <td>0.636917</td>\n",
              "      <td>0.785000</td>\n",
              "      <td>0.552500</td>\n",
              "      <td>0.347009</td>\n",
              "      <td>0.741794</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.196800</td>\n",
              "      <td>0.674640</td>\n",
              "      <td>0.671250</td>\n",
              "      <td>0.705487</td>\n",
              "      <td>0.666746</td>\n",
              "      <td>0.638945</td>\n",
              "      <td>0.787500</td>\n",
              "      <td>0.555000</td>\n",
              "      <td>0.352150</td>\n",
              "      <td>0.740631</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 6932, total number of training (for each informative and uninform class) and test samples: 80, 7120 0.01 DISRoBERTa-B 6932 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilbert/distilroberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 00:05, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.704900</td>\n",
              "      <td>0.696333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.640838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.688700</td>\n",
              "      <td>0.689136</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.682662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.654600</td>\n",
              "      <td>0.676332</td>\n",
              "      <td>0.592500</td>\n",
              "      <td>0.678501</td>\n",
              "      <td>0.561093</td>\n",
              "      <td>0.560261</td>\n",
              "      <td>0.860000</td>\n",
              "      <td>0.325000</td>\n",
              "      <td>0.218973</td>\n",
              "      <td>0.688831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.551700</td>\n",
              "      <td>0.688271</td>\n",
              "      <td>0.578750</td>\n",
              "      <td>0.672498</td>\n",
              "      <td>0.541152</td>\n",
              "      <td>0.550079</td>\n",
              "      <td>0.865000</td>\n",
              "      <td>0.292500</td>\n",
              "      <td>0.192095</td>\n",
              "      <td>0.676269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.363000</td>\n",
              "      <td>0.678611</td>\n",
              "      <td>0.623750</td>\n",
              "      <td>0.643787</td>\n",
              "      <td>0.622556</td>\n",
              "      <td>0.611236</td>\n",
              "      <td>0.680000</td>\n",
              "      <td>0.567500</td>\n",
              "      <td>0.249081</td>\n",
              "      <td>0.684319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.274500</td>\n",
              "      <td>0.696963</td>\n",
              "      <td>0.626250</td>\n",
              "      <td>0.643623</td>\n",
              "      <td>0.625360</td>\n",
              "      <td>0.615034</td>\n",
              "      <td>0.675000</td>\n",
              "      <td>0.577500</td>\n",
              "      <td>0.253709</td>\n",
              "      <td>0.688794</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 1759, total number of training (for each informative and uninform class) and test samples: 80, 7120 0.01 DISRoBERTa-B 1759 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilbert/distilroberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 00:04, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.688000</td>\n",
              "      <td>0.688954</td>\n",
              "      <td>0.563750</td>\n",
              "      <td>0.685869</td>\n",
              "      <td>0.486084</td>\n",
              "      <td>0.535865</td>\n",
              "      <td>0.952500</td>\n",
              "      <td>0.175000</td>\n",
              "      <td>0.202740</td>\n",
              "      <td>0.669275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.669300</td>\n",
              "      <td>0.679783</td>\n",
              "      <td>0.501250</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.338296</td>\n",
              "      <td>0.500627</td>\n",
              "      <td>0.997500</td>\n",
              "      <td>0.005000</td>\n",
              "      <td>0.020451</td>\n",
              "      <td>0.713719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.539100</td>\n",
              "      <td>0.683945</td>\n",
              "      <td>0.566250</td>\n",
              "      <td>0.687106</td>\n",
              "      <td>0.490192</td>\n",
              "      <td>0.537377</td>\n",
              "      <td>0.952500</td>\n",
              "      <td>0.180000</td>\n",
              "      <td>0.208657</td>\n",
              "      <td>0.728244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.422400</td>\n",
              "      <td>0.623867</td>\n",
              "      <td>0.668750</td>\n",
              "      <td>0.684899</td>\n",
              "      <td>0.667878</td>\n",
              "      <td>0.653061</td>\n",
              "      <td>0.720000</td>\n",
              "      <td>0.617500</td>\n",
              "      <td>0.339287</td>\n",
              "      <td>0.734775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.269900</td>\n",
              "      <td>0.669357</td>\n",
              "      <td>0.670000</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.641667</td>\n",
              "      <td>0.770000</td>\n",
              "      <td>0.570000</td>\n",
              "      <td>0.347011</td>\n",
              "      <td>0.745450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.122400</td>\n",
              "      <td>0.694394</td>\n",
              "      <td>0.685000</td>\n",
              "      <td>0.699284</td>\n",
              "      <td>0.684288</td>\n",
              "      <td>0.668950</td>\n",
              "      <td>0.732500</td>\n",
              "      <td>0.637500</td>\n",
              "      <td>0.371681</td>\n",
              "      <td>0.745725</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 323, total number of training (for each informative and uninform class) and test samples: 80, 7120 0.01 DISRoBERTa-B 323 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilbert/distilroberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 00:04, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.686500</td>\n",
              "      <td>0.692290</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.698531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.701400</td>\n",
              "      <td>0.690559</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.718094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.669200</td>\n",
              "      <td>0.679210</td>\n",
              "      <td>0.556250</td>\n",
              "      <td>0.682184</td>\n",
              "      <td>0.473597</td>\n",
              "      <td>0.531381</td>\n",
              "      <td>0.952500</td>\n",
              "      <td>0.160000</td>\n",
              "      <td>0.184465</td>\n",
              "      <td>0.732400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.621300</td>\n",
              "      <td>0.659949</td>\n",
              "      <td>0.568750</td>\n",
              "      <td>0.679666</td>\n",
              "      <td>0.510005</td>\n",
              "      <td>0.540620</td>\n",
              "      <td>0.915000</td>\n",
              "      <td>0.222500</td>\n",
              "      <td>0.190597</td>\n",
              "      <td>0.731269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.552100</td>\n",
              "      <td>0.630057</td>\n",
              "      <td>0.643750</td>\n",
              "      <td>0.691224</td>\n",
              "      <td>0.635125</td>\n",
              "      <td>0.609943</td>\n",
              "      <td>0.797500</td>\n",
              "      <td>0.490000</td>\n",
              "      <td>0.302139</td>\n",
              "      <td>0.738662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.470400</td>\n",
              "      <td>0.626471</td>\n",
              "      <td>0.640000</td>\n",
              "      <td>0.689655</td>\n",
              "      <td>0.630542</td>\n",
              "      <td>0.606061</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.480000</td>\n",
              "      <td>0.295540</td>\n",
              "      <td>0.740100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 1694, total number of training (for each informative and uninform class) and test samples: 80, 7120 0.01 DISRoBERTa-B 1694 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilbert/distilroberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 00:04, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.724600</td>\n",
              "      <td>0.695442</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.642587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.674800</td>\n",
              "      <td>0.686639</td>\n",
              "      <td>0.567500</td>\n",
              "      <td>0.672968</td>\n",
              "      <td>0.517296</td>\n",
              "      <td>0.541033</td>\n",
              "      <td>0.890000</td>\n",
              "      <td>0.245000</td>\n",
              "      <td>0.176659</td>\n",
              "      <td>0.673156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.627900</td>\n",
              "      <td>0.659032</td>\n",
              "      <td>0.658750</td>\n",
              "      <td>0.656604</td>\n",
              "      <td>0.658737</td>\n",
              "      <td>0.660759</td>\n",
              "      <td>0.652500</td>\n",
              "      <td>0.665000</td>\n",
              "      <td>0.317525</td>\n",
              "      <td>0.675506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.435600</td>\n",
              "      <td>0.669340</td>\n",
              "      <td>0.637500</td>\n",
              "      <td>0.679912</td>\n",
              "      <td>0.631022</td>\n",
              "      <td>0.608696</td>\n",
              "      <td>0.770000</td>\n",
              "      <td>0.505000</td>\n",
              "      <td>0.285196</td>\n",
              "      <td>0.681963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.282900</td>\n",
              "      <td>0.771176</td>\n",
              "      <td>0.652500</td>\n",
              "      <td>0.649874</td>\n",
              "      <td>0.652480</td>\n",
              "      <td>0.654822</td>\n",
              "      <td>0.645000</td>\n",
              "      <td>0.660000</td>\n",
              "      <td>0.305034</td>\n",
              "      <td>0.678494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.135300</td>\n",
              "      <td>0.833378</td>\n",
              "      <td>0.646250</td>\n",
              "      <td>0.634839</td>\n",
              "      <td>0.645904</td>\n",
              "      <td>0.656000</td>\n",
              "      <td>0.615000</td>\n",
              "      <td>0.677500</td>\n",
              "      <td>0.293073</td>\n",
              "      <td>0.677569</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 9741, total number of training (for each informative and uninform class) and test samples: 80, 7120 0.01 DISRoBERTa-B 9741 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilbert/distilroberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 00:04, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.716000</td>\n",
              "      <td>0.692984</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.623644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.678900</td>\n",
              "      <td>0.689102</td>\n",
              "      <td>0.620000</td>\n",
              "      <td>0.680672</td>\n",
              "      <td>0.605768</td>\n",
              "      <td>0.586957</td>\n",
              "      <td>0.810000</td>\n",
              "      <td>0.430000</td>\n",
              "      <td>0.259463</td>\n",
              "      <td>0.673425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>0.687320</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.697975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.615400</td>\n",
              "      <td>0.671277</td>\n",
              "      <td>0.591250</td>\n",
              "      <td>0.695247</td>\n",
              "      <td>0.537377</td>\n",
              "      <td>0.554235</td>\n",
              "      <td>0.932500</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.249697</td>\n",
              "      <td>0.692444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.540700</td>\n",
              "      <td>0.662421</td>\n",
              "      <td>0.607500</td>\n",
              "      <td>0.686000</td>\n",
              "      <td>0.581333</td>\n",
              "      <td>0.571667</td>\n",
              "      <td>0.857500</td>\n",
              "      <td>0.357500</td>\n",
              "      <td>0.248261</td>\n",
              "      <td>0.689431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.446500</td>\n",
              "      <td>0.675845</td>\n",
              "      <td>0.615000</td>\n",
              "      <td>0.690141</td>\n",
              "      <td>0.590945</td>\n",
              "      <td>0.577441</td>\n",
              "      <td>0.857500</td>\n",
              "      <td>0.372500</td>\n",
              "      <td>0.263003</td>\n",
              "      <td>0.689006</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 200, total number of training (for each informative and uninform class) and test samples: 80, 7120 0.01 DISRoBERTa-B 200 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilbert/distilroberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 00:04, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.704400</td>\n",
              "      <td>0.689232</td>\n",
              "      <td>0.561250</td>\n",
              "      <td>0.304950</td>\n",
              "      <td>0.492201</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.192500</td>\n",
              "      <td>0.930000</td>\n",
              "      <td>0.181388</td>\n",
              "      <td>0.662931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.670700</td>\n",
              "      <td>0.683200</td>\n",
              "      <td>0.558750</td>\n",
              "      <td>0.292585</td>\n",
              "      <td>0.485984</td>\n",
              "      <td>0.737374</td>\n",
              "      <td>0.182500</td>\n",
              "      <td>0.935000</td>\n",
              "      <td>0.178411</td>\n",
              "      <td>0.694575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.618400</td>\n",
              "      <td>0.656543</td>\n",
              "      <td>0.630000</td>\n",
              "      <td>0.698574</td>\n",
              "      <td>0.609805</td>\n",
              "      <td>0.589347</td>\n",
              "      <td>0.857500</td>\n",
              "      <td>0.402500</td>\n",
              "      <td>0.291974</td>\n",
              "      <td>0.687937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.402500</td>\n",
              "      <td>0.641623</td>\n",
              "      <td>0.645000</td>\n",
              "      <td>0.662708</td>\n",
              "      <td>0.644019</td>\n",
              "      <td>0.631222</td>\n",
              "      <td>0.697500</td>\n",
              "      <td>0.592500</td>\n",
              "      <td>0.291612</td>\n",
              "      <td>0.690006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.368400</td>\n",
              "      <td>0.699570</td>\n",
              "      <td>0.638750</td>\n",
              "      <td>0.654719</td>\n",
              "      <td>0.637976</td>\n",
              "      <td>0.627002</td>\n",
              "      <td>0.685000</td>\n",
              "      <td>0.592500</td>\n",
              "      <td>0.278695</td>\n",
              "      <td>0.689487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.264300</td>\n",
              "      <td>0.738552</td>\n",
              "      <td>0.647500</td>\n",
              "      <td>0.675862</td>\n",
              "      <td>0.644780</td>\n",
              "      <td>0.625532</td>\n",
              "      <td>0.735000</td>\n",
              "      <td>0.560000</td>\n",
              "      <td>0.299624</td>\n",
              "      <td>0.688906</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 999, total number of training (for each informative and uninform class) and test samples: 80, 7120 0.01 DISRoBERTa-B 999 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilbert/distilroberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 00:04, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.709300</td>\n",
              "      <td>0.691075</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.658556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.679600</td>\n",
              "      <td>0.685845</td>\n",
              "      <td>0.676250</td>\n",
              "      <td>0.697076</td>\n",
              "      <td>0.674713</td>\n",
              "      <td>0.654945</td>\n",
              "      <td>0.745000</td>\n",
              "      <td>0.607500</td>\n",
              "      <td>0.355880</td>\n",
              "      <td>0.707956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.659500</td>\n",
              "      <td>0.676181</td>\n",
              "      <td>0.558750</td>\n",
              "      <td>0.685103</td>\n",
              "      <td>0.474075</td>\n",
              "      <td>0.532594</td>\n",
              "      <td>0.960000</td>\n",
              "      <td>0.157500</td>\n",
              "      <td>0.196932</td>\n",
              "      <td>0.720156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.564700</td>\n",
              "      <td>0.640532</td>\n",
              "      <td>0.636250</td>\n",
              "      <td>0.690096</td>\n",
              "      <td>0.624927</td>\n",
              "      <td>0.601113</td>\n",
              "      <td>0.810000</td>\n",
              "      <td>0.462500</td>\n",
              "      <td>0.290611</td>\n",
              "      <td>0.718675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.411900</td>\n",
              "      <td>0.628193</td>\n",
              "      <td>0.663750</td>\n",
              "      <td>0.691867</td>\n",
              "      <td>0.660927</td>\n",
              "      <td>0.638478</td>\n",
              "      <td>0.755000</td>\n",
              "      <td>0.572500</td>\n",
              "      <td>0.333094</td>\n",
              "      <td>0.715481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.363500</td>\n",
              "      <td>0.633577</td>\n",
              "      <td>0.665000</td>\n",
              "      <td>0.690531</td>\n",
              "      <td>0.662704</td>\n",
              "      <td>0.641631</td>\n",
              "      <td>0.747500</td>\n",
              "      <td>0.582500</td>\n",
              "      <td>0.334586</td>\n",
              "      <td>0.714531</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 94, total number of training (for each informative and uninform class) and test samples: 80, 7120 0.01 XLNet-B 94 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 00:13, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.701500</td>\n",
              "      <td>0.733592</td>\n",
              "      <td>0.518750</td>\n",
              "      <td>0.186047</td>\n",
              "      <td>0.422216</td>\n",
              "      <td>0.602740</td>\n",
              "      <td>0.110000</td>\n",
              "      <td>0.927500</td>\n",
              "      <td>0.065112</td>\n",
              "      <td>0.604944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.695600</td>\n",
              "      <td>0.676653</td>\n",
              "      <td>0.581250</td>\n",
              "      <td>0.631463</td>\n",
              "      <td>0.573329</td>\n",
              "      <td>0.563851</td>\n",
              "      <td>0.717500</td>\n",
              "      <td>0.445000</td>\n",
              "      <td>0.168892</td>\n",
              "      <td>0.582750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.632600</td>\n",
              "      <td>0.674601</td>\n",
              "      <td>0.602500</td>\n",
              "      <td>0.646667</td>\n",
              "      <td>0.596190</td>\n",
              "      <td>0.582000</td>\n",
              "      <td>0.727500</td>\n",
              "      <td>0.477500</td>\n",
              "      <td>0.211723</td>\n",
              "      <td>0.610413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.677000</td>\n",
              "      <td>0.664001</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.609375</td>\n",
              "      <td>0.624399</td>\n",
              "      <td>0.635870</td>\n",
              "      <td>0.585000</td>\n",
              "      <td>0.665000</td>\n",
              "      <td>0.250804</td>\n",
              "      <td>0.642206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.522300</td>\n",
              "      <td>0.683445</td>\n",
              "      <td>0.570000</td>\n",
              "      <td>0.654618</td>\n",
              "      <td>0.542541</td>\n",
              "      <td>0.546980</td>\n",
              "      <td>0.815000</td>\n",
              "      <td>0.325000</td>\n",
              "      <td>0.160602</td>\n",
              "      <td>0.610469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.510100</td>\n",
              "      <td>0.681187</td>\n",
              "      <td>0.577500</td>\n",
              "      <td>0.653689</td>\n",
              "      <td>0.556011</td>\n",
              "      <td>0.553819</td>\n",
              "      <td>0.797500</td>\n",
              "      <td>0.357500</td>\n",
              "      <td>0.172606</td>\n",
              "      <td>0.609031</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 791, total number of training (for each informative and uninform class) and test samples: 80, 7120 0.01 XLNet-B 791 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 00:13, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.725100</td>\n",
              "      <td>0.681101</td>\n",
              "      <td>0.582500</td>\n",
              "      <td>0.557029</td>\n",
              "      <td>0.581115</td>\n",
              "      <td>0.593220</td>\n",
              "      <td>0.525000</td>\n",
              "      <td>0.640000</td>\n",
              "      <td>0.166102</td>\n",
              "      <td>0.590400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.702500</td>\n",
              "      <td>0.811903</td>\n",
              "      <td>0.543750</td>\n",
              "      <td>0.265594</td>\n",
              "      <td>0.467339</td>\n",
              "      <td>0.680412</td>\n",
              "      <td>0.165000</td>\n",
              "      <td>0.922500</td>\n",
              "      <td>0.134031</td>\n",
              "      <td>0.645069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.489600</td>\n",
              "      <td>0.702270</td>\n",
              "      <td>0.620000</td>\n",
              "      <td>0.674518</td>\n",
              "      <td>0.609031</td>\n",
              "      <td>0.589888</td>\n",
              "      <td>0.787500</td>\n",
              "      <td>0.452500</td>\n",
              "      <td>0.254718</td>\n",
              "      <td>0.666275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.414800</td>\n",
              "      <td>0.760712</td>\n",
              "      <td>0.623750</td>\n",
              "      <td>0.627014</td>\n",
              "      <td>0.623721</td>\n",
              "      <td>0.621622</td>\n",
              "      <td>0.632500</td>\n",
              "      <td>0.615000</td>\n",
              "      <td>0.247538</td>\n",
              "      <td>0.669581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.351900</td>\n",
              "      <td>0.909050</td>\n",
              "      <td>0.627500</td>\n",
              "      <td>0.670354</td>\n",
              "      <td>0.621097</td>\n",
              "      <td>0.601190</td>\n",
              "      <td>0.757500</td>\n",
              "      <td>0.497500</td>\n",
              "      <td>0.264082</td>\n",
              "      <td>0.670681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.203100</td>\n",
              "      <td>0.910426</td>\n",
              "      <td>0.622500</td>\n",
              "      <td>0.643868</td>\n",
              "      <td>0.621136</td>\n",
              "      <td>0.609375</td>\n",
              "      <td>0.682500</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>0.246783</td>\n",
              "      <td>0.667856</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 5, total number of training (for each informative and uninform class) and test samples: 80, 7120 0.01 XLNet-B 5 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 00:13, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.716200</td>\n",
              "      <td>0.665481</td>\n",
              "      <td>0.580000</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.564270</td>\n",
              "      <td>0.557971</td>\n",
              "      <td>0.770000</td>\n",
              "      <td>0.390000</td>\n",
              "      <td>0.172976</td>\n",
              "      <td>0.620419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.682700</td>\n",
              "      <td>0.702989</td>\n",
              "      <td>0.550000</td>\n",
              "      <td>0.669725</td>\n",
              "      <td>0.481921</td>\n",
              "      <td>0.528986</td>\n",
              "      <td>0.912500</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>0.145191</td>\n",
              "      <td>0.646844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.545000</td>\n",
              "      <td>0.731999</td>\n",
              "      <td>0.571250</td>\n",
              "      <td>0.680930</td>\n",
              "      <td>0.513798</td>\n",
              "      <td>0.542222</td>\n",
              "      <td>0.915000</td>\n",
              "      <td>0.227500</td>\n",
              "      <td>0.196231</td>\n",
              "      <td>0.658112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.501600</td>\n",
              "      <td>0.743833</td>\n",
              "      <td>0.578750</td>\n",
              "      <td>0.679962</td>\n",
              "      <td>0.531937</td>\n",
              "      <td>0.548239</td>\n",
              "      <td>0.895000</td>\n",
              "      <td>0.262500</td>\n",
              "      <td>0.203341</td>\n",
              "      <td>0.665488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.367300</td>\n",
              "      <td>0.708663</td>\n",
              "      <td>0.620000</td>\n",
              "      <td>0.674518</td>\n",
              "      <td>0.609031</td>\n",
              "      <td>0.589888</td>\n",
              "      <td>0.787500</td>\n",
              "      <td>0.452500</td>\n",
              "      <td>0.254718</td>\n",
              "      <td>0.684300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.376500</td>\n",
              "      <td>0.808018</td>\n",
              "      <td>0.588750</td>\n",
              "      <td>0.690499</td>\n",
              "      <td>0.538918</td>\n",
              "      <td>0.553544</td>\n",
              "      <td>0.917500</td>\n",
              "      <td>0.260000</td>\n",
              "      <td>0.235582</td>\n",
              "      <td>0.678575</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 6932, total number of training (for each informative and uninform class) and test samples: 80, 7120 0.01 XLNet-B 6932 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 00:13, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.690300</td>\n",
              "      <td>0.698911</td>\n",
              "      <td>0.482500</td>\n",
              "      <td>0.475949</td>\n",
              "      <td>0.482419</td>\n",
              "      <td>0.482051</td>\n",
              "      <td>0.470000</td>\n",
              "      <td>0.495000</td>\n",
              "      <td>-0.035011</td>\n",
              "      <td>0.479994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.675800</td>\n",
              "      <td>0.690731</td>\n",
              "      <td>0.501250</td>\n",
              "      <td>0.659847</td>\n",
              "      <td>0.362710</td>\n",
              "      <td>0.500647</td>\n",
              "      <td>0.967500</td>\n",
              "      <td>0.035000</td>\n",
              "      <td>0.006922</td>\n",
              "      <td>0.573331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.659900</td>\n",
              "      <td>0.688983</td>\n",
              "      <td>0.558750</td>\n",
              "      <td>0.404722</td>\n",
              "      <td>0.527088</td>\n",
              "      <td>0.621762</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.817500</td>\n",
              "      <td>0.137317</td>\n",
              "      <td>0.583013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.679700</td>\n",
              "      <td>0.700795</td>\n",
              "      <td>0.533750</td>\n",
              "      <td>0.667261</td>\n",
              "      <td>0.444278</td>\n",
              "      <td>0.518724</td>\n",
              "      <td>0.935000</td>\n",
              "      <td>0.132500</td>\n",
              "      <td>0.113131</td>\n",
              "      <td>0.625875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.598200</td>\n",
              "      <td>0.679161</td>\n",
              "      <td>0.575000</td>\n",
              "      <td>0.662028</td>\n",
              "      <td>0.544819</td>\n",
              "      <td>0.549505</td>\n",
              "      <td>0.832500</td>\n",
              "      <td>0.317500</td>\n",
              "      <td>0.174990</td>\n",
              "      <td>0.639012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.531200</td>\n",
              "      <td>0.674779</td>\n",
              "      <td>0.586250</td>\n",
              "      <td>0.660513</td>\n",
              "      <td>0.565456</td>\n",
              "      <td>0.560000</td>\n",
              "      <td>0.805000</td>\n",
              "      <td>0.367500</td>\n",
              "      <td>0.191833</td>\n",
              "      <td>0.644381</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 1759, total number of training (for each informative and uninform class) and test samples: 80, 7120 0.01 XLNet-B 1759 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 00:13, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.692900</td>\n",
              "      <td>0.685991</td>\n",
              "      <td>0.551250</td>\n",
              "      <td>0.533160</td>\n",
              "      <td>0.550575</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.512500</td>\n",
              "      <td>0.590000</td>\n",
              "      <td>0.102809</td>\n",
              "      <td>0.532216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.645700</td>\n",
              "      <td>0.679398</td>\n",
              "      <td>0.553750</td>\n",
              "      <td>0.507586</td>\n",
              "      <td>0.549793</td>\n",
              "      <td>0.566154</td>\n",
              "      <td>0.460000</td>\n",
              "      <td>0.647500</td>\n",
              "      <td>0.109441</td>\n",
              "      <td>0.587888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.657400</td>\n",
              "      <td>0.672828</td>\n",
              "      <td>0.571250</td>\n",
              "      <td>0.625137</td>\n",
              "      <td>0.562203</td>\n",
              "      <td>0.555340</td>\n",
              "      <td>0.715000</td>\n",
              "      <td>0.427500</td>\n",
              "      <td>0.148781</td>\n",
              "      <td>0.598294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.560000</td>\n",
              "      <td>0.701384</td>\n",
              "      <td>0.580000</td>\n",
              "      <td>0.661972</td>\n",
              "      <td>0.553758</td>\n",
              "      <td>0.553872</td>\n",
              "      <td>0.822500</td>\n",
              "      <td>0.337500</td>\n",
              "      <td>0.182959</td>\n",
              "      <td>0.617850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.554600</td>\n",
              "      <td>0.692440</td>\n",
              "      <td>0.591250</td>\n",
              "      <td>0.632171</td>\n",
              "      <td>0.586128</td>\n",
              "      <td>0.574642</td>\n",
              "      <td>0.702500</td>\n",
              "      <td>0.480000</td>\n",
              "      <td>0.187192</td>\n",
              "      <td>0.634700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.565700</td>\n",
              "      <td>0.687544</td>\n",
              "      <td>0.611250</td>\n",
              "      <td>0.628435</td>\n",
              "      <td>0.610417</td>\n",
              "      <td>0.601831</td>\n",
              "      <td>0.657500</td>\n",
              "      <td>0.565000</td>\n",
              "      <td>0.223458</td>\n",
              "      <td>0.638300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 323, total number of training (for each informative and uninform class) and test samples: 80, 7120 0.01 XLNet-B 323 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 00:13, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.676300</td>\n",
              "      <td>0.678934</td>\n",
              "      <td>0.576250</td>\n",
              "      <td>0.647975</td>\n",
              "      <td>0.557896</td>\n",
              "      <td>0.554174</td>\n",
              "      <td>0.780000</td>\n",
              "      <td>0.372500</td>\n",
              "      <td>0.166994</td>\n",
              "      <td>0.584556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.633300</td>\n",
              "      <td>0.694614</td>\n",
              "      <td>0.578750</td>\n",
              "      <td>0.493233</td>\n",
              "      <td>0.566403</td>\n",
              "      <td>0.618868</td>\n",
              "      <td>0.410000</td>\n",
              "      <td>0.747500</td>\n",
              "      <td>0.167317</td>\n",
              "      <td>0.613338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.478200</td>\n",
              "      <td>0.766324</td>\n",
              "      <td>0.610000</td>\n",
              "      <td>0.615764</td>\n",
              "      <td>0.609912</td>\n",
              "      <td>0.606796</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.595000</td>\n",
              "      <td>0.220099</td>\n",
              "      <td>0.628812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.458700</td>\n",
              "      <td>0.801750</td>\n",
              "      <td>0.613750</td>\n",
              "      <td>0.589641</td>\n",
              "      <td>0.612412</td>\n",
              "      <td>0.628895</td>\n",
              "      <td>0.555000</td>\n",
              "      <td>0.672500</td>\n",
              "      <td>0.229087</td>\n",
              "      <td>0.641531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.381900</td>\n",
              "      <td>0.793351</td>\n",
              "      <td>0.626250</td>\n",
              "      <td>0.641056</td>\n",
              "      <td>0.625613</td>\n",
              "      <td>0.616628</td>\n",
              "      <td>0.667500</td>\n",
              "      <td>0.585000</td>\n",
              "      <td>0.253364</td>\n",
              "      <td>0.662744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.246900</td>\n",
              "      <td>0.807280</td>\n",
              "      <td>0.633750</td>\n",
              "      <td>0.650775</td>\n",
              "      <td>0.632878</td>\n",
              "      <td>0.621868</td>\n",
              "      <td>0.682500</td>\n",
              "      <td>0.585000</td>\n",
              "      <td>0.268781</td>\n",
              "      <td>0.667294</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 1694, total number of training (for each informative and uninform class) and test samples: 80, 7120 0.01 XLNet-B 1694 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 00:13, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.760900</td>\n",
              "      <td>0.829074</td>\n",
              "      <td>0.532500</td>\n",
              "      <td>0.664875</td>\n",
              "      <td>0.446074</td>\n",
              "      <td>0.518156</td>\n",
              "      <td>0.927500</td>\n",
              "      <td>0.137500</td>\n",
              "      <td>0.106017</td>\n",
              "      <td>0.640381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.645400</td>\n",
              "      <td>0.674761</td>\n",
              "      <td>0.612500</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>0.603882</td>\n",
              "      <td>0.659574</td>\n",
              "      <td>0.465000</td>\n",
              "      <td>0.760000</td>\n",
              "      <td>0.235479</td>\n",
              "      <td>0.658931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.430100</td>\n",
              "      <td>0.727462</td>\n",
              "      <td>0.621250</td>\n",
              "      <td>0.664452</td>\n",
              "      <td>0.614866</td>\n",
              "      <td>0.596421</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.492500</td>\n",
              "      <td>0.250963</td>\n",
              "      <td>0.675800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.405100</td>\n",
              "      <td>0.792533</td>\n",
              "      <td>0.621250</td>\n",
              "      <td>0.671010</td>\n",
              "      <td>0.612383</td>\n",
              "      <td>0.593090</td>\n",
              "      <td>0.772500</td>\n",
              "      <td>0.470000</td>\n",
              "      <td>0.254420</td>\n",
              "      <td>0.681925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.271200</td>\n",
              "      <td>0.761212</td>\n",
              "      <td>0.633750</td>\n",
              "      <td>0.630517</td>\n",
              "      <td>0.633722</td>\n",
              "      <td>0.636132</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.642500</td>\n",
              "      <td>0.267541</td>\n",
              "      <td>0.687850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.221100</td>\n",
              "      <td>0.785970</td>\n",
              "      <td>0.640000</td>\n",
              "      <td>0.652174</td>\n",
              "      <td>0.639558</td>\n",
              "      <td>0.630841</td>\n",
              "      <td>0.675000</td>\n",
              "      <td>0.605000</td>\n",
              "      <td>0.280689</td>\n",
              "      <td>0.689506</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 9741, total number of training (for each informative and uninform class) and test samples: 80, 7120 0.01 XLNet-B 9741 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 00:13, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.701100</td>\n",
              "      <td>0.685107</td>\n",
              "      <td>0.556250</td>\n",
              "      <td>0.523490</td>\n",
              "      <td>0.554143</td>\n",
              "      <td>0.565217</td>\n",
              "      <td>0.487500</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.113579</td>\n",
              "      <td>0.563575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.737800</td>\n",
              "      <td>0.688020</td>\n",
              "      <td>0.546250</td>\n",
              "      <td>0.447489</td>\n",
              "      <td>0.531273</td>\n",
              "      <td>0.571984</td>\n",
              "      <td>0.367500</td>\n",
              "      <td>0.725000</td>\n",
              "      <td>0.099046</td>\n",
              "      <td>0.541806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.674100</td>\n",
              "      <td>0.687950</td>\n",
              "      <td>0.512500</td>\n",
              "      <td>0.632768</td>\n",
              "      <td>0.453931</td>\n",
              "      <td>0.507553</td>\n",
              "      <td>0.840000</td>\n",
              "      <td>0.185000</td>\n",
              "      <td>0.033085</td>\n",
              "      <td>0.561319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.630300</td>\n",
              "      <td>0.693798</td>\n",
              "      <td>0.540000</td>\n",
              "      <td>0.303030</td>\n",
              "      <td>0.479873</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.880000</td>\n",
              "      <td>0.109109</td>\n",
              "      <td>0.540931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.623000</td>\n",
              "      <td>0.691731</td>\n",
              "      <td>0.541250</td>\n",
              "      <td>0.410915</td>\n",
              "      <td>0.517638</td>\n",
              "      <td>0.573991</td>\n",
              "      <td>0.320000</td>\n",
              "      <td>0.762500</td>\n",
              "      <td>0.091997</td>\n",
              "      <td>0.542312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.649500</td>\n",
              "      <td>0.688845</td>\n",
              "      <td>0.543750</td>\n",
              "      <td>0.562874</td>\n",
              "      <td>0.542875</td>\n",
              "      <td>0.540230</td>\n",
              "      <td>0.587500</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.087837</td>\n",
              "      <td>0.552456</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 200, total number of training (for each informative and uninform class) and test samples: 80, 7120 0.01 XLNet-B 200 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 00:13, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.828100</td>\n",
              "      <td>0.751875</td>\n",
              "      <td>0.503750</td>\n",
              "      <td>0.667782</td>\n",
              "      <td>0.343768</td>\n",
              "      <td>0.501887</td>\n",
              "      <td>0.997500</td>\n",
              "      <td>0.010000</td>\n",
              "      <td>0.047583</td>\n",
              "      <td>0.556319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.671300</td>\n",
              "      <td>0.675501</td>\n",
              "      <td>0.582500</td>\n",
              "      <td>0.450658</td>\n",
              "      <td>0.556982</td>\n",
              "      <td>0.658654</td>\n",
              "      <td>0.342500</td>\n",
              "      <td>0.822500</td>\n",
              "      <td>0.188084</td>\n",
              "      <td>0.593744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.565000</td>\n",
              "      <td>0.667893</td>\n",
              "      <td>0.617500</td>\n",
              "      <td>0.681250</td>\n",
              "      <td>0.601562</td>\n",
              "      <td>0.583929</td>\n",
              "      <td>0.817500</td>\n",
              "      <td>0.417500</td>\n",
              "      <td>0.256406</td>\n",
              "      <td>0.622050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.497500</td>\n",
              "      <td>0.658969</td>\n",
              "      <td>0.631250</td>\n",
              "      <td>0.608234</td>\n",
              "      <td>0.629973</td>\n",
              "      <td>0.648725</td>\n",
              "      <td>0.572500</td>\n",
              "      <td>0.690000</td>\n",
              "      <td>0.264331</td>\n",
              "      <td>0.634562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.440600</td>\n",
              "      <td>0.675049</td>\n",
              "      <td>0.622500</td>\n",
              "      <td>0.671739</td>\n",
              "      <td>0.613811</td>\n",
              "      <td>0.594231</td>\n",
              "      <td>0.772500</td>\n",
              "      <td>0.472500</td>\n",
              "      <td>0.256830</td>\n",
              "      <td>0.650750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.478000</td>\n",
              "      <td>0.685234</td>\n",
              "      <td>0.628750</td>\n",
              "      <td>0.683706</td>\n",
              "      <td>0.617193</td>\n",
              "      <td>0.595547</td>\n",
              "      <td>0.802500</td>\n",
              "      <td>0.455000</td>\n",
              "      <td>0.274614</td>\n",
              "      <td>0.658256</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 999, total number of training (for each informative and uninform class) and test samples: 80, 7120 0.01 XLNet-B 999 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 00:13, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.809400</td>\n",
              "      <td>0.702232</td>\n",
              "      <td>0.510000</td>\n",
              "      <td>0.105023</td>\n",
              "      <td>0.383837</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>0.057500</td>\n",
              "      <td>0.962500</td>\n",
              "      <td>0.047013</td>\n",
              "      <td>0.591938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.694700</td>\n",
              "      <td>0.700398</td>\n",
              "      <td>0.530000</td>\n",
              "      <td>0.675862</td>\n",
              "      <td>0.410658</td>\n",
              "      <td>0.515789</td>\n",
              "      <td>0.980000</td>\n",
              "      <td>0.080000</td>\n",
              "      <td>0.137649</td>\n",
              "      <td>0.613962</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.549900</td>\n",
              "      <td>0.679269</td>\n",
              "      <td>0.557500</td>\n",
              "      <td>0.406040</td>\n",
              "      <td>0.526725</td>\n",
              "      <td>0.617347</td>\n",
              "      <td>0.302500</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.133694</td>\n",
              "      <td>0.614650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.436800</td>\n",
              "      <td>0.673671</td>\n",
              "      <td>0.612500</td>\n",
              "      <td>0.672304</td>\n",
              "      <td>0.599149</td>\n",
              "      <td>0.582418</td>\n",
              "      <td>0.795000</td>\n",
              "      <td>0.430000</td>\n",
              "      <td>0.241674</td>\n",
              "      <td>0.624506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.420500</td>\n",
              "      <td>0.666885</td>\n",
              "      <td>0.601250</td>\n",
              "      <td>0.589447</td>\n",
              "      <td>0.600920</td>\n",
              "      <td>0.607427</td>\n",
              "      <td>0.572500</td>\n",
              "      <td>0.630000</td>\n",
              "      <td>0.202836</td>\n",
              "      <td>0.651563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.388800</td>\n",
              "      <td>0.669812</td>\n",
              "      <td>0.606250</td>\n",
              "      <td>0.596671</td>\n",
              "      <td>0.606028</td>\n",
              "      <td>0.611549</td>\n",
              "      <td>0.582500</td>\n",
              "      <td>0.630000</td>\n",
              "      <td>0.212740</td>\n",
              "      <td>0.656763</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 94, total number of training (for each informative and uninform class) and test samples: 80, 7120 0.01 XLNet-L 94 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-large-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 00:28, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.723200</td>\n",
              "      <td>0.689496</td>\n",
              "      <td>0.517500</td>\n",
              "      <td>0.089623</td>\n",
              "      <td>0.380696</td>\n",
              "      <td>0.791667</td>\n",
              "      <td>0.047500</td>\n",
              "      <td>0.987500</td>\n",
              "      <td>0.102587</td>\n",
              "      <td>0.594256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.709600</td>\n",
              "      <td>0.698495</td>\n",
              "      <td>0.513750</td>\n",
              "      <td>0.664366</td>\n",
              "      <td>0.391140</td>\n",
              "      <td>0.507246</td>\n",
              "      <td>0.962500</td>\n",
              "      <td>0.065000</td>\n",
              "      <td>0.062356</td>\n",
              "      <td>0.572362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.682600</td>\n",
              "      <td>0.679966</td>\n",
              "      <td>0.550000</td>\n",
              "      <td>0.666048</td>\n",
              "      <td>0.488197</td>\n",
              "      <td>0.529499</td>\n",
              "      <td>0.897500</td>\n",
              "      <td>0.202500</td>\n",
              "      <td>0.139080</td>\n",
              "      <td>0.644081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.631400</td>\n",
              "      <td>0.672742</td>\n",
              "      <td>0.566250</td>\n",
              "      <td>0.632025</td>\n",
              "      <td>0.551934</td>\n",
              "      <td>0.548803</td>\n",
              "      <td>0.745000</td>\n",
              "      <td>0.387500</td>\n",
              "      <td>0.141876</td>\n",
              "      <td>0.640825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.645800</td>\n",
              "      <td>0.684480</td>\n",
              "      <td>0.573750</td>\n",
              "      <td>0.449111</td>\n",
              "      <td>0.550753</td>\n",
              "      <td>0.634703</td>\n",
              "      <td>0.347500</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.165402</td>\n",
              "      <td>0.604950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.582200</td>\n",
              "      <td>0.717878</td>\n",
              "      <td>0.570000</td>\n",
              "      <td>0.650407</td>\n",
              "      <td>0.545982</td>\n",
              "      <td>0.547945</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.340000</td>\n",
              "      <td>0.157672</td>\n",
              "      <td>0.620950</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 791, total number of training (for each informative and uninform class) and test samples: 80, 7120 0.01 XLNet-L 791 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-large-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 00:28, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.705900</td>\n",
              "      <td>0.694993</td>\n",
              "      <td>0.522500</td>\n",
              "      <td>0.578366</td>\n",
              "      <td>0.513967</td>\n",
              "      <td>0.517787</td>\n",
              "      <td>0.655000</td>\n",
              "      <td>0.390000</td>\n",
              "      <td>0.046668</td>\n",
              "      <td>0.514919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.803900</td>\n",
              "      <td>0.696201</td>\n",
              "      <td>0.530000</td>\n",
              "      <td>0.655046</td>\n",
              "      <td>0.458895</td>\n",
              "      <td>0.517391</td>\n",
              "      <td>0.892500</td>\n",
              "      <td>0.167500</td>\n",
              "      <td>0.087114</td>\n",
              "      <td>0.556575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.719800</td>\n",
              "      <td>0.705133</td>\n",
              "      <td>0.588750</td>\n",
              "      <td>0.588235</td>\n",
              "      <td>0.588749</td>\n",
              "      <td>0.588972</td>\n",
              "      <td>0.587500</td>\n",
              "      <td>0.590000</td>\n",
              "      <td>0.177501</td>\n",
              "      <td>0.629806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.620800</td>\n",
              "      <td>0.729632</td>\n",
              "      <td>0.567500</td>\n",
              "      <td>0.656746</td>\n",
              "      <td>0.536143</td>\n",
              "      <td>0.544408</td>\n",
              "      <td>0.827500</td>\n",
              "      <td>0.307500</td>\n",
              "      <td>0.158049</td>\n",
              "      <td>0.634131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.524300</td>\n",
              "      <td>0.749185</td>\n",
              "      <td>0.572500</td>\n",
              "      <td>0.670520</td>\n",
              "      <td>0.530990</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>0.870000</td>\n",
              "      <td>0.275000</td>\n",
              "      <td>0.180410</td>\n",
              "      <td>0.651481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.411700</td>\n",
              "      <td>0.770034</td>\n",
              "      <td>0.577500</td>\n",
              "      <td>0.675000</td>\n",
              "      <td>0.535714</td>\n",
              "      <td>0.548438</td>\n",
              "      <td>0.877500</td>\n",
              "      <td>0.277500</td>\n",
              "      <td>0.193750</td>\n",
              "      <td>0.653906</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 5, total number of training (for each informative and uninform class) and test samples: 80, 7120 0.01 XLNet-L 5 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-large-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 00:28, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.672900</td>\n",
              "      <td>0.694041</td>\n",
              "      <td>0.526250</td>\n",
              "      <td>0.657633</td>\n",
              "      <td>0.444435</td>\n",
              "      <td>0.514851</td>\n",
              "      <td>0.910000</td>\n",
              "      <td>0.142500</td>\n",
              "      <td>0.081897</td>\n",
              "      <td>0.522144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.761600</td>\n",
              "      <td>0.679245</td>\n",
              "      <td>0.560000</td>\n",
              "      <td>0.660232</td>\n",
              "      <td>0.518059</td>\n",
              "      <td>0.537736</td>\n",
              "      <td>0.855000</td>\n",
              "      <td>0.265000</td>\n",
              "      <td>0.148625</td>\n",
              "      <td>0.573006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.608000</td>\n",
              "      <td>0.686649</td>\n",
              "      <td>0.551250</td>\n",
              "      <td>0.662911</td>\n",
              "      <td>0.495941</td>\n",
              "      <td>0.530827</td>\n",
              "      <td>0.882500</td>\n",
              "      <td>0.220000</td>\n",
              "      <td>0.136838</td>\n",
              "      <td>0.587269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.519800</td>\n",
              "      <td>0.670502</td>\n",
              "      <td>0.590000</td>\n",
              "      <td>0.670683</td>\n",
              "      <td>0.563818</td>\n",
              "      <td>0.560403</td>\n",
              "      <td>0.835000</td>\n",
              "      <td>0.345000</td>\n",
              "      <td>0.206488</td>\n",
              "      <td>0.637331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.467500</td>\n",
              "      <td>0.666392</td>\n",
              "      <td>0.611250</td>\n",
              "      <td>0.659365</td>\n",
              "      <td>0.603336</td>\n",
              "      <td>0.586745</td>\n",
              "      <td>0.752500</td>\n",
              "      <td>0.470000</td>\n",
              "      <td>0.231948</td>\n",
              "      <td>0.673375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.453900</td>\n",
              "      <td>0.670322</td>\n",
              "      <td>0.607500</td>\n",
              "      <td>0.664530</td>\n",
              "      <td>0.595819</td>\n",
              "      <td>0.580224</td>\n",
              "      <td>0.777500</td>\n",
              "      <td>0.437500</td>\n",
              "      <td>0.228620</td>\n",
              "      <td>0.675569</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 6932, total number of training (for each informative and uninform class) and test samples: 80, 7120 0.01 XLNet-L 6932 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-large-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 00:28, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.713600</td>\n",
              "      <td>0.695989</td>\n",
              "      <td>0.513750</td>\n",
              "      <td>0.264650</td>\n",
              "      <td>0.450719</td>\n",
              "      <td>0.542636</td>\n",
              "      <td>0.175000</td>\n",
              "      <td>0.852500</td>\n",
              "      <td>0.037388</td>\n",
              "      <td>0.496425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.727700</td>\n",
              "      <td>0.697038</td>\n",
              "      <td>0.501250</td>\n",
              "      <td>0.664987</td>\n",
              "      <td>0.344719</td>\n",
              "      <td>0.500632</td>\n",
              "      <td>0.990000</td>\n",
              "      <td>0.012500</td>\n",
              "      <td>0.011852</td>\n",
              "      <td>0.553106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.695400</td>\n",
              "      <td>0.686474</td>\n",
              "      <td>0.542500</td>\n",
              "      <td>0.595133</td>\n",
              "      <td>0.534635</td>\n",
              "      <td>0.533730</td>\n",
              "      <td>0.672500</td>\n",
              "      <td>0.412500</td>\n",
              "      <td>0.088027</td>\n",
              "      <td>0.608081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.749100</td>\n",
              "      <td>0.713082</td>\n",
              "      <td>0.502500</td>\n",
              "      <td>0.667224</td>\n",
              "      <td>0.341038</td>\n",
              "      <td>0.501256</td>\n",
              "      <td>0.997500</td>\n",
              "      <td>0.007500</td>\n",
              "      <td>0.035444</td>\n",
              "      <td>0.542350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.660600</td>\n",
              "      <td>0.689427</td>\n",
              "      <td>0.545000</td>\n",
              "      <td>0.645914</td>\n",
              "      <td>0.504775</td>\n",
              "      <td>0.528662</td>\n",
              "      <td>0.830000</td>\n",
              "      <td>0.260000</td>\n",
              "      <td>0.109536</td>\n",
              "      <td>0.598406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.697300</td>\n",
              "      <td>0.686981</td>\n",
              "      <td>0.546250</td>\n",
              "      <td>0.551298</td>\n",
              "      <td>0.546193</td>\n",
              "      <td>0.545232</td>\n",
              "      <td>0.557500</td>\n",
              "      <td>0.535000</td>\n",
              "      <td>0.092523</td>\n",
              "      <td>0.607725</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 1759, total number of training (for each informative and uninform class) and test samples: 80, 7120 0.01 XLNet-L 1759 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-large-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 00:28, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.668300</td>\n",
              "      <td>0.703675</td>\n",
              "      <td>0.503750</td>\n",
              "      <td>0.047962</td>\n",
              "      <td>0.356187</td>\n",
              "      <td>0.588235</td>\n",
              "      <td>0.025000</td>\n",
              "      <td>0.982500</td>\n",
              "      <td>0.026003</td>\n",
              "      <td>0.492453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.804100</td>\n",
              "      <td>0.793678</td>\n",
              "      <td>0.513750</td>\n",
              "      <td>0.332762</td>\n",
              "      <td>0.475132</td>\n",
              "      <td>0.530055</td>\n",
              "      <td>0.242500</td>\n",
              "      <td>0.785000</td>\n",
              "      <td>0.032736</td>\n",
              "      <td>0.544687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.777200</td>\n",
              "      <td>0.705911</td>\n",
              "      <td>0.496250</td>\n",
              "      <td>0.056206</td>\n",
              "      <td>0.356321</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.030000</td>\n",
              "      <td>0.962500</td>\n",
              "      <td>-0.020766</td>\n",
              "      <td>0.541269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.633400</td>\n",
              "      <td>0.697506</td>\n",
              "      <td>0.497500</td>\n",
              "      <td>0.106667</td>\n",
              "      <td>0.378551</td>\n",
              "      <td>0.480000</td>\n",
              "      <td>0.060000</td>\n",
              "      <td>0.935000</td>\n",
              "      <td>-0.010328</td>\n",
              "      <td>0.538828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.760500</td>\n",
              "      <td>0.691580</td>\n",
              "      <td>0.545000</td>\n",
              "      <td>0.657250</td>\n",
              "      <td>0.490335</td>\n",
              "      <td>0.527190</td>\n",
              "      <td>0.872500</td>\n",
              "      <td>0.217500</td>\n",
              "      <td>0.119106</td>\n",
              "      <td>0.552672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.707800</td>\n",
              "      <td>0.703515</td>\n",
              "      <td>0.558750</td>\n",
              "      <td>0.642351</td>\n",
              "      <td>0.533247</td>\n",
              "      <td>0.540034</td>\n",
              "      <td>0.792500</td>\n",
              "      <td>0.325000</td>\n",
              "      <td>0.132920</td>\n",
              "      <td>0.569519</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 323, total number of training (for each informative and uninform class) and test samples: 80, 7120 0.01 XLNet-L 323 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-large-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 00:28, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.744900</td>\n",
              "      <td>0.707631</td>\n",
              "      <td>0.503750</td>\n",
              "      <td>0.667225</td>\n",
              "      <td>0.345898</td>\n",
              "      <td>0.501892</td>\n",
              "      <td>0.995000</td>\n",
              "      <td>0.012500</td>\n",
              "      <td>0.040266</td>\n",
              "      <td>0.510719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.720900</td>\n",
              "      <td>0.688935</td>\n",
              "      <td>0.523750</td>\n",
              "      <td>0.143820</td>\n",
              "      <td>0.406975</td>\n",
              "      <td>0.711111</td>\n",
              "      <td>0.080000</td>\n",
              "      <td>0.967500</td>\n",
              "      <td>0.103080</td>\n",
              "      <td>0.609994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.754500</td>\n",
              "      <td>0.690624</td>\n",
              "      <td>0.517500</td>\n",
              "      <td>0.134529</td>\n",
              "      <td>0.400020</td>\n",
              "      <td>0.652174</td>\n",
              "      <td>0.075000</td>\n",
              "      <td>0.960000</td>\n",
              "      <td>0.075173</td>\n",
              "      <td>0.586631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.675000</td>\n",
              "      <td>0.710934</td>\n",
              "      <td>0.497500</td>\n",
              "      <td>0.004950</td>\n",
              "      <td>0.334415</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.002500</td>\n",
              "      <td>0.992500</td>\n",
              "      <td>-0.035444</td>\n",
              "      <td>0.625387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.782300</td>\n",
              "      <td>0.690328</td>\n",
              "      <td>0.517500</td>\n",
              "      <td>0.134529</td>\n",
              "      <td>0.400020</td>\n",
              "      <td>0.652174</td>\n",
              "      <td>0.075000</td>\n",
              "      <td>0.960000</td>\n",
              "      <td>0.075173</td>\n",
              "      <td>0.618169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.685100</td>\n",
              "      <td>0.690082</td>\n",
              "      <td>0.525000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.417249</td>\n",
              "      <td>0.678571</td>\n",
              "      <td>0.095000</td>\n",
              "      <td>0.955000</td>\n",
              "      <td>0.097983</td>\n",
              "      <td>0.612063</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 1694, total number of training (for each informative and uninform class) and test samples: 80, 7120 0.01 XLNet-L 1694 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-large-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 00:28, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.838300</td>\n",
              "      <td>0.688960</td>\n",
              "      <td>0.545000</td>\n",
              "      <td>0.470930</td>\n",
              "      <td>0.535904</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>0.405000</td>\n",
              "      <td>0.685000</td>\n",
              "      <td>0.093750</td>\n",
              "      <td>0.562887</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.663800</td>\n",
              "      <td>0.683333</td>\n",
              "      <td>0.545000</td>\n",
              "      <td>0.372414</td>\n",
              "      <td>0.507776</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.270000</td>\n",
              "      <td>0.820000</td>\n",
              "      <td>0.107763</td>\n",
              "      <td>0.588863</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.690500</td>\n",
              "      <td>0.673492</td>\n",
              "      <td>0.593750</td>\n",
              "      <td>0.604141</td>\n",
              "      <td>0.593470</td>\n",
              "      <td>0.589074</td>\n",
              "      <td>0.620000</td>\n",
              "      <td>0.567500</td>\n",
              "      <td>0.187759</td>\n",
              "      <td>0.622106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.601100</td>\n",
              "      <td>0.668449</td>\n",
              "      <td>0.595000</td>\n",
              "      <td>0.648590</td>\n",
              "      <td>0.585357</td>\n",
              "      <td>0.572797</td>\n",
              "      <td>0.747500</td>\n",
              "      <td>0.442500</td>\n",
              "      <td>0.199506</td>\n",
              "      <td>0.634269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.485100</td>\n",
              "      <td>0.672463</td>\n",
              "      <td>0.613750</td>\n",
              "      <td>0.657048</td>\n",
              "      <td>0.607494</td>\n",
              "      <td>0.590818</td>\n",
              "      <td>0.740000</td>\n",
              "      <td>0.487500</td>\n",
              "      <td>0.235119</td>\n",
              "      <td>0.642781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.467700</td>\n",
              "      <td>0.691256</td>\n",
              "      <td>0.608750</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.596571</td>\n",
              "      <td>0.580705</td>\n",
              "      <td>0.782500</td>\n",
              "      <td>0.435000</td>\n",
              "      <td>0.231955</td>\n",
              "      <td>0.644663</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 9741, total number of training (for each informative and uninform class) and test samples: 80, 7120 0.01 XLNet-L 9741 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-large-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 00:28, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.723800</td>\n",
              "      <td>0.687600</td>\n",
              "      <td>0.548750</td>\n",
              "      <td>0.550436</td>\n",
              "      <td>0.548744</td>\n",
              "      <td>0.548387</td>\n",
              "      <td>0.552500</td>\n",
              "      <td>0.545000</td>\n",
              "      <td>0.097503</td>\n",
              "      <td>0.553812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.754500</td>\n",
              "      <td>0.694188</td>\n",
              "      <td>0.496250</td>\n",
              "      <td>0.649260</td>\n",
              "      <td>0.377845</td>\n",
              "      <td>0.497997</td>\n",
              "      <td>0.932500</td>\n",
              "      <td>0.060000</td>\n",
              "      <td>-0.015350</td>\n",
              "      <td>0.504188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.695700</td>\n",
              "      <td>0.691949</td>\n",
              "      <td>0.501250</td>\n",
              "      <td>0.645963</td>\n",
              "      <td>0.401205</td>\n",
              "      <td>0.500688</td>\n",
              "      <td>0.910000</td>\n",
              "      <td>0.092500</td>\n",
              "      <td>0.004341</td>\n",
              "      <td>0.520813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.701900</td>\n",
              "      <td>0.701917</td>\n",
              "      <td>0.508750</td>\n",
              "      <td>0.053012</td>\n",
              "      <td>0.360683</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.027500</td>\n",
              "      <td>0.990000</td>\n",
              "      <td>0.064509</td>\n",
              "      <td>0.530253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.693700</td>\n",
              "      <td>0.695153</td>\n",
              "      <td>0.516250</td>\n",
              "      <td>0.089412</td>\n",
              "      <td>0.380025</td>\n",
              "      <td>0.760000</td>\n",
              "      <td>0.047500</td>\n",
              "      <td>0.985000</td>\n",
              "      <td>0.093395</td>\n",
              "      <td>0.551894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.729500</td>\n",
              "      <td>0.693938</td>\n",
              "      <td>0.506250</td>\n",
              "      <td>0.669456</td>\n",
              "      <td>0.347074</td>\n",
              "      <td>0.503145</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.012500</td>\n",
              "      <td>0.079305</td>\n",
              "      <td>0.551269</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 200, total number of training (for each informative and uninform class) and test samples: 80, 7120 0.01 XLNet-L 200 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-large-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 00:28, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.755800</td>\n",
              "      <td>0.706191</td>\n",
              "      <td>0.515000</td>\n",
              "      <td>0.170940</td>\n",
              "      <td>0.414092</td>\n",
              "      <td>0.588235</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.930000</td>\n",
              "      <td>0.053786</td>\n",
              "      <td>0.445578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.743600</td>\n",
              "      <td>0.693714</td>\n",
              "      <td>0.501250</td>\n",
              "      <td>0.666109</td>\n",
              "      <td>0.340462</td>\n",
              "      <td>0.500629</td>\n",
              "      <td>0.995000</td>\n",
              "      <td>0.007500</td>\n",
              "      <td>0.015861</td>\n",
              "      <td>0.525697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.797600</td>\n",
              "      <td>0.712173</td>\n",
              "      <td>0.513750</td>\n",
              "      <td>0.488830</td>\n",
              "      <td>0.512592</td>\n",
              "      <td>0.515235</td>\n",
              "      <td>0.465000</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>0.027632</td>\n",
              "      <td>0.521962</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.788300</td>\n",
              "      <td>0.697406</td>\n",
              "      <td>0.496250</td>\n",
              "      <td>0.661060</td>\n",
              "      <td>0.340262</td>\n",
              "      <td>0.498099</td>\n",
              "      <td>0.982500</td>\n",
              "      <td>0.010000</td>\n",
              "      <td>-0.032202</td>\n",
              "      <td>0.559269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.763100</td>\n",
              "      <td>0.698740</td>\n",
              "      <td>0.498750</td>\n",
              "      <td>0.664996</td>\n",
              "      <td>0.334979</td>\n",
              "      <td>0.499373</td>\n",
              "      <td>0.995000</td>\n",
              "      <td>0.002500</td>\n",
              "      <td>-0.020451</td>\n",
              "      <td>0.566084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.704500</td>\n",
              "      <td>0.700531</td>\n",
              "      <td>0.498750</td>\n",
              "      <td>0.665555</td>\n",
              "      <td>0.332777</td>\n",
              "      <td>0.499374</td>\n",
              "      <td>0.997500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.035377</td>\n",
              "      <td>0.549550</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 999, total number of training (for each informative and uninform class) and test samples: 80, 7120 0.01 XLNet-L 999 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-large-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 00:27, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.766000</td>\n",
              "      <td>0.698318</td>\n",
              "      <td>0.527500</td>\n",
              "      <td>0.357143</td>\n",
              "      <td>0.491813</td>\n",
              "      <td>0.558511</td>\n",
              "      <td>0.262500</td>\n",
              "      <td>0.792500</td>\n",
              "      <td>0.064859</td>\n",
              "      <td>0.508219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.671500</td>\n",
              "      <td>0.773560</td>\n",
              "      <td>0.503750</td>\n",
              "      <td>0.667225</td>\n",
              "      <td>0.345898</td>\n",
              "      <td>0.501892</td>\n",
              "      <td>0.995000</td>\n",
              "      <td>0.012500</td>\n",
              "      <td>0.040266</td>\n",
              "      <td>0.531675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.700500</td>\n",
              "      <td>0.742682</td>\n",
              "      <td>0.551250</td>\n",
              "      <td>0.680321</td>\n",
              "      <td>0.463850</td>\n",
              "      <td>0.528354</td>\n",
              "      <td>0.955000</td>\n",
              "      <td>0.147500</td>\n",
              "      <td>0.173768</td>\n",
              "      <td>0.560881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.555000</td>\n",
              "      <td>0.814691</td>\n",
              "      <td>0.538750</td>\n",
              "      <td>0.670830</td>\n",
              "      <td>0.450237</td>\n",
              "      <td>0.521498</td>\n",
              "      <td>0.940000</td>\n",
              "      <td>0.137500</td>\n",
              "      <td>0.129891</td>\n",
              "      <td>0.545419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.513100</td>\n",
              "      <td>0.797183</td>\n",
              "      <td>0.560000</td>\n",
              "      <td>0.659574</td>\n",
              "      <td>0.518833</td>\n",
              "      <td>0.537855</td>\n",
              "      <td>0.852500</td>\n",
              "      <td>0.267500</td>\n",
              "      <td>0.147959</td>\n",
              "      <td>0.618594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.582600</td>\n",
              "      <td>0.782808</td>\n",
              "      <td>0.566250</td>\n",
              "      <td>0.664734</td>\n",
              "      <td>0.525288</td>\n",
              "      <td>0.541732</td>\n",
              "      <td>0.860000</td>\n",
              "      <td>0.272500</td>\n",
              "      <td>0.163737</td>\n",
              "      <td>0.628575</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 94, total number of training (for each informative and uninform class) and test samples: 80, 7120 0.01 DEBERT-B 94 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 00:15, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.702400</td>\n",
              "      <td>0.694206</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.612441</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.688400</td>\n",
              "      <td>0.693590</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.597969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.696600</td>\n",
              "      <td>0.693053</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.600569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.677900</td>\n",
              "      <td>0.691576</td>\n",
              "      <td>0.512500</td>\n",
              "      <td>0.664948</td>\n",
              "      <td>0.385227</td>\n",
              "      <td>0.506545</td>\n",
              "      <td>0.967500</td>\n",
              "      <td>0.057500</td>\n",
              "      <td>0.060298</td>\n",
              "      <td>0.602644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.645400</td>\n",
              "      <td>0.799807</td>\n",
              "      <td>0.522500</td>\n",
              "      <td>0.204167</td>\n",
              "      <td>0.431548</td>\n",
              "      <td>0.612500</td>\n",
              "      <td>0.122500</td>\n",
              "      <td>0.922500</td>\n",
              "      <td>0.075000</td>\n",
              "      <td>0.582281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.466500</td>\n",
              "      <td>0.719280</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>0.480712</td>\n",
              "      <td>0.551371</td>\n",
              "      <td>0.591241</td>\n",
              "      <td>0.405000</td>\n",
              "      <td>0.720000</td>\n",
              "      <td>0.131705</td>\n",
              "      <td>0.594812</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 791, total number of training (for each informative and uninform class) and test samples: 80, 7120 0.01 DEBERT-B 791 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 00:15, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.696100</td>\n",
              "      <td>0.694579</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.580409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.693900</td>\n",
              "      <td>0.693299</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.626631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.642900</td>\n",
              "      <td>0.763428</td>\n",
              "      <td>0.533750</td>\n",
              "      <td>0.671366</td>\n",
              "      <td>0.434608</td>\n",
              "      <td>0.518367</td>\n",
              "      <td>0.952500</td>\n",
              "      <td>0.115000</td>\n",
              "      <td>0.123527</td>\n",
              "      <td>0.611225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.592600</td>\n",
              "      <td>0.772705</td>\n",
              "      <td>0.576250</td>\n",
              "      <td>0.649431</td>\n",
              "      <td>0.556943</td>\n",
              "      <td>0.553792</td>\n",
              "      <td>0.785000</td>\n",
              "      <td>0.367500</td>\n",
              "      <td>0.167826</td>\n",
              "      <td>0.648925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.198200</td>\n",
              "      <td>0.935342</td>\n",
              "      <td>0.598750</td>\n",
              "      <td>0.467662</td>\n",
              "      <td>0.572848</td>\n",
              "      <td>0.694581</td>\n",
              "      <td>0.352500</td>\n",
              "      <td>0.845000</td>\n",
              "      <td>0.226930</td>\n",
              "      <td>0.651650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.168000</td>\n",
              "      <td>0.932158</td>\n",
              "      <td>0.605000</td>\n",
              "      <td>0.564738</td>\n",
              "      <td>0.601591</td>\n",
              "      <td>0.628834</td>\n",
              "      <td>0.512500</td>\n",
              "      <td>0.697500</td>\n",
              "      <td>0.213689</td>\n",
              "      <td>0.655219</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 5, total number of training (for each informative and uninform class) and test samples: 80, 7120 0.01 DEBERT-B 5 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 00:15, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.696100</td>\n",
              "      <td>0.695446</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.613694</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.690100</td>\n",
              "      <td>0.694394</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.680075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.643900</td>\n",
              "      <td>0.681927</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.693456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.565900</td>\n",
              "      <td>0.803414</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.706113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.418900</td>\n",
              "      <td>1.171812</td>\n",
              "      <td>0.512500</td>\n",
              "      <td>0.672269</td>\n",
              "      <td>0.360525</td>\n",
              "      <td>0.506329</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.025000</td>\n",
              "      <td>0.112509</td>\n",
              "      <td>0.701081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.492900</td>\n",
              "      <td>0.929685</td>\n",
              "      <td>0.606250</td>\n",
              "      <td>0.699714</td>\n",
              "      <td>0.564013</td>\n",
              "      <td>0.565485</td>\n",
              "      <td>0.917500</td>\n",
              "      <td>0.295000</td>\n",
              "      <td>0.271524</td>\n",
              "      <td>0.711525</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 6932, total number of training (for each informative and uninform class) and test samples: 80, 7120 0.01 DEBERT-B 6932 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 00:15, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.694600</td>\n",
              "      <td>0.693994</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.588512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.579500</td>\n",
              "      <td>0.814098</td>\n",
              "      <td>0.525000</td>\n",
              "      <td>0.170306</td>\n",
              "      <td>0.418778</td>\n",
              "      <td>0.672414</td>\n",
              "      <td>0.097500</td>\n",
              "      <td>0.952500</td>\n",
              "      <td>0.096408</td>\n",
              "      <td>0.639750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.393600</td>\n",
              "      <td>0.791961</td>\n",
              "      <td>0.635000</td>\n",
              "      <td>0.668934</td>\n",
              "      <td>0.631125</td>\n",
              "      <td>0.612033</td>\n",
              "      <td>0.737500</td>\n",
              "      <td>0.532500</td>\n",
              "      <td>0.275859</td>\n",
              "      <td>0.677150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.258800</td>\n",
              "      <td>1.420149</td>\n",
              "      <td>0.622500</td>\n",
              "      <td>0.619647</td>\n",
              "      <td>0.622479</td>\n",
              "      <td>0.624365</td>\n",
              "      <td>0.615000</td>\n",
              "      <td>0.630000</td>\n",
              "      <td>0.245028</td>\n",
              "      <td>0.668175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.221600</td>\n",
              "      <td>1.664661</td>\n",
              "      <td>0.640000</td>\n",
              "      <td>0.676404</td>\n",
              "      <td>0.635385</td>\n",
              "      <td>0.614286</td>\n",
              "      <td>0.752500</td>\n",
              "      <td>0.527500</td>\n",
              "      <td>0.287368</td>\n",
              "      <td>0.674512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.006100</td>\n",
              "      <td>1.693603</td>\n",
              "      <td>0.633750</td>\n",
              "      <td>0.665906</td>\n",
              "      <td>0.630325</td>\n",
              "      <td>0.612159</td>\n",
              "      <td>0.730000</td>\n",
              "      <td>0.537500</td>\n",
              "      <td>0.272598</td>\n",
              "      <td>0.672000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 1759, total number of training (for each informative and uninform class) and test samples: 80, 7120 0.01 DEBERT-B 1759 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 00:15, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.696800</td>\n",
              "      <td>0.692971</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.590706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.688500</td>\n",
              "      <td>0.689562</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.682691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.423700</td>\n",
              "      <td>0.740858</td>\n",
              "      <td>0.636250</td>\n",
              "      <td>0.670442</td>\n",
              "      <td>0.632292</td>\n",
              "      <td>0.612836</td>\n",
              "      <td>0.740000</td>\n",
              "      <td>0.532500</td>\n",
              "      <td>0.278563</td>\n",
              "      <td>0.698519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.130600</td>\n",
              "      <td>1.196396</td>\n",
              "      <td>0.643750</td>\n",
              "      <td>0.602510</td>\n",
              "      <td>0.639874</td>\n",
              "      <td>0.681388</td>\n",
              "      <td>0.540000</td>\n",
              "      <td>0.747500</td>\n",
              "      <td>0.293897</td>\n",
              "      <td>0.702913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.176000</td>\n",
              "      <td>1.562988</td>\n",
              "      <td>0.610000</td>\n",
              "      <td>0.681633</td>\n",
              "      <td>0.589203</td>\n",
              "      <td>0.575862</td>\n",
              "      <td>0.835000</td>\n",
              "      <td>0.385000</td>\n",
              "      <td>0.246353</td>\n",
              "      <td>0.700113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.040600</td>\n",
              "      <td>1.508000</td>\n",
              "      <td>0.631250</td>\n",
              "      <td>0.673311</td>\n",
              "      <td>0.625034</td>\n",
              "      <td>0.604374</td>\n",
              "      <td>0.760000</td>\n",
              "      <td>0.502500</td>\n",
              "      <td>0.271661</td>\n",
              "      <td>0.703100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 323, total number of training (for each informative and uninform class) and test samples: 80, 7120 0.01 DEBERT-B 323 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 00:15, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.693800</td>\n",
              "      <td>0.692984</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.620303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.697400</td>\n",
              "      <td>0.692564</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.672056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.688300</td>\n",
              "      <td>0.660598</td>\n",
              "      <td>0.646250</td>\n",
              "      <td>0.648447</td>\n",
              "      <td>0.646236</td>\n",
              "      <td>0.644444</td>\n",
              "      <td>0.652500</td>\n",
              "      <td>0.640000</td>\n",
              "      <td>0.292523</td>\n",
              "      <td>0.680206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.401800</td>\n",
              "      <td>0.702592</td>\n",
              "      <td>0.651250</td>\n",
              "      <td>0.642766</td>\n",
              "      <td>0.651053</td>\n",
              "      <td>0.658793</td>\n",
              "      <td>0.627500</td>\n",
              "      <td>0.675000</td>\n",
              "      <td>0.302842</td>\n",
              "      <td>0.695300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.250300</td>\n",
              "      <td>0.991675</td>\n",
              "      <td>0.663750</td>\n",
              "      <td>0.670747</td>\n",
              "      <td>0.663598</td>\n",
              "      <td>0.657074</td>\n",
              "      <td>0.685000</td>\n",
              "      <td>0.642500</td>\n",
              "      <td>0.327796</td>\n",
              "      <td>0.711537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.134200</td>\n",
              "      <td>1.182660</td>\n",
              "      <td>0.653750</td>\n",
              "      <td>0.642581</td>\n",
              "      <td>0.653412</td>\n",
              "      <td>0.664000</td>\n",
              "      <td>0.622500</td>\n",
              "      <td>0.685000</td>\n",
              "      <td>0.308102</td>\n",
              "      <td>0.706119</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 1694, total number of training (for each informative and uninform class) and test samples: 80, 7120 0.01 DEBERT-B 1694 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 00:15, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.707600</td>\n",
              "      <td>0.700004</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.650025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.615900</td>\n",
              "      <td>0.655639</td>\n",
              "      <td>0.623750</td>\n",
              "      <td>0.668137</td>\n",
              "      <td>0.616897</td>\n",
              "      <td>0.597633</td>\n",
              "      <td>0.757500</td>\n",
              "      <td>0.490000</td>\n",
              "      <td>0.256861</td>\n",
              "      <td>0.672312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.335300</td>\n",
              "      <td>0.764693</td>\n",
              "      <td>0.638750</td>\n",
              "      <td>0.650544</td>\n",
              "      <td>0.638338</td>\n",
              "      <td>0.629977</td>\n",
              "      <td>0.672500</td>\n",
              "      <td>0.605000</td>\n",
              "      <td>0.278134</td>\n",
              "      <td>0.682306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.095300</td>\n",
              "      <td>1.318977</td>\n",
              "      <td>0.621250</td>\n",
              "      <td>0.701478</td>\n",
              "      <td>0.591765</td>\n",
              "      <td>0.578862</td>\n",
              "      <td>0.890000</td>\n",
              "      <td>0.352500</td>\n",
              "      <td>0.287573</td>\n",
              "      <td>0.697850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.014200</td>\n",
              "      <td>1.356564</td>\n",
              "      <td>0.655000</td>\n",
              "      <td>0.665860</td>\n",
              "      <td>0.654635</td>\n",
              "      <td>0.645540</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>0.622500</td>\n",
              "      <td>0.310657</td>\n",
              "      <td>0.699788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.007600</td>\n",
              "      <td>1.438101</td>\n",
              "      <td>0.657500</td>\n",
              "      <td>0.665854</td>\n",
              "      <td>0.657286</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>0.682500</td>\n",
              "      <td>0.632500</td>\n",
              "      <td>0.315394</td>\n",
              "      <td>0.698669</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 9741, total number of training (for each informative and uninform class) and test samples: 80, 7120 0.01 DEBERT-B 9741 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 00:15, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.693600</td>\n",
              "      <td>0.698706</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.586881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.717700</td>\n",
              "      <td>0.697291</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.624141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.624600</td>\n",
              "      <td>0.752996</td>\n",
              "      <td>0.512500</td>\n",
              "      <td>0.173729</td>\n",
              "      <td>0.413992</td>\n",
              "      <td>0.569444</td>\n",
              "      <td>0.102500</td>\n",
              "      <td>0.922500</td>\n",
              "      <td>0.043679</td>\n",
              "      <td>0.613562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.310900</td>\n",
              "      <td>0.786488</td>\n",
              "      <td>0.615000</td>\n",
              "      <td>0.660044</td>\n",
              "      <td>0.608120</td>\n",
              "      <td>0.590909</td>\n",
              "      <td>0.747500</td>\n",
              "      <td>0.482500</td>\n",
              "      <td>0.238528</td>\n",
              "      <td>0.648250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.206400</td>\n",
              "      <td>1.207592</td>\n",
              "      <td>0.607500</td>\n",
              "      <td>0.632319</td>\n",
              "      <td>0.605703</td>\n",
              "      <td>0.594714</td>\n",
              "      <td>0.675000</td>\n",
              "      <td>0.540000</td>\n",
              "      <td>0.216986</td>\n",
              "      <td>0.650313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.129800</td>\n",
              "      <td>1.383680</td>\n",
              "      <td>0.605000</td>\n",
              "      <td>0.633411</td>\n",
              "      <td>0.602613</td>\n",
              "      <td>0.590909</td>\n",
              "      <td>0.682500</td>\n",
              "      <td>0.527500</td>\n",
              "      <td>0.212569</td>\n",
              "      <td>0.648294</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 200, total number of training (for each informative and uninform class) and test samples: 80, 7120 0.01 DEBERT-B 200 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 00:15, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.705300</td>\n",
              "      <td>0.695382</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.639803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.701500</td>\n",
              "      <td>0.694035</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.662591</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.629800</td>\n",
              "      <td>0.645432</td>\n",
              "      <td>0.635000</td>\n",
              "      <td>0.609626</td>\n",
              "      <td>0.633451</td>\n",
              "      <td>0.655172</td>\n",
              "      <td>0.570000</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.272311</td>\n",
              "      <td>0.690519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.376100</td>\n",
              "      <td>0.731014</td>\n",
              "      <td>0.643750</td>\n",
              "      <td>0.656212</td>\n",
              "      <td>0.643281</td>\n",
              "      <td>0.634033</td>\n",
              "      <td>0.680000</td>\n",
              "      <td>0.607500</td>\n",
              "      <td>0.288259</td>\n",
              "      <td>0.677494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.344000</td>\n",
              "      <td>0.939560</td>\n",
              "      <td>0.642500</td>\n",
              "      <td>0.647783</td>\n",
              "      <td>0.642420</td>\n",
              "      <td>0.638350</td>\n",
              "      <td>0.657500</td>\n",
              "      <td>0.627500</td>\n",
              "      <td>0.285128</td>\n",
              "      <td>0.680800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.147800</td>\n",
              "      <td>1.029387</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>0.667458</td>\n",
              "      <td>0.649033</td>\n",
              "      <td>0.635747</td>\n",
              "      <td>0.702500</td>\n",
              "      <td>0.597500</td>\n",
              "      <td>0.301668</td>\n",
              "      <td>0.681075</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model seed is: 999, total number of training (for each informative and uninform class) and test samples: 80, 7120 0.01 DEBERT-B 999 2e-05 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 00:15, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.721600</td>\n",
              "      <td>0.696636</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.581244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.688800</td>\n",
              "      <td>0.694256</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.623931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.690000</td>\n",
              "      <td>0.689817</td>\n",
              "      <td>0.607500</td>\n",
              "      <td>0.668076</td>\n",
              "      <td>0.593977</td>\n",
              "      <td>0.578755</td>\n",
              "      <td>0.790000</td>\n",
              "      <td>0.425000</td>\n",
              "      <td>0.230933</td>\n",
              "      <td>0.646100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.584900</td>\n",
              "      <td>0.671983</td>\n",
              "      <td>0.590000</td>\n",
              "      <td>0.677165</td>\n",
              "      <td>0.557761</td>\n",
              "      <td>0.558442</td>\n",
              "      <td>0.860000</td>\n",
              "      <td>0.320000</td>\n",
              "      <td>0.213862</td>\n",
              "      <td>0.674447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.536500</td>\n",
              "      <td>0.898099</td>\n",
              "      <td>0.623750</td>\n",
              "      <td>0.531882</td>\n",
              "      <td>0.608679</td>\n",
              "      <td>0.703704</td>\n",
              "      <td>0.427500</td>\n",
              "      <td>0.820000</td>\n",
              "      <td>0.269094</td>\n",
              "      <td>0.695794</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.288300</td>\n",
              "      <td>0.811777</td>\n",
              "      <td>0.638750</td>\n",
              "      <td>0.629012</td>\n",
              "      <td>0.638501</td>\n",
              "      <td>0.646438</td>\n",
              "      <td>0.612500</td>\n",
              "      <td>0.665000</td>\n",
              "      <td>0.277883</td>\n",
              "      <td>0.698738</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_result\",\n  \"rows\": 200,\n  \"fields\": [\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"oral-care\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ratio\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03424985786567727,\n        \"min\": 0.01,\n        \"max\": 0.1,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.05\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"DISRoBERTa-B\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"seed\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3168,\n        \"min\": 5,\n        \"max\": 9741,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          200\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07504329760720467,\n        \"min\": 0.47171875,\n        \"max\": 0.75625,\n        \"num_unique_values\": 187,\n        \"samples\": [\n          0.6530898876404494\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1-score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1693981203862819,\n        \"min\": 0.0,\n        \"max\": 0.7767390706626341,\n        \"num_unique_values\": 193,\n        \"samples\": [\n          0.7444993264481365\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"macro_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11237227824126368,\n        \"min\": 0.32052234844463323,\n        \"max\": 0.7559347888263894,\n        \"num_unique_values\": 196,\n        \"samples\": [\n          0.6881684607506002\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.13325769509926277,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 194,\n        \"samples\": [\n          0.6930432703801099\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.20446679075146376,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 189,\n        \"samples\": [\n          0.6329858326650628\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"specificity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1874617520623518,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 189,\n        \"samples\": [\n          0.6682450429121042\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mcc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14327987172373838,\n        \"min\": -0.023198887538345273,\n        \"max\": 0.5125143839749169,\n        \"num_unique_values\": 192,\n        \"samples\": [\n          0.46576770489249913\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AUC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08395806369257912,\n        \"min\": 0.43891586306857056,\n        \"max\": 0.8284633092259328,\n        \"num_unique_values\": 200,\n        \"samples\": [\n          0.784196892248005\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_result"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-9c99df60-9a89-4532-936a-34a2703e1e0c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>ratio</th>\n",
              "      <th>model</th>\n",
              "      <th>seed</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1-score</th>\n",
              "      <th>macro_f1</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>specificity</th>\n",
              "      <th>mcc</th>\n",
              "      <th>AUC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>oral-care</td>\n",
              "      <td>0.10</td>\n",
              "      <td>ALBERT-L</td>\n",
              "      <td>94</td>\n",
              "      <td>0.528438</td>\n",
              "      <td>0.691222</td>\n",
              "      <td>0.346933</td>\n",
              "      <td>0.528390</td>\n",
              "      <td>0.999113</td>\n",
              "      <td>0.001325</td>\n",
              "      <td>0.006609</td>\n",
              "      <td>0.621835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>oral-care</td>\n",
              "      <td>0.10</td>\n",
              "      <td>ALBERT-L</td>\n",
              "      <td>791</td>\n",
              "      <td>0.678906</td>\n",
              "      <td>0.656182</td>\n",
              "      <td>0.677497</td>\n",
              "      <td>0.755393</td>\n",
              "      <td>0.580006</td>\n",
              "      <td>0.789665</td>\n",
              "      <td>0.375835</td>\n",
              "      <td>0.753581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>oral-care</td>\n",
              "      <td>0.10</td>\n",
              "      <td>ALBERT-L</td>\n",
              "      <td>5</td>\n",
              "      <td>0.738906</td>\n",
              "      <td>0.761864</td>\n",
              "      <td>0.736457</td>\n",
              "      <td>0.735149</td>\n",
              "      <td>0.790594</td>\n",
              "      <td>0.681020</td>\n",
              "      <td>0.475292</td>\n",
              "      <td>0.783641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>oral-care</td>\n",
              "      <td>0.10</td>\n",
              "      <td>ALBERT-L</td>\n",
              "      <td>6932</td>\n",
              "      <td>0.749219</td>\n",
              "      <td>0.759623</td>\n",
              "      <td>0.748748</td>\n",
              "      <td>0.769417</td>\n",
              "      <td>0.750074</td>\n",
              "      <td>0.748261</td>\n",
              "      <td>0.497761</td>\n",
              "      <td>0.814214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>oral-care</td>\n",
              "      <td>0.10</td>\n",
              "      <td>ALBERT-L</td>\n",
              "      <td>1759</td>\n",
              "      <td>0.637656</td>\n",
              "      <td>0.688265</td>\n",
              "      <td>0.627848</td>\n",
              "      <td>0.630853</td>\n",
              "      <td>0.757172</td>\n",
              "      <td>0.503809</td>\n",
              "      <td>0.270467</td>\n",
              "      <td>0.667575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>oral-care</td>\n",
              "      <td>0.01</td>\n",
              "      <td>DEBERT-B</td>\n",
              "      <td>323</td>\n",
              "      <td>0.649719</td>\n",
              "      <td>0.655048</td>\n",
              "      <td>0.649635</td>\n",
              "      <td>0.678704</td>\n",
              "      <td>0.632986</td>\n",
              "      <td>0.668245</td>\n",
              "      <td>0.300901</td>\n",
              "      <td>0.713786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>oral-care</td>\n",
              "      <td>0.01</td>\n",
              "      <td>DEBERT-B</td>\n",
              "      <td>1694</td>\n",
              "      <td>0.652247</td>\n",
              "      <td>0.671269</td>\n",
              "      <td>0.651079</td>\n",
              "      <td>0.666843</td>\n",
              "      <td>0.675755</td>\n",
              "      <td>0.626221</td>\n",
              "      <td>0.302222</td>\n",
              "      <td>0.702237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>oral-care</td>\n",
              "      <td>0.01</td>\n",
              "      <td>DEBERT-B</td>\n",
              "      <td>9741</td>\n",
              "      <td>0.634972</td>\n",
              "      <td>0.670220</td>\n",
              "      <td>0.630754</td>\n",
              "      <td>0.637923</td>\n",
              "      <td>0.705961</td>\n",
              "      <td>0.556378</td>\n",
              "      <td>0.265547</td>\n",
              "      <td>0.685477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>oral-care</td>\n",
              "      <td>0.01</td>\n",
              "      <td>DEBERT-B</td>\n",
              "      <td>200</td>\n",
              "      <td>0.653090</td>\n",
              "      <td>0.681783</td>\n",
              "      <td>0.650246</td>\n",
              "      <td>0.658045</td>\n",
              "      <td>0.707298</td>\n",
              "      <td>0.593075</td>\n",
              "      <td>0.302531</td>\n",
              "      <td>0.701000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>oral-care</td>\n",
              "      <td>0.01</td>\n",
              "      <td>DEBERT-B</td>\n",
              "      <td>999</td>\n",
              "      <td>0.639326</td>\n",
              "      <td>0.622575</td>\n",
              "      <td>0.638614</td>\n",
              "      <td>0.691479</td>\n",
              "      <td>0.566159</td>\n",
              "      <td>0.720331</td>\n",
              "      <td>0.288949</td>\n",
              "      <td>0.703856</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200 rows  12 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9c99df60-9a89-4532-936a-34a2703e1e0c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9c99df60-9a89-4532-936a-34a2703e1e0c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9c99df60-9a89-4532-936a-34a2703e1e0c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1c3d4dbe-8d59-450c-8445-43af0434ffef\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1c3d4dbe-8d59-450c-8445-43af0434ffef')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1c3d4dbe-8d59-450c-8445-43af0434ffef button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_955afd0a-af99-42a8-a193-5807d0184c16\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_result')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_955afd0a-af99-42a8-a193-5807d0184c16 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_result');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "      category  ratio     model  seed  accuracy  f1-score  macro_f1  \\\n",
              "0    oral-care   0.10  ALBERT-L    94  0.528438  0.691222  0.346933   \n",
              "1    oral-care   0.10  ALBERT-L   791  0.678906  0.656182  0.677497   \n",
              "2    oral-care   0.10  ALBERT-L     5  0.738906  0.761864  0.736457   \n",
              "3    oral-care   0.10  ALBERT-L  6932  0.749219  0.759623  0.748748   \n",
              "4    oral-care   0.10  ALBERT-L  1759  0.637656  0.688265  0.627848   \n",
              "..         ...    ...       ...   ...       ...       ...       ...   \n",
              "195  oral-care   0.01  DEBERT-B   323  0.649719  0.655048  0.649635   \n",
              "196  oral-care   0.01  DEBERT-B  1694  0.652247  0.671269  0.651079   \n",
              "197  oral-care   0.01  DEBERT-B  9741  0.634972  0.670220  0.630754   \n",
              "198  oral-care   0.01  DEBERT-B   200  0.653090  0.681783  0.650246   \n",
              "199  oral-care   0.01  DEBERT-B   999  0.639326  0.622575  0.638614   \n",
              "\n",
              "     precision    recall  specificity       mcc       AUC  \n",
              "0     0.528390  0.999113     0.001325  0.006609  0.621835  \n",
              "1     0.755393  0.580006     0.789665  0.375835  0.753581  \n",
              "2     0.735149  0.790594     0.681020  0.475292  0.783641  \n",
              "3     0.769417  0.750074     0.748261  0.497761  0.814214  \n",
              "4     0.630853  0.757172     0.503809  0.270467  0.667575  \n",
              "..         ...       ...          ...       ...       ...  \n",
              "195   0.678704  0.632986     0.668245  0.300901  0.713786  \n",
              "196   0.666843  0.675755     0.626221  0.302222  0.702237  \n",
              "197   0.637923  0.705961     0.556378  0.265547  0.685477  \n",
              "198   0.658045  0.707298     0.593075  0.302531  0.701000  \n",
              "199   0.691479  0.566159     0.720331  0.288949  0.703856  \n",
              "\n",
              "[200 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "TypeError",
          "evalue": "Could not convert ALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-LXLNet-LXLNet-LXLNet-LXLNet-LXLNet-LXLNet-LXLNet-LXLNet-LXLNet-LDEBERT-BDEBERT-BDEBERT-BDEBERT-BDEBERT-BDEBERT-BDEBERT-BDEBERT-BDEBERT-BDEBERT-BALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-LXLNet-LXLNet-LXLNet-LXLNet-LXLNet-LXLNet-LXLNet-LXLNet-LXLNet-LDEBERT-BDEBERT-BDEBERT-BDEBERT-BDEBERT-BDEBERT-BDEBERT-BDEBERT-BDEBERT-BDEBERT-BALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-LXLNet-LXLNet-LXLNet-LXLNet-LXLNet-LXLNet-LXLNet-LXLNet-LXLNet-LDEBERT-BDEBERT-BDEBERT-BDEBERT-BDEBERT-BDEBERT-BDEBERT-BDEBERT-BDEBERT-BDEBERT-BALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-LXLNet-LXLNet-LXLNet-LXLNet-LXLNet-LXLNet-LXLNet-LXLNet-LXLNet-LDEBERT-BDEBERT-BDEBERT-BDEBERT-BDEBERT-BDEBERT-BDEBERT-BDEBERT-BDEBERT-BDEBERT-B to numeric",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36marray_func\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m   1489\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1490\u001b[0;31m                 result = self.grouper._cython_operation(\n\u001b[0m\u001b[1;32m   1491\u001b[0m                     \u001b[0;34m\"aggregate\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36m_cython_operation\u001b[0;34m(self, kind, values, how, axis, min_count, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mngroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 959\u001b[0;31m         return cy_op.cython_operation(\n\u001b[0m\u001b[1;32m    960\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36mcython_operation\u001b[0;34m(self, values, axis, min_count, comp_ids, ngroups, **kwargs)\u001b[0m\n\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m         return self._cython_op_ndim_compat(\n\u001b[0m\u001b[1;32m    658\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36m_cython_op_ndim_compat\u001b[0;34m(self, values, min_count, ngroups, comp_ids, mask, result_mask, **kwargs)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m         return self._call_cython_op(\n\u001b[0m\u001b[1;32m    498\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36m_call_cython_op\u001b[0;34m(self, values, min_count, ngroups, comp_ids, mask, result_mask, **kwargs)\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0mout_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_cython_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_numeric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_cython_vals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36m_get_cython_function\u001b[0;34m(cls, kind, how, dtype, is_numeric)\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0;31m# raise NotImplementedError here rather than TypeError later\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 raise NotImplementedError(\n\u001b[0m\u001b[1;32m    174\u001b[0m                     \u001b[0;34mf\"function is not implemented for this dtype: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: function is not implemented for this dtype: [how->mean,dtype->object]",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36m_ensure_numeric\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1691\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1692\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1693\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'ALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-LXLNet-LXLNet-LXLNet-LXLNet-LXLNet-LXLNet-LXLNet-LXLNet-LXLNet-LDEBERT-BDEBERT-BDEBERT-BDEBERT-BDEBERT-BDEBERT-BDEBERT-BDEBERT-BDEBERT-BDEBERT-BALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-LXLNet-LXLNet-LXLNet-LXLNet-LXLNet-LXLNet-LXLNet-LXLNet-LXLNet-LDEBERT-BDEBERT-BDEBERT-BDEBERT-BDEBERT-BDEBERT-BDEBERT-BDEBERT-BDEBERT-BDEBERT-BALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-LXLNet-LXLNet-LXLNet-LXLNet-LXLNet-LXLNet-LXLNet-LXLNet-LXLNet-LDEBERT-BDEBERT-BDEBERT-BDEBERT-BDEBERT-BDEBERT-BDEBERT-BDEBERT-BDEBERT-BDEBERT-BALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDI...",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36m_ensure_numeric\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1695\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1696\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomplex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1697\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: complex() arg is a malformed string",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-53c09aebcea5>\u001b[0m in \u001b[0;36m<cell line: 166>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0mdf_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'category'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ratio'\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'seed'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'f1-score'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'macro_f1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'precision'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'recall'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'specificity'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mcc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'AUC'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(self, numeric_only, engine, engine_kwargs)\u001b[0m\n\u001b[1;32m   1853\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numba_agg_general\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msliding_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1854\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1855\u001b[0;31m             result = self._cython_agg_general(\n\u001b[0m\u001b[1;32m   1856\u001b[0m                 \u001b[0;34m\"mean\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1857\u001b[0m                 \u001b[0malt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m_cython_agg_general\u001b[0;34m(self, how, alt, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[1;32m   1505\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1507\u001b[0;31m         \u001b[0mnew_mgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouped_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1508\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_agged_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_mgr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1509\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_aggregated_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mgrouped_reduce\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m   1501\u001b[0m                 \u001b[0;31m#  while others do not.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1502\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0msb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1503\u001b[0;31m                     \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1504\u001b[0m                     \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1505\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0mone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \"\"\"\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split_op_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36marray_func\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m   1501\u001b[0m                 \u001b[0;31m# try to python agg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1502\u001b[0m                 \u001b[0;31m# TODO: shouldn't min_count matter?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1503\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_agg_py_fallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1505\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m_agg_py_fallback\u001b[0;34m(self, values, ndim, alt)\u001b[0m\n\u001b[1;32m   1455\u001b[0m         \u001b[0;31m#  should always be preserved by the implemented aggregations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m         \u001b[0;31m# TODO: Is this exactly right; see WrappedCythonOp get_result_dtype?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1457\u001b[0;31m         \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreserve_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36magg_series\u001b[0;34m(self, obj, func, preserve_dtype)\u001b[0m\n\u001b[1;32m    992\u001b[0m             \u001b[0mpreserve_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aggregate_series_pure_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m         \u001b[0mnpvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_convert_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtry_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36m_aggregate_series_pure_python\u001b[0;34m(self, obj, func)\u001b[0m\n\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplitter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1015\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1016\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1855\u001b[0m             result = self._cython_agg_general(\n\u001b[1;32m   1856\u001b[0m                 \u001b[0;34m\"mean\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1857\u001b[0;31m                 \u001b[0malt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1858\u001b[0m                 \u001b[0mnumeric_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1859\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11554\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11555\u001b[0m         ):\n\u001b[0;32m> 11556\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  11557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11558\u001b[0m         \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"mean\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11199\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11200\u001b[0m     ) -> Series | float:\n\u001b[0;32m> 11201\u001b[0;31m         return self._stat_function(\n\u001b[0m\u001b[1;32m  11202\u001b[0m             \u001b[0;34m\"mean\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnanops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11203\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_stat_function\u001b[0;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11156\u001b[0m         \u001b[0mvalidate_bool_kwarg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"skipna\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnone_allowed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 11158\u001b[0;31m         return self._reduce(\n\u001b[0m\u001b[1;32m  11159\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11160\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   4668\u001b[0m                 )\n\u001b[1;32m   4669\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4670\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4672\u001b[0m     def _reindex_indexer(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36m_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvalid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0;31m# we want to transform an object array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    156\u001b[0m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[1;32m    419\u001b[0m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdatetimelike\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mnanmean\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m    725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m     \u001b[0mthe_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ensure_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_sum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthe_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ndim\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36m_ensure_numeric\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1697\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1698\u001b[0m                 \u001b[0;31m# e.g. \"foo\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1699\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Could not convert {x} to numeric\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1700\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Could not convert ALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-LXLNet-LXLNet-LXLNet-LXLNet-LXLNet-LXLNet-LXLNet-LXLNet-LXLNet-LDEBERT-BDEBERT-BDEBERT-BDEBERT-BDEBERT-BDEBERT-BDEBERT-BDEBERT-BDEBERT-BDEBERT-BALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-LXLNet-LXLNet-LXLNet-LXLNet-LXLNet-LXLNet-LXLNet-LXLNet-LXLNet-LDEBERT-BDEBERT-BDEBERT-BDEBERT-BDEBERT-BDEBERT-BDEBERT-BDEBERT-BDEBERT-BDEBERT-BALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-BXLNet-LXLNet-LXLNet-LXLNet-LXLNet-LXLNet-LXLNet-LXLNet-LXLNet-LXLNet-LDEBERT-BDEBERT-BDEBERT-BDEBERT-BDEBERT-BDEBERT-BDEBERT-BDEBERT-BDEBERT-BDEBERT-BALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LALBERT-LDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERTa-BDISRoBERT..."
          ]
        }
      ],
      "source": [
        "frequency = pd.read_pickle('/content/drive/MyDrive/paper1/datasets/dictionary frequency of occurence of needs')\n",
        "\n",
        "# In domain dataset\n",
        "data_set_1 = pd.read_csv('/content/drive/MyDrive/Fairness paper datasets/8000_sentences_with_need_IDs.csv')\n",
        "\n",
        "# Out of domain datasets\n",
        "data_set_2 = pd.read_csv('/content/drive/MyDrive/Fairness paper datasets/Electronics.csv')\n",
        "data_set_3 = pd.read_csv('/content/drive/MyDrive/Fairness paper datasets/baby.csv')\n",
        "data_set_4 = pd.read_csv('/content/drive/MyDrive/Fairness paper datasets/Pet_supplies.csv')\n",
        "data_set_5 = pd.read_csv('/content/drive/MyDrive/Fairness paper datasets/Sport_outdoors.csv')\n",
        "\n",
        "# Ensure the 'sentence' column is of type 'str'\n",
        "data_set_1['sentence'] = data_set_1['sentence'].astype(str)\n",
        "data_set_2['sentence'] = data_set_2['sentence'].astype(str)\n",
        "data_set_3['sentence'] = data_set_3['sentence'].astype(str)\n",
        "data_set_4['sentence'] = data_set_4['sentence'].astype(str)\n",
        "data_set_5['sentence'] = data_set_5['sentence'].astype(str)\n",
        "\n",
        "ratios = {\n",
        "           'A': 0.50,\n",
        "           'B': 0.20,\n",
        "           'C': 0.10,\n",
        "           'D': 0.05,\n",
        "           'E': 0.025,\n",
        "           'F': 0.01\n",
        "           }\n",
        "\n",
        "models = {\n",
        "              'albert_base' :\"albert-base-v2\",\n",
        "              'distilbert'  :\"distilbert-base-uncased\",\n",
        "              'bertB'       :\"bert-base-uncased\",\n",
        "              'bertL'       :\"bert-large-uncased\",\n",
        "              'robertB'     :\"roberta-base\",\n",
        "              'robertL'     :\"roberta-large\",\n",
        "              'allenaiB'    :\"allenai/reviews_roberta_base\",\n",
        "\n",
        "              'ALBERT-L'      :\"albert/albert-large-v2\",\n",
        "              'DISRoBERTa-B'  :\"distilbert/distilroberta-base\",\n",
        "              'XLNet-B'       :\"xlnet/xlnet-base-cased\",\n",
        "              'XLNet-L'       :\"xlnet/xlnet-large-cased\",\n",
        "              'DEBERT-B'      :\"microsoft/deberta-base\",\n",
        "              'DEBERT-L'      :\"microsoft/deberta-large\",\n",
        "              'XLM-B'         :\"FacebookAI/xlm-roberta-base\",\n",
        "              'XLM-L'         :\"FacebookAI/xlm-roberta-large\"\n",
        "          }\n",
        "\n",
        "seeds = [94, 791, 5, 6932, 1759, 323, 1694, 9741, 200, 999]  # randomly selected\n",
        "all_datasets_ratio_models_seed_results = {}\n",
        "results = []\n",
        "results_exclude = []\n",
        "results_garbage = []\n",
        "results_uninf_exc = []\n",
        "\n",
        "\n",
        "\n",
        "for ratio_label, ratio in ratios.items():\n",
        "    all_datasets_ratio_models_seed_results.update({ratio:{}})\n",
        "\n",
        "    for model_name, model_address in models.items():\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_address)\n",
        "        all_datasets_ratio_models_seed_results[ratio].update({model_name:{}})\n",
        "        training_args = return_training_args()  # to reinitialize training arguments:  must be added\n",
        "        if (ratio < 0.20) and (ratio >= 0.05):\n",
        "           training_args.per_device_train_batch_size = 8\n",
        "           training_args.logging_steps = 25\n",
        "        elif (ratio < 0.05):\n",
        "           training_args.per_device_train_batch_size = 4\n",
        "           training_args.logging_steps = 10\n",
        "\n",
        "\n",
        "        if model_name == 'bertL':\n",
        "           training_args.learning_rate = 2e-5\n",
        "        if model_name == 'robertL':\n",
        "           training_args.learning_rate = 1.25e-5\n",
        "        if model_name == 'ALBERT-L' :\n",
        "           training_args.learning_rate = 8e-6\n",
        "        if model_name == 'DISRoBERTa-B':\n",
        "           training_args.learning_rate = 2e-5\n",
        "        if model_name == 'XLNet-B':\n",
        "           training_args.learning_rate = 2e-5\n",
        "        if model_name == 'XLNet-L' :\n",
        "           training_args.learning_rate = 1e-5\n",
        "        if model_name == 'DEBERT-B':\n",
        "           training_args.learning_rate = 3e-5\n",
        "        if model_name == 'DEBERT-L':\n",
        "           training_args.learning_rate = 1e-5\n",
        "        if model_name ==  'XLM-B':\n",
        "           training_args.learning_rate = 2e-5\n",
        "        if model_name ==  'XLM-L':\n",
        "           training_args.learning_rate = 8e-6\n",
        "        else:\n",
        "           training_args.learning_rate = 2e-5\n",
        "\n",
        "        for seed in seeds:\n",
        "            set_seed(seed)\n",
        "            training_args.seed = seed\n",
        "\n",
        "            r = int(ratio * data_set_1.shape[0] / 2)\n",
        "            df_train_uninf = data_set_1[data_set_1.label == 0].sample(n = r, random_state = seed)\n",
        "            df_train_inf = data_set_1[data_set_1.label == 1].sample(n = r, random_state = seed)\n",
        "            df_train = pd.concat([df_train_inf, df_train_uninf]).sample(frac= 1, random_state = seed)\n",
        "            # Find the rows not selected\n",
        "            df_test_all = data_set_1.drop(df_train.index)\n",
        "            df_val_uninf = df_test_all[df_test_all.label == 0].sample(n = 400, random_state = seed)\n",
        "            df_val_inf = df_test_all[df_test_all.label == 1].sample(n = 400, random_state = seed)\n",
        "            df_val  = pd.concat([df_val_inf, df_val_uninf]).sample(frac= 1, random_state = seed)\n",
        "            df_test = df_test_all.drop(df_val.index)\n",
        "\n",
        "            # Reset index\n",
        "            df_train = df_train.reset_index(drop=True)\n",
        "            df_val   = df_val.reset_index(drop=True)\n",
        "            df_test  = df_test.reset_index(drop=True)\n",
        "            # Encoding\n",
        "            train_main_encodings = tokenizer(df_train.sentence.tolist(), truncation=True, padding=True, max_length=40)\n",
        "            val_main_encodings   = tokenizer(df_val.sentence.tolist(), truncation=True, padding=True, max_length=40)\n",
        "            test_main_encodings  = tokenizer(df_test.sentence.tolist(), truncation=True, padding=True, max_length=40)\n",
        "\n",
        "\n",
        "            train_dataset     = AmazonDataset(train_main_encodings, df_train.label.tolist())\n",
        "            val_dataset       = AmazonDataset(val_main_encodings, df_val.label.tolist())\n",
        "            test_main_dataset = AmazonDataset(test_main_encodings, df_test.label.tolist())\n",
        "\n",
        "\n",
        "            print(f'Model seed is: {training_args.seed}, total number of '\n",
        "                  f'training (for each informative and uninform class) and test samples: '\n",
        "                  f'{df_train.shape[0]}, {df_test.shape[0]}', ratio, model_name,\n",
        "                  training_args.seed, training_args.learning_rate,\n",
        "                  training_args.per_device_train_batch_size)\n",
        "            model = AutoModelForSequenceClassification.from_pretrained(model_address) # option 1: allenai/reviews_roberta_base  # option2: roberta-base\n",
        "            trainer = Trainer(\n",
        "                model=model,\n",
        "                args=training_args,\n",
        "                train_dataset = train_dataset,\n",
        "                eval_dataset = val_dataset,             # evaluation dataset must be off when doing simple K-fold cross validation\n",
        "                # callbacks= [EarlyStoppingCallback(early_stopping_patience= 3,early_stopping_threshold=0.05)],\n",
        "                compute_metrics = compute_metrics\n",
        "            )\n",
        "\n",
        "            trainoutput = trainer.train()\n",
        "            tr_loss = trainoutput.training_loss\n",
        "            pred = trainer.predict(test_main_dataset)\n",
        "            results.append([\"oral-care\", ratio, model_name, seed, pred.metrics['test_accuracy'], pred.metrics['test_f1'], pred.metrics['test_macro_f1'],\n",
        "                            pred.metrics['test_precision'], pred.metrics['test_recall'], pred.metrics['test_specificity'],\n",
        "                            pred.metrics['test_mcc'], pred.metrics['test_AUC']])\n",
        "            log_history = trainer.state.log_history\n",
        "            all_datasets_ratio_models_seed_results[ratio][model_name].update(\n",
        "                                                                           { seed : {\n",
        "                                                                                            \"oral-care\":            [df_train.Sentence_ID.values, df_val.Sentence_ID.values, df_test.Sentence_ID.values, pred, tr_loss, log_history],\n",
        "                                                                                            \"electronics\":          trainer.predict(prepare_auxilary_datasets(data_set_2)),\n",
        "                                                                                            \"baby\":                 trainer.predict(prepare_auxilary_datasets(data_set_3)),\n",
        "                                                                                            \"pet-supplies\":         trainer.predict(prepare_auxilary_datasets(data_set_4)),\n",
        "                                                                                            \"Sport-outdoors\":       trainer.predict(prepare_auxilary_datasets(data_set_5)),\n",
        "                                                                                          }\n",
        "                                                                           })\n",
        "        # Specify the path in Google Drive\n",
        "        file_path = f'/content/drive/MyDrive/paper1/Sample_Efficiency/all_results_{ratio_label}_{model_name}'\n",
        "        # Serialize and save the dictionary\n",
        "        with open(file_path, 'wb') as handle:\n",
        "             pickle.dump(all_datasets_ratio_models_seed_results, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_result = pd.DataFrame(results, columns = ['category', 'ratio' ,'model', 'seed', 'accuracy','f1-score', 'macro_f1', 'precision', 'recall', 'specificity', 'mcc', 'AUC'])\n",
        "display(df_result)\n",
        "display(df_result.groupby(df_result.category).mean(numeric_only = True))\n",
        "\n",
        "\n",
        "tables = {\"oral-care\": results,\"electronics\": [],\"baby\": [],\n",
        "          \"pet-supplies\": [],\"Sport-outdoors\": []}\n",
        "\n",
        "for rto, values in all_datasets_ratio_models_seed_results.items():\n",
        "    for model_name, value in values.items():\n",
        "        for seed, val in value.items():\n",
        "            for dataset, v in val.items():\n",
        "                if dataset == \"oral-care\":\n",
        "                  tables[\"oral-care\"] =  df_result\n",
        "                else:\n",
        "                   tables[dataset].append([dataset, rto, model_name, seed, v.metrics['test_accuracy'],\n",
        "                                           v.metrics['test_f1'], v.metrics['test_macro_f1'], v.metrics['test_precision'],\n",
        "                                           v.metrics['test_recall'], v.metrics['test_specificity'],\n",
        "                                           pred.metrics['test_mcc'], v.metrics['test_AUC']]\n",
        "                                          )\n",
        "\n",
        "\n",
        "df_total_list = [pd.DataFrame(t, columns = ['category','ratio' ,'model', 'seed', 'accuracy','f1-score', 'macro_f1','precision', 'recall', 'specificity', 'mcc', 'AUC']) for k, t in tables.items()]\n",
        "df = pd.concat(df_total_list).drop_duplicates().reset_index(drop=True)\n",
        "display(df.groupby(df.category).mean(numeric_only = True))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2XabC655EeY"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Specify the path in Google Drive\n",
        "file_path = f'/content/drive/MyDrive/paper1/temp/Sample_Efficiency/all_results_sample_efficiency_after_revision_3'\n",
        "# Serialize and save the dictionary\n",
        "with open(file_path, 'wb') as handle:\n",
        "     pickle.dump(all_datasets_ratio_models_seed_results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}